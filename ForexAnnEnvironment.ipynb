{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y23CLo2oUco-O4CAkKZhYsjzzzbnTeLP",
      "authorship_tag": "ABX9TyMqNNP0Fkx6moLcjD6O4AWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment\n",
        "\n",
        "Installing all the necessary packages and importing the relevant libraries to be used in the creation and testing of models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "21a4334e-bd5a-48e2-97e4-ef167968f964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "!pip install fred\n",
        "#!pip install mock\n",
        "\n",
        "\n",
        "import fred\n",
        "#from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, CuDNNLSTM\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import math"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.12.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.0.3)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.18.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.12.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fred) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2020.4.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLZPCwgy2jrc",
        "colab_type": "code",
        "outputId": "607a2436-446f-429d-93d0-f62af37db4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import platform\n",
        "print(platform.python_version())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knovwSza04MP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSX-AVfVGK6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The start and end date to be used in queries to the various API\n",
        "START_DATE = '2001-01-01'\n",
        "END_DATE = '2020-02-01'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mBJkhEqGfRq",
        "colab_type": "text"
      },
      "source": [
        "## Moving average function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpuooBtRGero",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function which takes data and a window size to return an array of same length\n",
        "# but as a moving average\n",
        "def getMovingAverages(data, windowSize):\n",
        "\n",
        "    movingAverages = []\n",
        "\n",
        "    # For each datapoint, take the previous 'windowSie' values and calculate average\n",
        "    for x in range(len(data)):\n",
        "        if (x < windowSize):\n",
        "            window = data[:x+1]\n",
        "        else:\n",
        "            window = data[x-(windowSize - 1):x+1]\n",
        "        \n",
        "        total = sum(window)\n",
        "        average = total / len(window)\n",
        "        movingAverages.append(average)\n",
        "\n",
        "    return movingAverages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n68WYYVB6UK7",
        "colab_type": "text"
      },
      "source": [
        "## FOREX data\n",
        "\n",
        "This imports all necessary FOREX data and normalises it, ready for use by the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get FOREX data from quandl API using a key\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=START_DATE, end_date=END_DATE, returns=\"numpy\")\n",
        "forexData = dataGbpEurRate.Value\n",
        "\n",
        "# Convert forex data to numpy array, then calcaulte the mean and std to normalise the dataset\n",
        "forexRaw = np.asarray(forexData)\n",
        "forex_mean_raw = forexRaw.mean()\n",
        "forex_std_raw = forexRaw.std()\n",
        "forexRaw = (forexRaw - forex_mean_raw) / forex_std_raw\n",
        "\n",
        "# Convert the forex data into a moving average, then apply the same steps to normalise the data\n",
        "forexMonthMovAvg = getMovingAverages(forexData, 10)\n",
        "forexMonthMovAvg = np.asarray(forexMonthMovAvg)\n",
        "forex_mean_avg = forexMonthMovAvg.mean()\n",
        "forex_std_avg = forexMonthMovAvg.std()\n",
        "forexMonthMovAvg = (forexMonthMovAvg - forex_mean_avg) / forex_std_avg\n",
        "\n",
        "# Convert all dates retrieved from the API to pandas Timestamps\n",
        "ukFOREXdates = []\n",
        "for x in dataGbpEurRate.Date:\n",
        "    ukFOREXdates.append(pd.Timestamp(x))\n",
        "\n",
        "# Create a dictionary of the dates : raw forex value\n",
        "forexRawDict = {ukFOREXdates[i]: forexRaw[i] for i in range(len(ukFOREXdates))}\n",
        "\n",
        "# Create a dataframe object of the moving average forex values\n",
        "forexData = {'Date':ukFOREXdates,'Value':forexMonthMovAvg}\n",
        "forexDf = pd.DataFrame(forexData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "## Interest Rate Data (INT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUTeDp07W41L",
        "colab_type": "text"
      },
      "source": [
        "### INT data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0f5HNs21pcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retreive the LIBOR rates for all maturity lengths and both currency as a json format \n",
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "\n",
        "# Filter the json objects to just the observed values\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgecCRUBkiR",
        "colab_type": "text"
      },
      "source": [
        "### INT data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkAjnFLBlhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to clean specifically LIBOR rate data\n",
        "def cleanDataSets(dataset):\n",
        "\n",
        "    # Convert the dataset given into a dictionary of date : value\n",
        "    dataDict = {pd.Timestamp(dataset[i][\"date\"]): dataset[i][\"value\"] for i in range(len(dataset))}\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "\n",
        "    # Loop over the FOREX dataframe as a reference of all dates that are needed to be matched\n",
        "    for index, row in forexDf.iterrows():\n",
        "        # For each FOREX value, it will attempt to get the LIBOR rate for the same day from the dict \n",
        "        value = dataDict.get(row['Date'], 1000000)\n",
        "\n",
        "        if (value=='.'):\n",
        "            value = 1000000\n",
        "\n",
        "        # If the date was either missing or returned as '.' the missing data must be created\n",
        "        if(value==1000000):\n",
        "            # Get the values from either side of the missing value\n",
        "            dateBelow = forexDf.Date.iloc[index-1]\n",
        "            dateAbove = forexDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataDict.get(dateBelow, 1000000)\n",
        "            valueAbove = dataDict.get(dateAbove, 1000000)\n",
        "\n",
        "            # Calculate an average and impute the data\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "# Clean all LIBOR datasets\n",
        "GBRovrC = cleanDataSets(GBRovrJson)\n",
        "EURovrC = cleanDataSets(EURovrJson)\n",
        "GBR3mC = cleanDataSets(GBR3mJson)\n",
        "EUR3mC = cleanDataSets(EUR3mJson)\n",
        "GBR6mC = cleanDataSets(GBR6mJson)\n",
        "EUR6mC = cleanDataSets(EUR6mJson)\n",
        "GBR12mC = cleanDataSets(GBR12mJson)\n",
        "EUR12mC = cleanDataSets(EUR12mJson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euiAqH5oXFmC",
        "colab_type": "text"
      },
      "source": [
        "### INT feature engineering\n",
        "\n",
        "This section now creates the features that will be used in the final models. Getting the difference between the currencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjzi_yf1sjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create dictionary of the difference of two dictionaries passed to it\n",
        "def getDifferenceFeatures(xDict, yDict, avg):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "                   \n",
        "    # Loop over each value of one dict and retreive the value for the same date from the other\n",
        "    for k,v in xDict.items():\n",
        "\n",
        "        match = yDict.get(k, 0)\n",
        "        valuesX.append(float(v))\n",
        "        valuesY.append(float(match))\n",
        "        dates.append(k)\n",
        " \n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    # Calculate the difference between all values\n",
        "    diffValues = datasetXarr - datasetYarr\n",
        "\n",
        "    # If the avg flag was passed as true then calculate the moving average aswell\n",
        "    if(avg):\n",
        "        diffValues = getMovingAverages(diffValues, 10)\n",
        "\n",
        "    diffValues = np.asarray(diffValues)\n",
        "\n",
        "    # Normalise the difference data\n",
        "    data_mean = diffValues.mean()\n",
        "    data_std = diffValues.std()\n",
        "    dataNormalised = (diffValues - data_mean) - data_std\n",
        "\n",
        "    # Create a dictionary for the difference values of date : difference value\n",
        "    diffDict = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return diffDict\n",
        "\n",
        "# Get the difference values for all LIBOR maturity lengths, both raw and as an average\n",
        "ovrRatio = getDifferenceFeatures(GBRovrC,EURovrC, False)\n",
        "threeMRatio = getDifferenceFeatures(GBR3mC,EUR3mC, False)\n",
        "sixMRatio = getDifferenceFeatures(GBR6mC,EUR6mC, False)\n",
        "twelveMRatio = getDifferenceFeatures(GBR12mC,EUR12mC, False)\n",
        "ovrRatioMovAvg = getDifferenceFeatures(GBRovrC,EURovrC, True)\n",
        "threeMRatioMovAvg = getDifferenceFeatures(GBR3mC,EUR3mC, True)\n",
        "sixMRatioMovAvg = getDifferenceFeatures(GBR6mC,EUR6mC, True)\n",
        "twelveMRatioMovAvg = getDifferenceFeatures(GBR12mC,EUR12mC, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "## Inflation data (CPI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUCPuwpYOnn",
        "colab_type": "text"
      },
      "source": [
        "### CPI data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVanjbf-n1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch the inflation data for UK and EU from the DBNomics API\n",
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "# Convert the raw data into dictionaries\n",
        "ukCPIDict = {ukCPI.period.iloc[i]: ukCPI.value.iloc[i] for i in range(len(ukCPI))}\n",
        "euCPIDict = {euCPI.period.iloc[i]: euCPI.value.iloc[i] for i in range(len(euCPI))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhffkl2I-kY0",
        "colab_type": "text"
      },
      "source": [
        "### CPI data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxREJ3rFVj5",
        "colab_type": "code",
        "outputId": "3fc898e2-a3e4-4edb-a41b-646511661af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Method to clean a monthly dataset which is also used by IR\n",
        "def cleanMonthlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    # Loop over each FOREX datapoint as a reference\n",
        "    for index, row in forexDf.iterrows():\n",
        "\n",
        "        # Round the date of the FOREX value to the first day of the month\n",
        "        # So that it can be matched to the relevant inflation data\n",
        "        roundedDay = row['Date'].replace(day=1)\n",
        "        inflationValue = dataset.get(pd.Timestamp(roundedDay),1000000)\n",
        "\n",
        "        # If the value was not present then impute the data from the month either side\n",
        "        if(inflationValue==1000000):\n",
        "            clean = False\n",
        "            dateBelow = forexDf.Date.iloc[index-1]\n",
        "            dateAbove = forexDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataset.get(dateBelow, 1000000)\n",
        "            valueAbove = dataset.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            inflationValue = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = inflationValue\n",
        "        count = count + 1\n",
        "\n",
        "    # If the data did not need any artificially created then print message\n",
        "    if(clean==True):\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "# Clean both the UK and EU cpi datasets\n",
        "ukCPIDictC = cleanMonthlyData(ukCPIDict)\n",
        "euCPIDictC = cleanMonthlyData(euCPIDict)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T2dZu4RA6Sl",
        "colab_type": "text"
      },
      "source": [
        "### CPI feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = []\n",
        "ukCPIarr = []\n",
        "euCPIarr = []\n",
        "\n",
        "# Match the UK and EU inflation data with their dates\n",
        "for k,v in ukCPIDictC.items():\n",
        "\n",
        "    match = euCPIDictC.get(k, 0)\n",
        "    ukCPIarr.append(v)\n",
        "    euCPIarr.append(match)\n",
        "    dates.append(k)\n",
        "\n",
        "ukCPIarr = np.array(ukCPIarr, dtype=np.float)\n",
        "euCPIarr = np.array(euCPIarr, dtype=np.float)\n",
        "\n",
        "# Calculate their difference values\n",
        "ukEuCpiRatio = ukCPIarr - euCPIarr\n",
        "\n",
        "# Normalise the data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "# Create a dictionary of date : cpi value\n",
        "cpiDict = {dates[i]: ukEuCpiRatio[i] for i in range(len(dates))}\n",
        "\n",
        "cpiData = {'Date':dates, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "## International Reserves data (IR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeoJsXNEQA_m",
        "colab_type": "text"
      },
      "source": [
        "### IR data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXRsvqQIQMG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch UK and EU international reserve data from DBNomics\n",
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRDict = {ukIR.period.iloc[i]: ukIR.value.iloc[i] for i in range(len(ukIR))}\n",
        "euIRDict = {euIR.period.iloc[i]: euIR.value.iloc[i] for i in range(len(euIR))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj0vLPaBQFde",
        "colab_type": "text"
      },
      "source": [
        "### IR data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZbMYaFhQREG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4cab9d5e-ae15-424a-e3cc-900554be103f"
      },
      "source": [
        "# Clean both UK and EU IR datasets\n",
        "ukIRDictC = cleanMonthlyData(ukIRDict)\n",
        "euIRDictC = cleanMonthlyData(euIRDict)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCU1PotbQH3d",
        "colab_type": "text"
      },
      "source": [
        "### IR feature engineering\n",
        "\n",
        "Calcualte the ratio features between each inflation datapoint between UK and EU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IRdates = []\n",
        "ukIRarr = []\n",
        "euIRarr = []\n",
        "\n",
        "# Match the UK and EU IR data to their dates\n",
        "for k,v in ukIRDictC.items():\n",
        "\n",
        "    match = euIRDictC.get(k, 0)\n",
        "\n",
        "    ukIRarr.append(v)\n",
        "    euIRarr.append(match)\n",
        "    IRdates.append(k)\n",
        "\n",
        "# Get the ratio values between UK and EU IR values\n",
        "ukIRarr = np.array(ukIRarr, dtype=np.float)\n",
        "euIRarr = np.array(euIRarr, dtype=np.float)\n",
        "ukEuIRRatio = ukIRarr / euIRarr\n",
        "\n",
        "# Normalise the data\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {IRdates[i]: ukEuIRRatio[i] for i in range(len(IRdates))}\n",
        "\n",
        "irData = {'Date':IRdates, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Balance of Payments data (BOP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FpSuRNLR8Rb",
        "colab_type": "text"
      },
      "source": [
        "### BOP data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_2Bg9PSEym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch BOP data for UK andd EU from DBNomics\n",
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPDict = {ukBOP.period.iloc[i]: ukBOP.value.iloc[i] for i in range(len(ukBOP))}\n",
        "euBOPDict = {euBOP.period.iloc[i]: euBOP.value.iloc[i] for i in range(len(euBOP))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EsjDOHjR_Q-",
        "colab_type": "text"
      },
      "source": [
        "### BOP data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsVJ5XKGSmu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "35302aee-0cff-45aa-b5ea-b9e731e65dc6"
      },
      "source": [
        "# Function to clean quarterly data and match each FOREX value with a BOP value\n",
        "def cleanQuarterlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in forexDf.iterrows():\n",
        "        # For each FOREX datapoint, round its date to the first of the month \n",
        "        # then calculate the quarter that it is in\n",
        "\n",
        "        date = row['Date']\n",
        "        dateMonth = date.replace(day=1)\n",
        "        dateQuarter = date.quarter\n",
        "        \n",
        "        # Convert the date to be the first of the relevant quarter\n",
        "        switcher={\n",
        "            1:date.replace(month=1,day=1),\n",
        "            2:date.replace(month=4,day=1),\n",
        "            3:date.replace(month=7,day=1),\n",
        "            4:date.replace(month=10,day=1)\n",
        "        }\n",
        "\n",
        "        # Match the FOREX date with a BOP value\n",
        "        dateRoundedQuarter = switcher.get(dateQuarter)\n",
        "\n",
        "        value = dataset.get(dateRoundedQuarter,1000000)\n",
        "\n",
        "        # If the BOP value was not present then remove the FOREX value from the dataframe\n",
        "        # as it could not be imputed\n",
        "        if(value==1000000):\n",
        "            forexDf.drop([index], inplace=True)\n",
        "        else:\n",
        "            cleanedDataDict[row['Date']] = value\n",
        "\n",
        "\n",
        "    clean = True\n",
        "    for k,v in cleanedDataDict.items():\n",
        "        if (v==1000000):\n",
        "            clean = False;\n",
        "\n",
        "    if (clean==False):\n",
        "        print(\"Data is unlcean\")\n",
        "    else:\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "# Clean both the UK and EU BOP datasets\n",
        "ukBOPDictC = cleanQuarterlyData(ukBOPDict)\n",
        "euBOPDictC = cleanQuarterlyData(euBOPDict)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5T04eISB7G",
        "colab_type": "text"
      },
      "source": [
        "### BOP feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOPdates = []\n",
        "ukBOParr = []\n",
        "euBOParr = []\n",
        "\n",
        "# Match the UK and EU BOP based on their dates\n",
        "for k,v in ukBOPDictC.items():\n",
        "\n",
        "    match = euBOPDictC.get(k, 0)\n",
        "\n",
        "    ukBOParr.append(v)\n",
        "    euBOParr.append(match)\n",
        "    BOPdates.append(k)\n",
        "\n",
        "# Calculate their ratio values\n",
        "ukBOParr = np.array(ukBOParr, dtype=np.float)\n",
        "euBOParr = np.array(euBOParr, dtype=np.float)\n",
        "ukEuBOPRatio = ukBOParr / euBOParr\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {BOPdates[i]: ukEuBOPRatio[i] for i in range(len(BOPdates))}\n",
        "\n",
        "bopData = {'Date':BOPdates, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "## Creating full data matrix\n",
        "\n",
        "Creating a matrix which includes a value from all datasets for every date. This is then where all the data is taken for the training of the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOlDl_FgRI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the full dataframe columns\n",
        "completeDf = pd.DataFrame(columns=['Date','ForexAvg','ForexRaw','CPIRatio', 'IRRatio',\n",
        "                                   'BOPRatio', 'OvrLIBOR','OvrAvg','3mLIBOR', '3mAvg',\n",
        "                                   '6mLIBOR','6mAvg','12mLIBOR', '12mAvg'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        " \n",
        " # Loop over each FOREX value as a reference to get all other datapoints\n",
        "for index, row in forexDf.iterrows():\n",
        "\n",
        "    date = row['Date']\n",
        "    forex = row['Value']\n",
        "\n",
        "    forexRaw = forexRawDict.get(date, 0)\n",
        "    \n",
        "    # Get the value from all datasets with the relevant date\n",
        "    cpi = cpiDict.get(date, 0)\n",
        "    ir = irDict.get(date,0)\n",
        "    bop = bopDict.get(date,0)\n",
        "    ovr = ovrRatio.get(date, 0)\n",
        "    ovrAvg = ovrRatioMovAvg.get(date, 0)\n",
        "    i3month = threeMRatio.get(date, 0)\n",
        "    i3monthAvg = threeMRatioMovAvg.get(date, 0)\n",
        "    i6month = sixMRatio.get(date, 0)\n",
        "    i6monthAvg = sixMRatioMovAvg.get(date, 0)\n",
        "    i12month = twelveMRatio.get(date, 0)\n",
        "    i12monthAvg = twelveMRatioMovAvg.get(date, 0)\n",
        "\n",
        "    # Append the data as a row in the dataframe\n",
        "    completeDf = completeDf.append({'Date':date,\n",
        "                            'ForexAvg':forex,\n",
        "                            'ForexRaw':forexRaw,\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovr,\n",
        "                            'OvrAvg':ovrAvg,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '3mAvg':i3monthAvg,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '6mAvg':i6monthAvg,\n",
        "                            '12mLIBOR': i12month,\n",
        "                            '12mAvg':i12monthAvg},\n",
        "                            ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9gVEULcO0zD",
        "colab_type": "text"
      },
      "source": [
        "# Variable Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpiLy6YcO5-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "d8bc2d07-c77e-464d-883c-b0f759c78d50"
      },
      "source": [
        "variables = ['CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR']\n",
        "\n",
        "forex = completeDf['ForexAvg'].tolist()\n",
        "correlations = []\n",
        "\n",
        "# For every variable in variables, it calculates the Pearsons correlation between\n",
        "# FOREX and the variable\n",
        "for x in range(len(variables)):\n",
        "    \n",
        "    column = completeDf[variables[x]].tolist()\n",
        "\n",
        "    r = np.corrcoef(forex, column)\n",
        "\n",
        "    correlations.append(r[0,1])\n",
        "\n",
        "# These correlations are then displayed on a graph\n",
        "y_pos = np.arange(0,14,2)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(y_pos, correlations, align='center', alpha=0.5, color=(0.0, 0.0, 0.0, 1))\n",
        "plt.xticks(y_pos, variables)\n",
        "plt.ylabel('Usage')\n",
        "plt.title('Correlations')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZv8h4QoUelO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "02d2abb4-2ecb-4bef-d04e-7c44ff6ca3e0"
      },
      "source": [
        "# This does the same as above except it calculates the correlation between all\n",
        "# pairs of variables\n",
        "corrDf = completeDf[['ForexAvg','CPIRatio', 'IRRatio',\n",
        "                    'BOPRatio', 'OvrAvg', '3mAvg',\n",
        "                    '6mAvg', '12mAvg']]\n",
        "\n",
        "# The correlations are displayed as a matrix\n",
        "corrMatrix = corrDf.corr()\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "plt.gcf().subplots_adjust(bottom=0.20)\n",
        "plt.savefig('CorrelationMatrix3.png')\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMlG3PXw4dX",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSvQDGXwFVJ",
        "colab_type": "text"
      },
      "source": [
        "## Data setup\n",
        "\n",
        "Contains all of the parameters for the models to be trained. This is where to control what data is getting trained etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4_5GXRVwHR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters for the neural networks\n",
        "EPOCHS = 10\n",
        "VALIDATION_STEPS = 50\n",
        "BATCH_SIZE = 30\n",
        "FOLDS = 5\n",
        "\n",
        "# Paramters for the splitting of data\n",
        "# HISTORY_STEPS is the number of past months to be included\n",
        "\n",
        "HISTORY_STEPS = 24\n",
        "# FUTURE_STEPS is the number of months in advance to be predicted\n",
        "FUTURE_STEPS = 6\n",
        "\n",
        "# Changing the value in target will decide which data the neural networks are attempting to predict\n",
        "target = ['ForexAvg']\n",
        "# Features is the data that will be used as inputs to the models to predict the target\n",
        "# This array was changed depending on the experiment\n",
        "features = ['ForexAvg']\n",
        "\n",
        "# Gets the relevant data from the main data frame\n",
        "dataSet = completeDf[features]\n",
        "dataSet = dataSet.values\n",
        "target = completeDf[target]\n",
        "target = target.values\n",
        "\n",
        "# Calculates the size of the folds and then determines the locations of the fold splits\n",
        "fold_steps = math.floor(len(dataSet) / FOLDS)\n",
        "fold_locations = []\n",
        "results = []\n",
        "\n",
        "for x in range(0,len(dataSet), fold_steps):\n",
        "    fold_locations.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4r-1IZnpzKj",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzFM320p1Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to retreive the indicies of the backdated datapoints\n",
        "# it will go the number of steps passed to it in monthly increments\n",
        "def getIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex\n",
        "\n",
        "    # Starting from the currentIndex parameter it will go back\n",
        "    # 22 for 3 months and then 21 for one\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index - 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index - 22\n",
        "\n",
        "    # Reverse this list to get it moving forward again\n",
        "    indices = list(reversed(indices))\n",
        "\n",
        "    return indices\n",
        "\n",
        "# Function to split the data into features and labels for the single-step models\n",
        "def singleStepDataSplit(dataset, target, startIndex, endIndex,\n",
        "                steps, future_steps):  \n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # Determine the start and end point using the start and end index passed to it\n",
        "    history_size = 22 * steps\n",
        "    max_index = 22 * future_steps\n",
        "    target_size = round(21.75 * future_steps)\n",
        "    startIndex = startIndex + history_size\n",
        "\n",
        "    # If endIndex is none then use the full dataset\n",
        "    if endIndex is None:\n",
        "        endIndex = len(dataset) - max_index\n",
        "\n",
        "    # Loop over each index, retreive the past indices to get the past data values\n",
        "    # as the features, and go forward the size of the futureStep\n",
        "    for i in range(startIndex, endIndex):\n",
        "        dataIndices = getIndices(i,steps)\n",
        "        features.append(dataset[dataIndices])\n",
        "        labels.append(target[i+target_size])\n",
        "\n",
        "    # Return an array of features and their respective label\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Function to retreive the indicies of the future values\n",
        "def getFutureIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "    index = currentIndex + 22\n",
        "\n",
        "    # Starting from current index + one month, calculate indicies\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index + 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index + 22\n",
        "\n",
        "    return indices\n",
        "\n",
        "# Function to split the data into features and labels for the multi-step models\n",
        "def multiStepDataSplit(dataset, target, start_index, end_index, steps, future_steps):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "    target_size = 22 * future_steps\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    # For each index, retreive the past features and future labels\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = getIndices(i,steps)\n",
        "        features.append(dataset[indices])\n",
        "        indiciesL = getFutureIndices(i, future_steps)\n",
        "        labels.append(target[indiciesL])\n",
        "\n",
        "    return np.array(features), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nd5E-y_o1HY",
        "colab_type": "text"
      },
      "source": [
        "## Single-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseG60kHb2hB",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYFUp6Mb98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build single-step model consisting of one layer of 32 LSTM cells into 1 dense cell\n",
        "def singleStepLSTM():\n",
        "    singleStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(32, input_shape=(HISTORY_STEPS, len(features))),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    # Use the 'adam' optmizer and print the mse as the loss values\n",
        "    singleStepLSTMModel.compile(optimizer='adam', loss='mse')\n",
        "    return singleStepLSTMModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJqrxLV9xCEB",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmajAmS4xEs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fffeb43d-4aec-467f-daf9-96c313017251"
      },
      "source": [
        "# Function to train a set of models using history_steps as the number of time lags\n",
        "# and future_step being the prediction horizon being predicted. Produces a model\n",
        "# for each fold\n",
        "def trainModel(history_steps, future_step):\n",
        "\n",
        "    models = []\n",
        "\n",
        "    # For each fold split the data and train the model, the first fold location is 0\n",
        "    # so start from the second split\n",
        "    for x in range(1, FOLDS):\n",
        "\n",
        "        model = singleStepLSTM()\n",
        "\n",
        "        # This is the index of the data that the model will train up to\n",
        "        valIndex = fold_locations[x]\n",
        "        \n",
        "        # end index is the index the model will use to validate the data on\n",
        "        if (x==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[x+1]\n",
        "\n",
        "        # Split the data into the features and labels \n",
        "        xTrain, yTrain = singleStepDataSplit(dataSet, target, 0, valIndex, history_steps, future_step)\n",
        "        xVal, yVal = singleStepDataSplit(dataSet, target, valIndex, endIndex, history_steps, future_step)\n",
        "\n",
        "        # Batch the data into the correct format to be used by the TensorFlow models\n",
        "        dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "        dataTrain = dataTrain.cache().batch(BATCH_SIZE).repeat()\n",
        "        dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "        dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        print(\"--------------------- Model validated on fold \", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "        # Calculate the required number of steps per epoch for the size of the dataset\n",
        "        # to ensure the whole dataset is used for an epoch\n",
        "        epochSteps = math.floor(len(xTrain)/BATCH_SIZE)\n",
        "\n",
        "        # Train the model\n",
        "        result = model.fit(dataTrain, epochs=EPOCHS, steps_per_epoch=epochSteps,\n",
        "                            validation_data=dataVal, validation_steps=50)\n",
        "\n",
        "        # Save the trained model to later be tested\n",
        "        models.append(model)\n",
        "\n",
        "    # Return the model for each fold, 4 models\n",
        "    return models\n",
        "\n",
        "# Function to train all folds models for each of the 6 prediction horizons for one dataset combination\n",
        "def createModelsForAllSteps():\n",
        "\n",
        "    allModels = []\n",
        "\n",
        "    for i in range(1,FUTURE_STEPS+1):\n",
        "\n",
        "        print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month\", \"%d/%d &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\" % (i, FUTURE_STEPS))\n",
        "\n",
        "        models = trainModel(HISTORY_STEPS, i)\n",
        "        allModels.append(models)\n",
        "\n",
        "    # Return array of all models. Shape of (6, 4)\n",
        "    return allModels\n",
        "\n",
        "# Save all models created from the single-step training\n",
        "allModels = createModelsForAllSteps()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 1/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 49ms/step - loss: 0.7527 - val_loss: 0.3601\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0774 - val_loss: 0.3895\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.1024 - val_loss: 0.3949\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0654 - val_loss: 0.3508\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0550 - val_loss: 0.3573\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0558 - val_loss: 0.3741\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0565 - val_loss: 0.3826\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0563 - val_loss: 0.3894\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0537 - val_loss: 0.3989\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0523 - val_loss: 0.4078\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.2630 - val_loss: 0.4308\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1948 - val_loss: 0.3468\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1320 - val_loss: 0.3010\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1098 - val_loss: 0.2676\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1003 - val_loss: 0.2298\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0949 - val_loss: 0.2073\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0877 - val_loss: 0.1744\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0817 - val_loss: 0.1626\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0730 - val_loss: 0.1274\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0648 - val_loss: 0.1334\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3906 - val_loss: 0.1990\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1371 - val_loss: 0.1541\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.1240 - val_loss: 0.1394\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0901 - val_loss: 0.1231\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.0786 - val_loss: 0.1093\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0720 - val_loss: 0.0997\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0667 - val_loss: 0.0922\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.0626 - val_loss: 0.0861\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0590 - val_loss: 0.0805\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0560 - val_loss: 0.0754\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.2355 - val_loss: 0.1050\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1274 - val_loss: 0.0730\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.0894 - val_loss: 0.0646\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0734 - val_loss: 0.0597\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0651 - val_loss: 0.0556\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0593 - val_loss: 0.0509\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0544 - val_loss: 0.0461\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0508 - val_loss: 0.0417\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0473 - val_loss: 0.0377\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0433 - val_loss: 0.0342\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 2/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 0.4820 - val_loss: 0.2785\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0598 - val_loss: 0.4114\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1357 - val_loss: 0.3173\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0666 - val_loss: 0.3226\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0611 - val_loss: 0.3505\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.0627 - val_loss: 0.3577\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0552 - val_loss: 0.3659\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0577 - val_loss: 0.3853\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0563 - val_loss: 0.4076\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0525 - val_loss: 0.4300\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.2732 - val_loss: 0.3193\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1956 - val_loss: 0.2440\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1388 - val_loss: 0.2089\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1210 - val_loss: 0.1799\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1040 - val_loss: 0.1545\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1008 - val_loss: 0.1347\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0935 - val_loss: 0.1177\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0909 - val_loss: 0.1049\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0859 - val_loss: 0.0942\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.0794 - val_loss: 0.0867\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3809 - val_loss: 0.2035\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1789 - val_loss: 0.1924\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1588 - val_loss: 0.1801\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1239 - val_loss: 0.1645\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1087 - val_loss: 0.1546\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1009 - val_loss: 0.1465\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0962 - val_loss: 0.1402\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0921 - val_loss: 0.1349\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0887 - val_loss: 0.1297\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.0851 - val_loss: 0.1246\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 2s 14ms/step - loss: 0.2732 - val_loss: 0.1503\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1735 - val_loss: 0.0902\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1279 - val_loss: 0.0769\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1090 - val_loss: 0.0729\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.0990 - val_loss: 0.0695\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0928 - val_loss: 0.0650\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.0880 - val_loss: 0.0596\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0833 - val_loss: 0.0541\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0800 - val_loss: 0.0491\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.0758 - val_loss: 0.0447\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 3/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 44ms/step - loss: 0.5381 - val_loss: 0.2756\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0522 - val_loss: 0.5926\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 22ms/step - loss: 0.1949 - val_loss: 0.3324\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.0843 - val_loss: 0.3318\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0625 - val_loss: 0.3770\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0680 - val_loss: 0.3880\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0646 - val_loss: 0.3871\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0625 - val_loss: 0.4009\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0657 - val_loss: 0.4225\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0623 - val_loss: 0.4444\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.3017 - val_loss: 0.3762\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2570 - val_loss: 0.2862\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1831 - val_loss: 0.2420\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1639 - val_loss: 0.2079\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1474 - val_loss: 0.1795\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1337 - val_loss: 0.1562\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1347 - val_loss: 0.1373\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1287 - val_loss: 0.1218\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1267 - val_loss: 0.1098\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 0.1215 - val_loss: 0.0999\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3619 - val_loss: 0.2665\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2127 - val_loss: 0.2683\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1875 - val_loss: 0.2521\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1494 - val_loss: 0.2385\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1370 - val_loss: 0.2253\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1272 - val_loss: 0.2171\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1215 - val_loss: 0.2093\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1170 - val_loss: 0.2006\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1125 - val_loss: 0.1913\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1078 - val_loss: 0.1833\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.2572 - val_loss: 0.1650\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1930 - val_loss: 0.1003\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1453 - val_loss: 0.0891\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1301 - val_loss: 0.0853\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1225 - val_loss: 0.0836\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1166 - val_loss: 0.0814\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1124 - val_loss: 0.0781\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1082 - val_loss: 0.0742\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1046 - val_loss: 0.0703\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1012 - val_loss: 0.0665\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 4/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 43ms/step - loss: 0.1186 - val_loss: 0.7461\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1791 - val_loss: 0.3717\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0856 - val_loss: 0.3924\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0669 - val_loss: 0.4525\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.0725 - val_loss: 0.4421\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0569 - val_loss: 0.4400\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0535 - val_loss: 0.4569\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0520 - val_loss: 0.4731\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0515 - val_loss: 0.4960\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0530 - val_loss: 0.5298\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 0.2669 - val_loss: 0.2921\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2945 - val_loss: 0.2048\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2126 - val_loss: 0.1765\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1931 - val_loss: 0.1569\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1732 - val_loss: 0.1409\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1573 - val_loss: 0.1285\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1487 - val_loss: 0.1186\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1506 - val_loss: 0.1109\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1469 - val_loss: 0.1049\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.1468 - val_loss: 0.1001\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4118 - val_loss: 0.2971\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2575 - val_loss: 0.3502\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2182 - val_loss: 0.3351\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1827 - val_loss: 0.3185\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1691 - val_loss: 0.3049\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1595 - val_loss: 0.2950\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1509 - val_loss: 0.2872\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.1461 - val_loss: 0.2818\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.1414 - val_loss: 0.2747\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.1371 - val_loss: 0.2656\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.3662 - val_loss: 0.1832\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.2452 - val_loss: 0.1201\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1932 - val_loss: 0.1020\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1706 - val_loss: 0.0920\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 1s 13ms/step - loss: 0.1596 - val_loss: 0.0884\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1521 - val_loss: 0.0858\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1464 - val_loss: 0.0836\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1422 - val_loss: 0.0807\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1369 - val_loss: 0.0772\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1332 - val_loss: 0.0733\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 5/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.5349 - val_loss: 0.5436\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0464 - val_loss: 1.0305\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.1123 - val_loss: 0.7331\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0623 - val_loss: 0.7426\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 23ms/step - loss: 0.0497 - val_loss: 0.8149\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0487 - val_loss: 0.8134\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0404 - val_loss: 0.8152\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 0.0404 - val_loss: 0.8386\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0385 - val_loss: 0.8600\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0399 - val_loss: 0.8886\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.1873 - val_loss: 0.2081\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.3402 - val_loss: 0.1455\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2824 - val_loss: 0.1142\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.2428 - val_loss: 0.1014\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.2267 - val_loss: 0.0940\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.2113 - val_loss: 0.0905\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1956 - val_loss: 0.0914\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1939 - val_loss: 0.0961\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1925 - val_loss: 0.1041\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.1928 - val_loss: 0.1151\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3181 - val_loss: 0.3795\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2587 - val_loss: 0.3975\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.2350 - val_loss: 0.3873\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1994 - val_loss: 0.3752\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.1871 - val_loss: 0.3645\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1802 - val_loss: 0.3566\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1728 - val_loss: 0.3502\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1666 - val_loss: 0.3449\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1628 - val_loss: 0.3396\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1584 - val_loss: 0.3324\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.2512 - val_loss: 0.2141\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2757 - val_loss: 0.1407\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2372 - val_loss: 0.1040\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2055 - val_loss: 0.0961\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1943 - val_loss: 0.0919\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1881 - val_loss: 0.0890\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1823 - val_loss: 0.0861\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.1784 - val_loss: 0.0828\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1741 - val_loss: 0.0786\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.1674 - val_loss: 0.0737\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 6/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 46ms/step - loss: 0.4392 - val_loss: 0.7434\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.0516 - val_loss: 1.1217\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 24ms/step - loss: 0.0892 - val_loss: 0.9087\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0591 - val_loss: 0.9225\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0498 - val_loss: 0.9922\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0490 - val_loss: 0.9959\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0382 - val_loss: 1.0028\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0353 - val_loss: 1.0309\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0360 - val_loss: 1.0611\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 21ms/step - loss: 0.0331 - val_loss: 1.0984\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 0.3041 - val_loss: 0.2962\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.4093 - val_loss: 0.2000\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.3374 - val_loss: 0.1616\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.3203 - val_loss: 0.1406\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2961 - val_loss: 0.1247\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2786 - val_loss: 0.1149\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.2616 - val_loss: 0.1101\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2471 - val_loss: 0.1103\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 0.2491 - val_loss: 0.1153\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 0.2445 - val_loss: 0.1250\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.6601 - val_loss: 0.3472\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4177 - val_loss: 0.5309\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.3224 - val_loss: 0.5300\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2714 - val_loss: 0.5185\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2435 - val_loss: 0.5036\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2281 - val_loss: 0.4918\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2168 - val_loss: 0.4811\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.2065 - val_loss: 0.4726\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1989 - val_loss: 0.4654\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.1921 - val_loss: 0.4584\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 2s 15ms/step - loss: 0.3815 - val_loss: 0.2893\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.3339 - val_loss: 0.1760\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2761 - val_loss: 0.1373\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2536 - val_loss: 0.1162\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 1s 11ms/step - loss: 0.2384 - val_loss: 0.1039\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2294 - val_loss: 0.0955\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2231 - val_loss: 0.0892\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2158 - val_loss: 0.0840\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2119 - val_loss: 0.0794\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 1s 12ms/step - loss: 0.2048 - val_loss: 0.0749\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpsQrU84mv0",
        "colab_type": "text"
      },
      "source": [
        "### Single-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEgXTi80WseN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d155a080-01e3-4ea6-8684-1b766bb83ac7"
      },
      "source": [
        "allMses = []\n",
        "allClassifications = []\n",
        "bestGuessClassifications = []\n",
        "relaxedGuessClassifications = []\n",
        "\n",
        "# Function to calculate 2 metrics for one model against the test data supplied\n",
        "def singleStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "    correctDirection = 0\n",
        "\n",
        "    # Calculate the MSE of the model using the unseen test data features and labels\n",
        "    mse = model.evaluate(xTest,yTest)\n",
        "\n",
        "    # For each test datapoint calculate the direction classifcation\n",
        "    for x in range(len(xTest)):\n",
        "        # Get the most recent FOREX value, the prediction based on the features and the actual value\n",
        "        current = xTest[x][-1][0]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        prediction = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        # If they moved in the same direction then +1 to the correct count\n",
        "        if((current > prediction) == (current > future)):\n",
        "                correctDirection = correctDirection + 1\n",
        "\n",
        "\n",
        "    directionClass = correctDirection / len(xTest)\n",
        "    mses.append(mse)\n",
        "    classifications.append(directionClass)\n",
        "\n",
        "    return mses, classifications\n",
        "\n",
        "# Function to test all single-step models on the first two metrics\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    # Test the model for each fold\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        # Get the start and end locations to get the test data for each fold\n",
        "        # this would be the fold after the one they were trained on\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        # Split the data into features and labels to do the testing\n",
        "        xTest, yTest = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "        # Do the tests\n",
        "        mses,classifications = singleStepModelTests(models[i-1], xTest, yTest)\n",
        "\n",
        "        modelMses.append(mses)\n",
        "        modelClassifications.append(classifications)\n",
        "\n",
        "        meanMse = np.mean(modelMses)\n",
        "        meanClass = np.mean(modelClassifications)\n",
        "\n",
        "    return modelMses, modelClassifications\n",
        "\n",
        "# Function to test a complete set of models to test the guessing ability metric for a particular fold\n",
        "def bestGuessTests(models, fold):\n",
        "\n",
        "    valIndex = fold_locations[fold+1]\n",
        "    \n",
        "    if (fold==FOLDS-2):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[fold+2]\n",
        "\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    # Split the data using the multi-step method as we want to get the following 6 values so a set of single-step\n",
        "    # models can be tested\n",
        "    xTest, yTest = multiStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    # For each feature vector, test the guessing ability\n",
        "    for datapoint in range(len(xTest)):\n",
        "\n",
        "    \n",
        "        past = tf.constant([xTest[datapoint]])\n",
        "        future = yTest[datapoint]\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        # Get the prediction from each of the 6 models\n",
        "        for j in range(FUTURE_STEPS):\n",
        "\n",
        "            prediction = models[j].predict(past)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        # Get the index of the highest values\n",
        "        actualMax = np.argmax(future)\n",
        "        predictedMax = np.argmax(predictions)\n",
        "\n",
        "        # Get the index of the 2nd highest value\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        # Test if the models correctly predicted the FOREX best month or 2nd best\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "    \n",
        "    bestMonthClass = correctMax / len(xTest)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xTest)\n",
        "\n",
        "    return bestMonthClass, bestMonthRelaxedClass\n",
        "\n",
        "# Function to run the guessing ability metric for all models\n",
        "def runBestGuessTests(allModels):\n",
        "\n",
        "    foldPerformances = []\n",
        "    relaxedFoldperformances = []\n",
        "\n",
        "    # For each fold, test the set of single-step models for their guessing ability \n",
        "    for i in range(len(allModels[0])):\n",
        "\n",
        "        foldModels = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "            foldModels.append(allModels[j][i])\n",
        "\n",
        "        # Get the fold performance for both the best and relaxed guesses\n",
        "        foldPerformance, relaxedFoldperformance = bestGuessTests(foldModels, i)\n",
        "\n",
        "        foldPerformances.append(foldPerformance)\n",
        "        relaxedFoldperformances.append(relaxedFoldperformance)\n",
        "\n",
        "    return foldPerformances, relaxedFoldperformances\n",
        "\n",
        "# Function to run all tests for all single-step models\n",
        "def singleStepExperiments():\n",
        "    \n",
        "    for modelsForOneStep in allModels:\n",
        "\n",
        "        modelMses, modelClassifications = runModels(modelsForOneStep)\n",
        "        allMses.append(modelMses)\n",
        "        allClassifications.append(modelClassifications)\n",
        "\n",
        "    bestGuess, relaxedGuess = runBestGuessTests(allModels)\n",
        "\n",
        "    bestGuessClassifications.append(bestGuess)\n",
        "    relaxedGuessClassifications.append(relaxedGuess)\n",
        "\n",
        "singleStepExperiments()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 3ms/step - loss: 1.2104\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1322\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4532\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0358\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.1475\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1094\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4477\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0375\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.0914\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1102\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4635\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0457\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.0353\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4546\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0557\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.1504\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1463\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4216\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0676\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.1993\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1304\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.4430\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwgG0U6-gUrZ",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DGg4vGuUmRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple function to display the results from the single-step models\n",
        "def printResults(mses,directionClass,bestClass):\n",
        "\n",
        "    for i in range(FUTURE_STEPS):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(mses[i]))\n",
        "        print(\"Dir: \" + str(directionClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uwx3VvAnnRN",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TYzy6YXnpjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions to display real vs predicted values on a graph\n",
        "def create_time_steps(length,steps):\n",
        "    return list(np.arange(-length, 0,step=steps))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\n",
        "    marker = ['.-', 'rx', 'go']\n",
        "    time_steps = create_time_steps(TIME_LAGS,STEP)\n",
        "\n",
        "    if delta:\n",
        "        future = delta\n",
        "    else:\n",
        "        future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "        if i:\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                    label=labels[i])\n",
        "        else:\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1syGFxznuVLK",
        "colab_type": "text"
      },
      "source": [
        "## Multi-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHJMXYsuZWp",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0P_sbFRuhMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the multi-step model consisting of two layers of LSTM cells\n",
        "def multiStepLSTM():\n",
        "    multiStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(units=32, return_sequences=True, input_shape = (HISTORY_STEPS, len(features))),\n",
        "        layers.LSTM(16, activation='relu'),\n",
        "        layers.Dense(FUTURE_STEPS)\n",
        "    ])\n",
        "\n",
        "    multiStepLSTMModel.compile(optimizer='adam', loss='mse')\n",
        "    return multiStepLSTMModel\n",
        "\n",
        "multiStepModel = multiStepLSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IwcoGcu3mP",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UAjl2pn0eT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "581a2728-fb3a-4bc3-895f-3380a937a697"
      },
      "source": [
        "models = []\n",
        "results = []\n",
        "dataTrainMulti = []\n",
        "\n",
        "# Train a model for each time period fold \n",
        "for x in range(1, FOLDS):\n",
        "\n",
        "    # Get the start and end indices of the data to be traied on\n",
        "    valIndex = fold_locations[x]\n",
        "\n",
        "    multiStepModel = multiStepLSTM()\n",
        "    \n",
        "    if (x==FOLDS-1):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[x+1]\n",
        "\n",
        "    # Get the features and labels for both training and validation data\n",
        "    xTrainMulti, yTrainMulti = multiStepDataSplit(dataSet, target, 0, valIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "    xValMulti, yValMulti = multiStepDataSplit(dataSet, target, valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    # Batch data into the correct format\n",
        "    dataTrainMulti = tf.data.Dataset.from_tensor_slices((xTrainMulti, yTrainMulti))\n",
        "    dataTrainMulti = dataTrainMulti.cache().batch(BATCH_SIZE).repeat()\n",
        "    dataValMulti = tf.data.Dataset.from_tensor_slices((xValMulti, yValMulti))\n",
        "    dataValMulti = dataValMulti.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    print(\"--------------------- Model\", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "    steps_per = math.floor(len(xTrainMulti)/BATCH_SIZE)\n",
        "\n",
        "    # Train the models\n",
        "    result = multiStepModel.fit(dataTrainMulti, epochs=EPOCHS, steps_per_epoch=steps_per,\n",
        "                        validation_data=dataValMulti, validation_steps=50)\n",
        "    \n",
        "    models.append(multiStepModel)\n",
        "    results.append(result)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------- Model 1/4 --------------------------\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 67ms/step - loss: 0.8047 - val_loss: 0.5245\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.5945 - val_loss: 0.5395\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 0.4803 - val_loss: 0.4172\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.2824 - val_loss: 0.4616\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.2103 - val_loss: 0.4888\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 0.1111 - val_loss: 0.5469\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.0811 - val_loss: 0.5472\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 0.0624 - val_loss: 0.6072\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.0554 - val_loss: 0.6332\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 36ms/step - loss: 0.0500 - val_loss: 0.6573\n",
            "--------------------- Model 2/4 --------------------------\n",
            "Epoch 1/10\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 0.4596 - val_loss: 0.7290\n",
            "Epoch 2/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.4183 - val_loss: 0.7603\n",
            "Epoch 3/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.3509 - val_loss: 0.7819\n",
            "Epoch 4/10\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 0.2868 - val_loss: 0.7865\n",
            "Epoch 5/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2924 - val_loss: 0.7959\n",
            "Epoch 6/10\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 0.2632 - val_loss: 0.7947\n",
            "Epoch 7/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2715 - val_loss: 0.7998\n",
            "Epoch 8/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2600 - val_loss: 0.7973\n",
            "Epoch 9/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2638 - val_loss: 0.7886\n",
            "Epoch 10/10\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 0.2546 - val_loss: 0.7509\n",
            "--------------------- Model 3/4 --------------------------\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 2s 27ms/step - loss: 0.4885 - val_loss: 0.2821\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4369 - val_loss: 0.3764\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4495 - val_loss: 0.4606\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.2636 - val_loss: 0.4739\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.3073 - val_loss: 0.4942\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.2500 - val_loss: 0.3843\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.2529 - val_loss: 0.4120\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.1715 - val_loss: 0.5063\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.2004 - val_loss: 0.4468\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.1694 - val_loss: 0.3559\n",
            "--------------------- Model 4/4 --------------------------\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.5057 - val_loss: 0.5428\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 2s 20ms/step - loss: 0.4058 - val_loss: 0.4321\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 2s 20ms/step - loss: 0.3731 - val_loss: 0.3606\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 2s 20ms/step - loss: 0.3443 - val_loss: 0.3018\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 2s 20ms/step - loss: 0.2512 - val_loss: 0.2408\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 2s 20ms/step - loss: 0.2508 - val_loss: 0.2577\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 2s 21ms/step - loss: 0.2179 - val_loss: 0.2066\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 2s 21ms/step - loss: 0.1987 - val_loss: 0.2099\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 2s 21ms/step - loss: 0.1808 - val_loss: 0.1895\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 2s 20ms/step - loss: 0.1696 - val_loss: 0.1675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Uaxl7U4rEH",
        "colab_type": "text"
      },
      "source": [
        "### Multi-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMsesMulti = []\n",
        "allClassificationsMulti = []\n",
        "bestGuessClassificationsMulti = []\n",
        "relaxedGuessClassificationsMulti = []\n",
        "\n",
        "# Function to test a single model all three metrics\n",
        "def multiStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    # Array of numbers, one for each month, to be used to seperate the performance for each month\n",
        "    correctDirection = [0,0,0,0,0,0]\n",
        "    totalSquaredError = [0,0,0,0,0,0]\n",
        "\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "\n",
        "    # For each test datapoint, run all tests\n",
        "    for x in range(noDatapoints):\n",
        "        # Get the current (most recent) FOREX value\n",
        "        current = xTest[x][-1][0]\n",
        "        # Get the past values that are passed into the model\n",
        "        past = tf.constant([xTest[x]])\n",
        "        # Make the predictions\n",
        "        predictions = model.predict(past)[0]\n",
        "        # The actual future values\n",
        "        future = yTest[x]\n",
        "\n",
        "        # Calculate if the predicted best month or 2nd best month\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        temp = future[actualMax]\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "        future[actualMax]=temp\n",
        "\n",
        "        # Calculate MSE value for each months predictions \n",
        "        for y in range(FUTURE_STEPS):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    # Calculate average mse and direction classifcation rates\n",
        "    for x in range(FUTURE_STEPS):\n",
        "        mse = totalSquaredError[x] / noDatapoints\n",
        "        mses.append(mse)\n",
        "\n",
        "    for x in range(FUTURE_STEPS):\n",
        "        monthClassification = correctDirection[x] / noDatapoints\n",
        "        classifications.append(monthClassification)\n",
        "\n",
        "    bestMonthClass = correctMax / noDatapoints\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / noDatapoints\n",
        "\n",
        "    allMsesMulti.append(mses)\n",
        "    allClassificationsMulti.append(classifications)\n",
        "    bestGuessClassificationsMulti.append(bestMonthClass)\n",
        "    relaxedGuessClassificationsMulti.append(bestMonthRelaxedClass)\n",
        "\n",
        "\n",
        "# Function to run tests on all multi-step models\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTestMulti, yTestMulti = multiStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        # Run tests for fold model\n",
        "        multiStepModelTests(models[i-1], xTestMulti, yTestMulti)\n",
        "\n",
        "runModels(models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GoqA1iO8TQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape results\n",
        "allMsesMulti = list(map(list, zip(*allMsesMulti)))\n",
        "allClassificationsMulti = list(map(list, zip(*allClassificationsMulti)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSYYPtFgP4i",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "Small code when wanting to see the results before being exported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2SBad6gSMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple function to display results\n",
        "def printResults(monthAverageMses,monthAverageClass,bestClass):\n",
        "\n",
        "    for i in range(len(monthAverageMses)):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(monthAverageMses[i]))\n",
        "        print(\"Dir: \" + str(monthAverageClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tii3SZcOw1qb",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR0uE5bfw5uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to be used if wanting visualisation of predictions vs real values\n",
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(TIME_LAGS,STEP)\n",
        "  num_out = len(true_future) * FUTURE_STEP\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
        "  plt.plot(np.arange(num_out, step=FUTURE_STEP), np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out,step=FUTURE_STEP), np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJ7pc31UP8k",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Results\n",
        "\n",
        "This code was for the exporting of all results into a single Google sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKanocQUSfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "612e8345-e6b3-4233-8009-668cce5a92e4"
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "import pygsheets\n",
        "\n",
        "# Authenticate access to the Google sheet\n",
        "auth.authenticate_user()\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "# Open and create a new worksheet\n",
        "sh = gc.open('Results')\n",
        "sh.add_worksheet('FOREX') \n",
        "\n",
        "wk1 = sh[0]\n",
        "\n",
        "shiftSize = FUTURE_STEPS + 5\n",
        "\n",
        "# Insert the titles for each of the results to be added so a human can read it\n",
        "titles = ['SINGLE_STEP','MSE(Fold1)','MSE(Fold2)','MSE(Fold3)','MSE(Fold4)','MSE(avg)',\n",
        "          'Dir(Fold1)','Dir(Fold2)','Dir(Fold3)','Dir(Fold4)','Dir(avg)']\n",
        "\n",
        "wk1.insert_rows(row = 0, number = 0, values = titles) \n",
        "\n",
        "mseAvgsSingle = []\n",
        "dirAvgsSingle = []\n",
        "bestSingle = []\n",
        "relaxedSingle = []\n",
        "\n",
        "mseAvgsMulti = []\n",
        "dirAvgsMulti = []\n",
        "bestMulti = []\n",
        "relaxedMultti = []\n",
        "\n",
        "# Add the MSE and direction results for the single-step models\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    # Get the 4 MSE fold results for the month\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMses[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allMses[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsSingle.append(mean)\n",
        "\n",
        "    # Ge the 4 direction results for the month\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassifications[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allClassifications[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsSingle.append(mean)\n",
        "\n",
        "    # Insert month results\n",
        "    wk1.insert_rows(row = step+1, number = 1, values = row)\n",
        "\n",
        "\n",
        "# Add the titles again for the multi-step results\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "# Add the best guess single-step results\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassifications[0])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestSingle = mean\n",
        "\n",
        "# Add the relaxed guess single-step results\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassifications[0])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedSingle = mean\n",
        "wk1.insert_rows(row = FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "\n",
        "titles[0] = 'MULTI-STEP'\n",
        "# Insert titles for multi-step test results\n",
        "wk1.insert_rows(row = shiftSize, number = 0, values = titles)\n",
        "\n",
        "# Add the MSE and direction results for each month\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    # Add the fold MSE results and average\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMsesMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allMsesMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsMulti.append(mean)\n",
        "\n",
        "    # Add the fold direction results to the row and average\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassificationsMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allClassificationsMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsMulti.append(mean)\n",
        "\n",
        "    # Insert row\n",
        "    wk1.insert_rows(row = shiftSize+step+1, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "# Get the best guess classification results\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "# Average the resuls and add to the row to be added\n",
        "arr = np.asarray(bestGuessClassificationsMulti)\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestMulti = mean\n",
        "\n",
        "# Get the relaxed guess classification results\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "# Average the results and add to the row to be added\n",
        "arr = np.asarray(relaxedGuessClassificationsMulti)\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedMulti = mean\n",
        "# Insert row\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "# Create a small summary table for all results including the average resuls for each metric\n",
        "# for each motnh\n",
        "for i in range(FUTURE_STEPS):\n",
        "\n",
        "    # Get MSE and direction average for each month for each model and insert row\n",
        "    month = 'Month ' + str(i+1)\n",
        "    row = [month]\n",
        "    row.append(str(mseAvgsSingle[i]))\n",
        "    row.append(str(dirAvgsSingle[i]))\n",
        "    row.append(str(mseAvgsMulti[i]))\n",
        "    row.append(str(dirAvgsMulti[i]))\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+FUTURE_STEPS+i+7, number = 1, values = row)\n",
        "\n",
        "# Get the guessing ability averages for both model and insert row \n",
        "row = ['Guesses']\n",
        "row.append(str(bestSingle))\n",
        "row.append(str(relaxedSingle))\n",
        "row.append(str(bestMulti))\n",
        "row.append(str(relaxedMulti))\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+FUTURE_STEPS+7, number = 1, values = row)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SpreadsheetNotFound",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/client.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mspreadsheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspreadsheet_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSpreadsheetNotFound\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-1fec52a0cd73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Open and create a new worksheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_worksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FOREX'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/client.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSpreadsheetNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not find a spreadsheet with title %s.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSpreadsheetNotFound\u001b[0m: Could not find a spreadsheet with title Results."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4TyRi68dwuB",
        "colab_type": "text"
      },
      "source": [
        "# Visualising Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4k6qY-KcmWW",
        "colab_type": "text"
      },
      "source": [
        "## Importing Results\n",
        "\n",
        "Imports all the results from the worksheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v140SYMbeHIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "import pygsheets\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "msesSingleAll = []\n",
        "msesMultiAll = []\n",
        "dirSingleAll = []\n",
        "dirMultiAll = []\n",
        "bestGuessSingle = []\n",
        "bestGuessMulti = []\n",
        "relaxedGuessSingle = []\n",
        "relaxedGuessMulti = []\n",
        "\n",
        "titles = ['ARIMA','Forex','ForexAvg','CPI','IR','BOP','OVR','OVRAvg','3m','3mAvg','6m','6mAvg','12m','12mAvg','CPI,IR','CPI,BOP','CPI,3m','IR,BOP','IR,3m','BOP,3m']\n",
        "\n",
        "# Function to import the results of one worksheet\n",
        "def importWorksheet(index):\n",
        "\n",
        "    # Authenticate access to the google sheet\n",
        "    auth.authenticate_user()\n",
        "    credentials, _ = google.auth.default()\n",
        "    gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "    sh = gc.open('Results')\n",
        "\n",
        "    wk1 = sh[index]\n",
        "\n",
        "    # Row number of start of summary results\n",
        "    summaryRow = 25\n",
        "\n",
        "    msesSingle = []\n",
        "    msesMulti = []\n",
        "    dirSingle = []\n",
        "    dirMulti = []\n",
        "    guesses = []\n",
        "\n",
        "    # Get each months MSE and direction results\n",
        "    for i in range(FUTURE_STEPS):\n",
        "\n",
        "        row = wk1.get_row(summaryRow)\n",
        "\n",
        "        msesSingle.append(float(row[1]))\n",
        "        dirSingle.append(float(row[2]))\n",
        "\n",
        "        if(index!=0):\n",
        "            msesMulti.append(float(row[3]))\n",
        "            dirMulti.append(float(row[4]))\n",
        "        else:\n",
        "            msesMulti.append(0)\n",
        "            dirMulti.append(0)\n",
        "\n",
        "        summaryRow = summaryRow + 1\n",
        "\n",
        "    guesses = wk1.get_row(summaryRow)\n",
        "\n",
        "    bestGuessSingle.append(float(guesses[1]))\n",
        "    relaxedGuessSingle.append(float(guesses[2]))\n",
        "\n",
        "    # If index is 0 then it is the ARIMA results and so only has one set of results\n",
        "    if(index!=0):\n",
        "        bestGuessMulti.append(float(guesses[3]))\n",
        "        relaxedGuessMulti.append(float(guesses[4]))\n",
        "    else:\n",
        "        bestGuessMulti.append(0)\n",
        "        relaxedGuessMulti.append(0)\n",
        "\n",
        "    msesSingleAll.append(msesSingle)\n",
        "    msesMultiAll.append(msesMulti)\n",
        "    dirSingleAll.append(dirSingle)\n",
        "    dirMultiAll.append(dirMulti)\n",
        "\n",
        "\n",
        "worksheetIndices = range(len(titles))\n",
        "\n",
        "# Function to import all worksheets (all datasets)\n",
        "def importAllWorksheets():\n",
        "    for index in worksheetIndices:\n",
        "        importWorksheet(index)\n",
        "\n",
        "\n",
        "importAllWorksheets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE9XHJ_AcpfQ",
        "colab_type": "text"
      },
      "source": [
        "## Create Graphs\n",
        "\n",
        "This was code to produce graphs for the dissertation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CywsiBscWCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "months = [1,2,3,4,5,6]\n",
        "\n",
        "# Display the results of data which has a result for each month\n",
        "# This can be fed both MSE and direction data\n",
        "def monthGraph(data, labels, xLabel, yLabel, title):\n",
        "\n",
        "    x = months\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "        y1 = data[i]\n",
        "        \n",
        "        plt.plot(x, y1, label = labels[i])\n",
        "\n",
        "    plt.xlabel(xLabel)\n",
        "    plt.ylabel(yLabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.savefig('mse2.png')\n",
        "    plt.show()\n",
        "\n",
        "# Function to produce bar chart, seperating single and multi-step\n",
        "def guessBarChart(data1, data2, labels, title, threshold):\n",
        "\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35 \n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, data1, width, label='Single-Step')\n",
        "    rects2 = ax.bar(x + width/2, data2, width, label='Multi-step')\n",
        "    ax.plot([-0.35, 7.35], [threshold, threshold], \"k--\")\n",
        "    ax.set_ylabel('Classification')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.legend()\n",
        "\n",
        "# Function to produce bar chart, seperating best and relaxed guess\n",
        "def guessBarChart1(data1, data2, labels, title, threshold):\n",
        "\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.35 \n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, data1, width, label='Best Guess')\n",
        "    rects2 = ax.bar(x + width/2, data2, width, label='Relaxed Guess')\n",
        "    ax.plot([-0.35, 6.35], [(1/6), (1/6)], \"k--\")\n",
        "    ax.plot([-0.35, 6.35], [(1/3), (1/3)], \"k--\")\n",
        "    ax.set_ylabel('Classification')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.legend()\n",
        "    plt.savefig('guess.png')\n",
        "\n",
        "# Function used to get the data ready to be put it in a line graph\n",
        "def getLineData(mseSingleIndices,msesMultiIndices,dirSingleIndices,\n",
        "                dirMultiIndices,labels, xLabel, yLabel, title):\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for x in mseSingleIndices:\n",
        "        data.append(msesSingleAll[x])\n",
        "    for x in msesMultiIndices:\n",
        "        data.append(msesMultiAll[x])\n",
        "    for x in dirSingleIndices:\n",
        "        data.append(dirSingleAll[x])\n",
        "    for x in dirMultiIndices:\n",
        "        data.append(dirMultiAll[x])\n",
        "    \n",
        "\n",
        "    monthGraph(data,labels,xLabel,yLabel,title)\n",
        "\n",
        "# Function used to get the data ready to be put into a bar chart\n",
        "def getBarData(singleIndices, multiIndices, labels):\n",
        "\n",
        "    bestGuess = []\n",
        "    relaxedGuess = []\n",
        "\n",
        "    for x in singleIndices:\n",
        "        bestGuess.append(bestGuessSingle[x])\n",
        "    for x in multiIndices:\n",
        "        bestGuess.append(bestGuessMulti[x])\n",
        "    for x in singleIndices:\n",
        "        relaxedGuess.append(relaxedGuessSingle[x])\n",
        "    for x in multiIndices:\n",
        "        relaxedGuess.append(relaxedGuessMulti[x])\n",
        "\n",
        "    guessBarChart1(bestGuess, relaxedGuess, labels,'', 0)\n",
        "\n",
        "\n",
        "# Function to create line graph for single dataset passed to it\n",
        "def createMonthGraphs(indices, data, xLabel, yLabel, title):\n",
        "\n",
        "    data = [data[x] for x in indices]\n",
        "    labels = [titles[x] for x in indices]\n",
        "\n",
        "    monthGraph(data, labels,'Months','MSE',title)\n",
        "\n",
        "\n",
        "# Function to create line graphs for all dataset indices passed to it\n",
        "def createAllMonthGraphs(indices):\n",
        "\n",
        "    createMonthGraphs(indices, msesSingleAll, 'Months', 'MSE','Single-step MSE')\n",
        "    createMonthGraphs(indices, msesMultiAll, 'Months', 'MSE','Multi-step MSE')\n",
        "\n",
        "    createMonthGraphs(indices, dirSingleAll, 'Months', 'Classification', 'Single-step Direction Classification')\n",
        "    createMonthGraphs(indices, dirMultiAll, 'Months', 'Classification', 'Multi-step Direction Classification')\n",
        "\n",
        "# Function to create bar charts for all dataset indicies passed to it\n",
        "def createBarCharts(indices):\n",
        "\n",
        "    labels = [titles[x] for x in indices]\n",
        "    data1 = [bestGuessSingle[x] for x in indices]\n",
        "    data2 = [bestGuessMulti[x] for x in indices]\n",
        "    data3 = [relaxedGuessSingle[x] for x in indices]\n",
        "    data4 = [relaxedGuessMulti[x] for x in indices]\n",
        "\n",
        "    guessBarChart1(data1, data3, labels,'Single-step month Classification', (1/6))\n",
        "    guessBarChart1(data2, data4, labels,'Multi-step month Classification', (1/3))\n",
        "\n",
        "# Set of indicies for economic data being tested by themselves\n",
        "#indicies = [2,3,4,5,7,9,11,13]\n",
        "# Set of indicies for tests using multiple datasets\n",
        "#indicies = [2,14,15,16,17,18,19]\n",
        "\n",
        "createAllMonthGraphs(indices)    \n",
        "createBarCharts(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRt7fgbEjj4o",
        "colab_type": "text"
      },
      "source": [
        "# ARIMA\n",
        "\n",
        "The following code is was for the testing and development of the ARIMA models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleLhkfMjl3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "xValues, yValues = multiStepDataSplit(dataSet, target, 3500, None, 40, FUTURE_STEPS)\n",
        "\n",
        "mses = []\n",
        "\n",
        "# Function to test the results of one set of ARIMA parameters\n",
        "def mseARIMAmodel(p,q,d):\n",
        "\n",
        "    tmse = 0\n",
        "\n",
        "    for x in range(len(xValues)):\n",
        "        current = xValues[x][-1][0]\n",
        "        past = xValues[x]\n",
        "        future = yValues[x]\n",
        "\n",
        "        model = ARIMA(past, order=(p,q,d))\n",
        "        model_fit = model.fit(disp=0)\n",
        "        predictions = model_fit.forecast(steps=FUTURE_STEPS)[0]\n",
        "\n",
        "        error = mean_squared_error(future,predictions)\n",
        "        tmse = tmse + error\n",
        "\n",
        "    mse = tmse / len(xValues)\n",
        "    mses.append(mse)\n",
        "\n",
        "\n",
        "# Function to test different combinations of ARIMA parameters\n",
        "def tuneParamters():\n",
        "    p_values = [4, 6, 8, 10]\n",
        "    d = 1\n",
        "    q = 0\n",
        "\n",
        "    for p in p_values:\n",
        "        mseARIMAmodel(p,d,q)\n",
        "\n",
        "\n",
        "tuneParamters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuDSDMUEHNQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arimaMSES = []\n",
        "arimaDir = []\n",
        "arimaBestGuess = []\n",
        "arimaRelaxedGuess = []\n",
        "\n",
        "xValues, yValues = multiStepDataSplit(dataSet, target, 950, None, 40, FUTURE_STEPS)\n",
        "\n",
        "# Function to complete full tests for the ARIMA model\n",
        "def testARIMA():\n",
        "\n",
        "    correctDirection = [0,0,0,0,0,0]\n",
        "    totalSquaredError = [0,0,0,0,0,0]\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    # For each test datapoint calculate metrics\n",
        "    for x in range(len(xValues)):\n",
        "        current = xValues[x][-1][0]\n",
        "        past = xValues[x]\n",
        "        future = yValues[x]\n",
        "\n",
        "        # Get ARIMA model predictions\n",
        "        model = ARIMA(past, order=(6,1,0))\n",
        "        model_fit = model.fit(disp=0)\n",
        "        predictions = model_fit.forecast(steps=FUTURE_STEPS)[0]\n",
        "\n",
        "        # Test for best and relaxed month guessing ability\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        temp = future[actualMax][0]\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        future[actualMax]=temp\n",
        "\n",
        "        # Calculate MSE for each month\n",
        "        for y in range(FUTURE_STEPS):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    # Calculate the average results across all test data points\n",
        "    for x in range(FUTURE_STEPS):\n",
        "        mse = totalSquaredError[x] / len(xValues)\n",
        "        arimaMSES.append(mse)\n",
        "\n",
        "    for x in range(FUTURE_STEPS):\n",
        "        percentInterval = correctDirection[x] / len(xValues)\n",
        "        arimaDir.append(percentInterval)\n",
        "\n",
        "    bestMonthClass = correctMax / len(xValues)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xValues)\n",
        "\n",
        "    arimaBestGuess.append(bestMonthClass)\n",
        "    arimaRelaxedGuess.append(bestMonthRelaxedClass)\n",
        "\n",
        "testARIMA()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}