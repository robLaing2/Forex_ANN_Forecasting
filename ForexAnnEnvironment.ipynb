{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y23CLo2oUco-O4CAkKZhYsjzzzbnTeLP",
      "authorship_tag": "ABX9TyMwQ1+kvOLqLpCaFsJpoIYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "54cadb63-2bbb-4082-e9e6-2899c13d85ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "#!pip install FRB\n",
        "!pip install fred\n",
        "!pip install mock\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.0.0\n",
        "\n",
        "import fred\n",
        "from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "\n",
        "START_DATE = '2016-01-01'\n",
        "END_DATE = ''\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: requests>=2.7.0 in /tensorflow-2.1.0/python3.6 (from quandl) (2.22.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.6.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.25.3)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.3.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from quandl) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /tensorflow-2.1.0/python3.6 (from quandl) (1.18.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /tensorflow-2.1.0/python3.6 (from dbnomics) (2.22.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (0.25.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (1.25.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /tensorflow-2.1.0/python3.6 (from pandas>=0.21->dbnomics) (1.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /tensorflow-2.1.0/python3.6 (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.14.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from fred) (2.22.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->fred) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->fred) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->fred) (1.25.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Interest Rate data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBT7oI__I2MS",
        "colab_type": "code",
        "outputId": "b86157cf-056b-4e38-d9e1-d7356f95c800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE)\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE)\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE)\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE)\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE)\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE)\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE)\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE)\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE)\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE)\n",
        "\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]\n",
        "\n",
        "def getRatioValues(datasetX, datasetY):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "\n",
        "    for x in range(len(datasetX)):\n",
        "        if (datasetX[x][\"value\"] == '.' or datasetY[x][\"value\"] == '.'):\n",
        "            continue\n",
        "\n",
        "        dates.append(pd.Timestamp(datasetX[x][\"date\"]))\n",
        "        valuesX.append(float(datasetX[x][\"value\"]))\n",
        "        valuesY.append(float(datasetY[x][\"value\"]))\n",
        "\n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    ratioValues = datasetXarr / datasetYarr\n",
        "\n",
        "    data_mean = ratioValues.mean()\n",
        "    data_std = ratioValues.std()\n",
        "    dataNormalised = (ratioValues - data_mean) / data_std\n",
        "\n",
        "    res = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return res\n",
        "\n",
        "GBPEURovrRatio = getRatioValues(GBRovrJson,EURovrJson)\n",
        "\n",
        "print(GBPEURovrRatio[pd.Timestamp('2016-01-04 00:00:00')])\n",
        "\n",
        "GBPEUR1mRatio = getRatioValues(GBR1mJson,EUR1mJson)\n",
        "GBPEUR3mRatio = getRatioValues(GBR3mJson,EUR3mJson)\n",
        "GBPEUR6mRatio = getRatioValues(GBR6mJson,EUR6mJson)\n",
        "GBPEUR12mRatio = getRatioValues(GBR12mJson,EUR12mJson)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.5700420176652672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Inflation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "# and period < '2019-06-01'\"\n",
        "\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "ukCPIdates = []\n",
        "for x in ukCPI.period:\n",
        "    ukCPIdates.append(x)\n",
        "\n",
        "ukCPIarr = np.array(ukCPI.value, dtype=np.float)\n",
        "euCPIarr = np.array(euCPI.value, dtype=np.float)\n",
        "\n",
        "ukEuCpiRatio = ukCPIarr*1000 / euCPIarr*1000\n",
        "\n",
        "# Normalise CPI data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "cpiDict = {ukCPIdates[i]: ukEuCpiRatio[i] for i in range(len(ukCPIdates))}\n",
        "\n",
        "cpiData = {'Date':ukCPI.period, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing International Reserves data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "# and period < '2019-06-01'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRdates = []\n",
        "for x in ukIR.period:\n",
        "    ukIRdates.append(x)\n",
        "\n",
        "ukIRarr = np.array(ukIR.value, dtype=np.float)\n",
        "euIRarr = np.array(euIR.value, dtype=np.float)\n",
        "\n",
        "ukEuIRRatio = ukIRarr*1000 / euIRarr*1000\n",
        "\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {ukIRdates[i]: ukEuIRRatio[i] for i in range(len(ukIRdates))}\n",
        "\n",
        "irData = {'Date':ukIR.period, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Balance of Payments data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "outputId": "88ba8b8b-4bdd-4aeb-99b3-b74ef3e901c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "# and period < '2019-06-01'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPdates = []\n",
        "for x in ukBOP.period:\n",
        "    ukBOPdates.append(x)\n",
        "\n",
        "ukBOParr = np.array(ukBOP.value, dtype=np.float)\n",
        "euBOParr = np.array(euBOP.value, dtype=np.float)\n",
        "\n",
        "ukEuBOPRatio = ukBOParr*1000 / euBOParr*1000\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {ukBOPdates[i]: ukEuBOPRatio[i] for i in range(len(ukBOPdates))}\n",
        "\n",
        "bopData = {'Date':ukBOP.period, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)\n",
        "\n",
        "print (bopDf)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          Date     Value\n",
            "184 2016-01-01 -0.625983\n",
            "185 2016-04-01  0.256890\n",
            "186 2016-07-01 -0.010063\n",
            "187 2016-10-01  0.888110\n",
            "188 2017-01-01  0.341923\n",
            "..         ...       ...\n",
            "194 2018-07-01  0.431774\n",
            "195 2018-10-01  0.137063\n",
            "196 2019-01-01 -0.781996\n",
            "197 2019-04-01 -1.482463\n",
            "198 2019-07-01  0.733947\n",
            "\n",
            "[15 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YSsNlwQPnPr",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing FOREX data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startDate = '2018-01-01'\n",
        "endDate = '2019-01-01'\n",
        "\n",
        "# Get FOREX data\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=START_DATE, returns=\"numpy\")\n",
        "forexDataN = dataGbpEurRate.Value\n",
        "\n",
        "# Normalise data\n",
        "forex_mean = forexDataN.mean()\n",
        "forex_std = forexDataN.std()\n",
        "forexDataN = (forexDataN - forex_mean) / forex_std\n",
        "\n",
        "forexData = {'Date':dataGbpEurRate.Date,'Value':forexDataN}\n",
        "forexDf = pd.DataFrame(forexData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1qXH4oOBAVu",
        "colab_type": "text"
      },
      "source": [
        "## FOREX Moving Averages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjWy9l5rBK58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "# Creating full data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaLD_2QagA8w",
        "colab_type": "code",
        "outputId": "c0d555a6-df42-4e35-87aa-f732d3e2bec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 12)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "mainDf = pd.DataFrame(columns=['Date','ForexRate','CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR', '1mLIBOR','3mLIBOR','6mLIBOR','12mLIBOR'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        "\n",
        "for index, row in forexDf.iterrows():\n",
        "\n",
        "    newD = row['Date']\n",
        "    roundD = newD.replace(day=1)\n",
        "    quarterD = 1\n",
        "\n",
        "    quarter = newD.quarter\n",
        "\n",
        "    cpi = cpiDict.get(roundD,0)\n",
        "    ir = irDict.get(roundD,0)\n",
        "\n",
        "    switcher={\n",
        "        1:newD.replace(month=1,day=1),\n",
        "        2:newD.replace(month=4,day=1),\n",
        "        3:newD.replace(month=7,day=1),\n",
        "        4:newD.replace(month=10,day=1)\n",
        "    }\n",
        "\n",
        "    quarterD = switcher.get(newD.quarter)\n",
        "\n",
        "    bop = bopDict.get(quarterD,0)\n",
        "\n",
        "    ovrI = GBPEURovrRatio.get(row['Date'], 0)\n",
        "    i1month = GBPEUR1mRatio.get(row['Date'], 0)\n",
        "    i3month = GBPEUR3mRatio.get(row['Date'], 0)\n",
        "    i6month = GBPEUR6mRatio.get(row['Date'], 0)\n",
        "    i12month = GBPEUR12mRatio.get(row['Date'], 0)\n",
        "\n",
        "    mainDf = mainDf.append({'Date':row['Date'],\n",
        "                            'ForexRate':row['Value'],\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovrI,\n",
        "                            '1mLIBOR': i1month,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '12mLIBOR': i12month},\n",
        "                            ignore_index=True)\n",
        "\n",
        "print(mainDf)\n",
        "\n",
        "# Split and format data\n",
        "futureDistance = 0\n",
        "historySize = 6"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Date  ForexRate  CPIRatio   IRRatio  BOPRatio  OvrLIBOR   1mLIBOR  \\\n",
            "0    2016-01-04  3.781480  -0.27492  -1.691234 -0.625983 -1.570042 -2.521962   \n",
            "1    2016-01-05  3.900603  -0.27492  -1.691234 -0.625983 -1.575190 -2.487274   \n",
            "2    2016-01-06  3.775807  -0.27492  -1.691234 -0.625983 -1.531958 -2.480564   \n",
            "3    2016-01-07  3.505417  -0.27492  -1.691234 -0.625983 -1.510590 -2.424434   \n",
            "4    2016-01-08  3.274733  -0.27492  -1.691234 -0.625983 -1.553390 -2.437240   \n",
            "...         ...       ...       ...        ...       ...       ...       ...   \n",
            "1048 2020-02-20  0.616205   0.00000   0.000000  0.000000 -0.341065 -0.196987   \n",
            "1049 2020-02-21  0.650241   0.00000   0.000000  0.000000 -0.274067 -0.186463   \n",
            "1050 2020-02-24  0.580279   0.00000   0.000000  0.000000  0.000000  0.000000   \n",
            "1051 2020-02-25  0.720202   0.00000   0.000000  0.000000  0.000000  0.000000   \n",
            "1052 2020-02-26  0.548135   0.00000   0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "       3mLIBOR   6mLIBOR  12mLIBOR  \n",
            "0    -4.288206 -9.427794  0.322854  \n",
            "1    -4.266262 -9.628011  0.321111  \n",
            "2    -4.122879 -8.204995  0.340595  \n",
            "3    -3.767152 -6.965416  0.365023  \n",
            "4    -3.767152 -6.732298  0.360937  \n",
            "...        ...       ...       ...  \n",
            "1048  0.077300  0.458022  0.058710  \n",
            "1049  0.090932  0.463199  0.058755  \n",
            "1050  0.000000  0.000000  0.000000  \n",
            "1051  0.000000  0.000000  0.000000  \n",
            "1052  0.000000  0.000000  0.000000  \n",
            "\n",
            "[1053 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3pUL5P8rC_d",
        "colab_type": "text"
      },
      "source": [
        "# Standard ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wFbpmT0sFOs",
        "colab_type": "code",
        "outputId": "4b56f547-5f12-4515-c3e1-54d96da1fe0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "from joblib import dump, load\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def formatData(data, start, end, history, target):\n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    startIndex = start + historySize\n",
        "    endIndex = len(data) - futureDistance\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        indices = range(i-historySize, i)\n",
        "        # Reshape data from (history_size,) to (history_size, 1)\n",
        "        x.append(data[indices])\n",
        "        y.append(data[i+futureDistance])\n",
        "        \n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "TRAIN_SPLIT = round(len(forexDataN) * 0.7)\n",
        "VALIDATION_SPLIT = round(len(forexDataN) * 0.85)\n",
        "\n",
        "xTrain, yTrain = formatData(forexDataN, 0, TRAIN_SPLIT, historySize, futureDistance)\n",
        "xVal, yVal = formatData(forexDataN, TRAIN_SPLIT, VALIDATION_SPLIT, historySize, futureDistance)\n",
        "xTest, yTest = formatData(forexDataN, VALIDATION_SPLIT, None, historySize, futureDistance)\n",
        "\n",
        "print(xTest[0])\n",
        "print(yTest[0])\n",
        "\n",
        "BATCH_SIZE = 30\n",
        "BUFFER_SIZE = 10\n",
        "\n",
        "# Form training tensors and shuffle etc.\n",
        "dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "dataTrain = dataTrain.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "# Form validation tensors and shuffle etc.\n",
        "dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "# Create model\n",
        "EVALUATION_INTERVAL = 10\n",
        "EPOCHS = 2\n",
        "\n",
        "def standard_ann_model():\n",
        "\tmodel = keras.Sequential([\n",
        "        layers.Dense(6,input_dim=(6),kernel_initializer='normal',activation='relu'),\n",
        "        layers.Dense(8, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "\tmodel.compile(optimizer='adam', loss='mse')\n",
        "\treturn model\n",
        "\n",
        "export_path = \"\"\n",
        "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "#cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                 save_weights_only=True,\n",
        "#                                                 verbose=1)\n",
        "\n",
        "\n",
        "model = standard_ann_model()\n",
        "\n",
        "model.fit(dataTrain, epochs=EPOCHS,\n",
        "                    steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                    validation_data=dataVal,\n",
        "                    validation_steps=50,\n",
        "                    callbacks=[cp_callback]\n",
        "          )\n",
        "\n",
        "\n",
        "model.save('newmodel.h5')\n",
        "\n",
        "result = model.evaluate(xTest, yTest, batch_size=30)\n",
        "#print(\"-----------------------------------------\")\n",
        "#print(\"Model loss:\", result)\n",
        "\n",
        "\n",
        "#print(type(model))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.99668541 -0.88890724 -0.86432626 -0.87188964 -0.83596358 -0.72062204]\n",
            "-0.7603297822386305\n",
            "Train for 10 steps, validate for 50 steps\n",
            "Epoch 1/2\n",
            " 1/10 [==>...........................] - ETA: 2s - loss: 7.5075\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 2.3142 - val_loss: 0.2913\n",
            "Epoch 2/2\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1122\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.2391 - val_loss: 0.2448\n",
            "152/152 [==============================] - 0s 382us/sample - loss: 0.2790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIg8KNPOqiyn",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HeS-tpxf97i",
        "colab_type": "code",
        "outputId": "d82e379f-d90f-4fe7-dcdc-8e9870ae9679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "def formatData(data, start, end, history, target):\n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    startIndex = start + historySize\n",
        "    endIndex = len(data) - futureDistance\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        indices = range(i-historySize, i)\n",
        "        # Reshape data from (history_size,) to (history_size, 1)\n",
        "        x.append(np.reshape(data[indices], (historySize, 1)))\n",
        "        y.append(data[i+futureDistance])\n",
        "        \n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "TRAIN_SPLIT = round(len(forexDataN) * 0.7)\n",
        "VALIDATION_SPLIT = round(len(forexDataN) * 0.85)\n",
        "\n",
        "xTrain, yTrain = formatData(forexDataN, 0, TRAIN_SPLIT, historySize, futureDistance)\n",
        "xVal, yVal = formatData(forexDataN, TRAIN_SPLIT, VALIDATION_SPLIT, historySize, futureDistance)\n",
        "xTest, yTest = formatData(forexDataN, VALIDATION_SPLIT, None, historySize, futureDistance)\n",
        "\n",
        "BATCH_SIZE = 30\n",
        "BUFFER_SIZE = 10\n",
        "\n",
        "# Form training tensors and shuffle etc.\n",
        "dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "dataTrain = dataTrain.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "# Form validation tensors and shuffle etc.\n",
        "dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "# Create model\n",
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 10\n",
        "\n",
        "def lstm_ann_model():\n",
        "    lstm_model = keras.Sequential([\n",
        "        layers.LSTM(8, input_shape=xTrain.shape[-2:]),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    lstm_model.compile(optimizer='adam', loss='mse')\n",
        "    return lstm_model\n",
        "\n",
        "model = lstm_ann_model()\n",
        "\n",
        "model.fit(dataTrain, epochs=EPOCHS,\n",
        "                     steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=dataVal,\n",
        "                      validation_steps=50)\n",
        "\n",
        "\n",
        "\n",
        "result = model.evaluate(xTest, yTest, batch_size=30)\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Model loss:\", result)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 200 steps, validate for 50 steps\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.7794 - val_loss: 0.1492\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.2370 - val_loss: 0.0418\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0743 - val_loss: 0.0405\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0500 - val_loss: 0.0342\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0453 - val_loss: 0.0278\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0384 - val_loss: 0.0230\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0313 - val_loss: 0.0197\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0304 - val_loss: 0.0176\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0280 - val_loss: 0.0160\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.0253 - val_loss: 0.0147\n",
            "152/152 [==============================] - 0s 2ms/sample - loss: 0.0188\n",
            "-----------------------------------------\n",
            "Model loss: 0.01875652952769183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsAv1nRFUBD4",
        "colab_type": "code",
        "outputId": "5be57dca-92cb-4f60-bd5d-7931846a11ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.summary"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f194faa36d8>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "outputId": "e1d21962-2ae2-4d50-e794-c734a853a4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "source": [
        "\n",
        "\n",
        "for x, y in dataVal.take(3):\n",
        "    print(x)\n",
        "    print(model.predict(x)[0])\n",
        "\n",
        "    plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
        "                    model.predict(x)[0]], 0, 'Simple LSTM model')\n",
        "    plot.show()\n",
        "\n",
        "def create_time_steps(length):\n",
        "  return list(range(-length, 0))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "               label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.71305866 -0.62797063 -0.70738612 -0.73196711 -0.69415021 -0.70549528]\n",
            " [-0.62797063 -0.70738612 -0.73196711 -0.69415021 -0.70549528 -0.75087556]\n",
            " [-0.70738612 -0.73196711 -0.69415021 -0.70549528 -0.75087556 -1.08744597]\n",
            " [-0.73196711 -0.69415021 -0.70549528 -0.75087556 -1.08744597 -1.00992132]\n",
            " [-0.69415021 -0.70549528 -0.75087556 -1.08744597 -1.00992132 -0.87188964]\n",
            " [-0.70549528 -0.75087556 -1.08744597 -1.00992132 -0.87188964 -0.91159738]\n",
            " [-0.75087556 -1.08744597 -1.00992132 -0.87188964 -0.91159738 -0.90970654]\n",
            " [-1.08744597 -1.00992132 -0.87188964 -0.91159738 -0.90970654 -0.89647062]\n",
            " [-1.00992132 -0.87188964 -0.91159738 -0.90970654 -0.89647062 -0.91159738]\n",
            " [-0.87188964 -0.91159738 -0.90970654 -0.89647062 -0.91159738 -0.99857625]\n",
            " [-0.91159738 -0.90970654 -0.89647062 -0.91159738 -0.99857625 -1.00235794]\n",
            " [-0.90970654 -0.89647062 -0.91159738 -0.99857625 -1.00235794 -0.91916076]\n",
            " [-0.89647062 -0.91159738 -0.99857625 -1.00235794 -0.91916076 -0.94374175]\n",
            " [-0.91159738 -0.99857625 -1.00235794 -0.91916076 -0.94374175 -0.94374175]\n",
            " [-0.99857625 -1.00235794 -0.91916076 -0.94374175 -0.94374175 -0.97210442]\n",
            " [-1.00235794 -0.91916076 -0.94374175 -0.94374175 -0.97210442 -0.95319597]\n",
            " [-0.91916076 -0.94374175 -0.94374175 -0.97210442 -0.95319597 -0.8491995 ]\n",
            " [-0.94374175 -0.94374175 -0.97210442 -0.95319597 -0.8491995  -0.93428752]\n",
            " [-0.94374175 -0.97210442 -0.95319597 -0.8491995  -0.93428752 -1.0174847 ]\n",
            " [-0.97210442 -0.95319597 -0.8491995  -0.93428752 -1.0174847  -0.84352696]\n",
            " [-0.95319597 -0.8491995  -0.93428752 -1.0174847  -0.84352696 -0.8662171 ]\n",
            " [-0.8491995  -0.93428752 -1.0174847  -0.84352696 -0.8662171  -0.89268893]\n",
            " [-0.93428752 -1.0174847  -0.84352696 -0.8662171  -0.89268893 -0.99668541]\n",
            " [-1.0174847  -0.84352696 -0.8662171  -0.89268893 -0.99668541 -0.95886851]\n",
            " [-0.84352696 -0.8662171  -0.89268893 -0.99668541 -0.95886851 -0.81327344]\n",
            " [-0.8662171  -0.89268893 -0.99668541 -0.95886851 -0.81327344 -0.6393157 ]\n",
            " [-0.89268893 -0.99668541 -0.95886851 -0.81327344 -0.6393157  -0.75465725]\n",
            " [-0.99668541 -0.95886851 -0.81327344 -0.6393157  -0.75465725 -0.58826289]\n",
            " [-0.95886851 -0.81327344 -0.6393157  -0.75465725 -0.58826289 -0.48237557]\n",
            " [-0.81327344 -0.6393157  -0.75465725 -0.58826289 -0.48237557 -0.45968543]], shape=(30, 6), dtype=float64)\n",
            "[-0.05638129]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-0d7b2cd043b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     plot = show_plot([x[0].numpy(), y[0].numpy(),\n\u001b[0m\u001b[1;32m      8\u001b[0m                     model.predict(x)[0]], 0, 'Simple LSTM model')\n\u001b[1;32m      9\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'show_plot' is not defined"
          ]
        }
      ]
    }
  ]
}