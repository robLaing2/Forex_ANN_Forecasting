{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y23CLo2oUco-O4CAkKZhYsjzzzbnTeLP",
      "authorship_tag": "ABX9TyNavDHW9lCnjkISoB7ucobg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "b7b6283f-669d-4282-ab1f-fb06e471b677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "#!pip install FRB\n",
        "!pip install fred\n",
        "!pip install mock\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.0.0\n",
        "\n",
        "import fred\n",
        "from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, CuDNNLSTM\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.0.3)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (1.18.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.12.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fred) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2.8)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knovwSza04MP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSX-AVfVGK6s",
        "colab_type": "code",
        "outputId": "f3ed6302-a058-49e7-b9cd-aff17aa8f7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "START_DATE = '2001-01-01'\n",
        "END_DATE = '2020-02-01'\n",
        "\n",
        "pd.set_option('display.max_rows', 25)\n",
        "pd.set_option('display.max_columns', 25)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mBJkhEqGfRq",
        "colab_type": "text"
      },
      "source": [
        "## Moving average function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpuooBtRGero",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMovingAverages(data, windowSize):\n",
        "\n",
        "    movingAverages = []\n",
        "\n",
        "    for x in range(len(data)):\n",
        "        if (x < windowSize):\n",
        "            window = data[:x+1]\n",
        "        else:\n",
        "            window = data[x-(windowSize - 1):x+1]\n",
        "        \n",
        "        total = sum(window)\n",
        "        average = total / len(window)\n",
        "        movingAverages.append(average)\n",
        "\n",
        "    return movingAverages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n68WYYVB6UK7",
        "colab_type": "text"
      },
      "source": [
        "## FOREX data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "outputId": "a1c917fb-c6b7-49c2-aa16-fb46bc2be6ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Get FOREX data\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=START_DATE, end_date=END_DATE, returns=\"numpy\")\n",
        "forexDataN = dataGbpEurRate.Value\n",
        "\n",
        "forexMonthMovAvg = getMovingAverages(forexDataN, 22)\n",
        "forexMonthMovAvg = np.asarray(forexMonthMovAvg)\n",
        "\n",
        "# Normalise data\n",
        "forex_mean = forexMonthMovAvg.mean()\n",
        "forex_std = forexMonthMovAvg.std()\n",
        "forexMonthMovAvg = (forexMonthMovAvg - forex_mean) / forex_std\n",
        "\n",
        "ukFOREXdates = []\n",
        "for x in dataGbpEurRate.Date:\n",
        "    ukFOREXdates.append(pd.Timestamp(x))\n",
        "\n",
        "forexData = {'Date':ukFOREXdates,'Value':forexMonthMovAvg}\n",
        "mainDf = pd.DataFrame(forexData)\n",
        "\n",
        "print(forex_mean)\n",
        "print(forex_std)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.309593875180065\n",
            "0.16475970732268408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "## Interest Rate Data (INT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUTeDp07W41L",
        "colab_type": "text"
      },
      "source": [
        "### INT data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0f5HNs21pcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgecCRUBkiR",
        "colab_type": "text"
      },
      "source": [
        "### INT data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkAjnFLBlhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanDataSets(dataset):\n",
        "\n",
        "    dataDict = {pd.Timestamp(dataset[i][\"date\"]): dataset[i][\"value\"] for i in range(len(dataset))}\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "        value = dataDict.get(row['Date'], 1000000)\n",
        "\n",
        "        if (value=='.'):\n",
        "            value = 1000000\n",
        "\n",
        "        if(value==1000000):\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataDict.get(dateBelow, 1000000)\n",
        "            valueAbove = dataDict.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "GBRovrC = cleanDataSets(GBRovrJson)\n",
        "EURovrC = cleanDataSets(EURovrJson)\n",
        "GBR3mC = cleanDataSets(GBR3mJson)\n",
        "EUR3mC = cleanDataSets(EUR3mJson)\n",
        "GBR6mC = cleanDataSets(GBR6mJson)\n",
        "EUR6mC = cleanDataSets(EUR6mJson)\n",
        "GBR12mC = cleanDataSets(GBR12mJson)\n",
        "EUR12mC = cleanDataSets(EUR12mJson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euiAqH5oXFmC",
        "colab_type": "text"
      },
      "source": [
        "### INT feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjzi_yf1sjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDifferenceFeatures(xDict, yDict):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "    ratioValues = []                      \n",
        "\n",
        "    for k,v in xDict.items():\n",
        "\n",
        "        match = yDict.get(k, 0)\n",
        "        valuesX.append(float(v))\n",
        "        valuesY.append(float(match))\n",
        "        dates.append(k)\n",
        " \n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    diffValues = datasetXarr - datasetYarr\n",
        "\n",
        "    movingAvg = getMovingAverages(diffValues, 22)\n",
        "    movingAvg = np.asarray(movingAvg)\n",
        "\n",
        "    data_mean = movingAvg.mean()\n",
        "    data_std = movingAvg.std()\n",
        "    dataNormalised = (movingAvg - data_mean) - data_std\n",
        "\n",
        "    res = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return res\n",
        "\n",
        "ovrRatioMovAvg = getDifferenceFeatures(GBRovrC,EURovrC)\n",
        "threeMRatioMovAvg = getDifferenceFeatures(GBR3mC,EUR3mC)\n",
        "sixMRatioMovAvg = getDifferenceFeatures(GBR6mC,EUR6mC)\n",
        "twelveMRatioMovAvg = getDifferenceFeatures(GBR12mC,EUR12mC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "## Inflation data (CPI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUCPuwpYOnn",
        "colab_type": "text"
      },
      "source": [
        "### CPI data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVanjbf-n1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "ukCPIDict = {ukCPI.period.iloc[i]: ukCPI.value.iloc[i] for i in range(len(ukCPI))}\n",
        "euCPIDict = {euCPI.period.iloc[i]: euCPI.value.iloc[i] for i in range(len(euCPI))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhffkl2I-kY0",
        "colab_type": "text"
      },
      "source": [
        "### CPI data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxREJ3rFVj5",
        "colab_type": "code",
        "outputId": "f7ebe3de-8dca-4a5c-e8a3-2aa802e9d43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def cleanMonthlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        roundD = row['Date'].replace(day=1)\n",
        "\n",
        "        value= dataset.get(pd.Timestamp(roundD),1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            clean = False\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataset.get(dateBelow, 1000000)\n",
        "            valueAbove = dataset.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    if(clean==True):\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukCPIDictC = cleanMonthlyData(ukCPIDict)\n",
        "euCPIDictC = cleanMonthlyData(euCPIDict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T2dZu4RA6Sl",
        "colab_type": "text"
      },
      "source": [
        "### CPI feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = []\n",
        "ukCPIarr = []\n",
        "euCPIarr = []\n",
        "\n",
        "for k,v in ukCPIDictC.items():\n",
        "\n",
        "    match = euCPIDictC.get(k, 0)\n",
        "\n",
        "    ukCPIarr.append(v)\n",
        "    euCPIarr.append(match)\n",
        "    dates.append(k)\n",
        "\n",
        "ukCPIarr = np.array(ukCPIarr, dtype=np.float)\n",
        "euCPIarr = np.array(euCPIarr, dtype=np.float)\n",
        "\n",
        "ukEuCpiRatio = ukCPIarr - euCPIarr\n",
        "\n",
        "# Normalise CPI data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "cpiDict = {dates[i]: ukEuCpiRatio[i] for i in range(len(dates))}\n",
        "\n",
        "cpiData = {'Date':dates, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "## International Reserves data (IR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeoJsXNEQA_m",
        "colab_type": "text"
      },
      "source": [
        "### IR data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXRsvqQIQMG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRDict = {ukIR.period.iloc[i]: ukIR.value.iloc[i] for i in range(len(ukIR))}\n",
        "euIRDict = {euIR.period.iloc[i]: euIR.value.iloc[i] for i in range(len(euIR))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj0vLPaBQFde",
        "colab_type": "text"
      },
      "source": [
        "### IR data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZbMYaFhQREG",
        "colab_type": "code",
        "outputId": "66a2e0c9-f3bb-47eb-bc77-75658b784925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "ukIRDictC = cleanMonthlyData(ukIRDict)\n",
        "euIRDictC = cleanMonthlyData(euIRDict)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCU1PotbQH3d",
        "colab_type": "text"
      },
      "source": [
        "### IR feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IRdates = []\n",
        "ukIRarr = []\n",
        "euIRarr = []\n",
        "\n",
        "for k,v in ukIRDictC.items():\n",
        "\n",
        "    match = euIRDictC.get(k, 0)\n",
        "\n",
        "    ukIRarr.append(v)\n",
        "    euIRarr.append(match)\n",
        "    IRdates.append(k)\n",
        "\n",
        "\n",
        "ukIRarr = np.array(ukIRarr, dtype=np.float)\n",
        "euIRarr = np.array(euIRarr, dtype=np.float)\n",
        "\n",
        "ukEuIRRatio = ukIRarr / euIRarr\n",
        "\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {IRdates[i]: ukEuIRRatio[i] for i in range(len(IRdates))}\n",
        "\n",
        "irData = {'Date':IRdates, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Balance of Payments data (BOP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FpSuRNLR8Rb",
        "colab_type": "text"
      },
      "source": [
        "### BOP data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_2Bg9PSEym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPDict = {ukBOP.period.iloc[i]: ukBOP.value.iloc[i] for i in range(len(ukBOP))}\n",
        "euBOPDict = {euBOP.period.iloc[i]: euBOP.value.iloc[i] for i in range(len(euBOP))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EsjDOHjR_Q-",
        "colab_type": "text"
      },
      "source": [
        "### BOP data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsVJ5XKGSmu_",
        "colab_type": "code",
        "outputId": "d5992ddb-52cb-4b29-f5ec-1d5a5a45aa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def cleanQuarterlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        date = row['Date']\n",
        "        dateMonth = date.replace(day=1)\n",
        "        dateQuarter = date.quarter\n",
        "        \n",
        "        switcher={\n",
        "            1:date.replace(month=1,day=1),\n",
        "            2:date.replace(month=4,day=1),\n",
        "            3:date.replace(month=7,day=1),\n",
        "            4:date.replace(month=10,day=1)\n",
        "        }\n",
        "\n",
        "        dateRoundedQuarter = switcher.get(dateQuarter)\n",
        "\n",
        "        value = dataset.get(dateRoundedQuarter,1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            mainDf.drop([index], inplace=True)\n",
        "        else:\n",
        "            cleanedDataDict[row['Date']] = value\n",
        "\n",
        "\n",
        "    clean = True\n",
        "    for k,v in cleanedDataDict.items():\n",
        "        if (v==1000000):\n",
        "            clean = False;\n",
        "\n",
        "    if (clean==False):\n",
        "        print(\"Data is unlcean\")\n",
        "    else:\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukBOPDictC = cleanQuarterlyData(ukBOPDict)\n",
        "euBOPDictC = cleanQuarterlyData(euBOPDict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5T04eISB7G",
        "colab_type": "text"
      },
      "source": [
        "### BOP feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOPdates = []\n",
        "ukBOParr = []\n",
        "euBOParr = []\n",
        "\n",
        "for k,v in ukBOPDictC.items():\n",
        "\n",
        "    match = euBOPDictC.get(k, 0)\n",
        "\n",
        "    ukBOParr.append(v)\n",
        "    euBOParr.append(match)\n",
        "    BOPdates.append(k)\n",
        "\n",
        "ukBOParr = np.array(ukBOParr, dtype=np.float)\n",
        "euBOParr = np.array(euBOParr, dtype=np.float)\n",
        "\n",
        "ukEuBOPRatio = ukBOParr / euBOParr\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {BOPdates[i]: ukEuBOPRatio[i] for i in range(len(BOPdates))}\n",
        "\n",
        "bopData = {'Date':BOPdates, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "## Creating full data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOlDl_FgRI8",
        "colab_type": "code",
        "outputId": "31b1d0e6-3564-46ba-83bc-ba25021b2a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "completeDf = pd.DataFrame(columns=['Date','ForexRate','CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        " \n",
        "for index, row in mainDf.iterrows():\n",
        "\n",
        "    date = row['Date']\n",
        "    forex = row['Value']\n",
        "    \n",
        "    cpi = cpiDict.get(date, 0)\n",
        "    ir = irDict.get(date,0)\n",
        "    bop = bopDict.get(date,0)\n",
        "\n",
        "    ovrI = ovrRatioMovAvg.get(date, 0)\n",
        "    i3month = threeMRatioMovAvg.get(date, 0)\n",
        "    i6month = sixMRatioMovAvg.get(date, 0)\n",
        "    i12month = twelveMRatioMovAvg.get(date, 0)\n",
        "\n",
        "    completeDf = completeDf.append({'Date':date,\n",
        "                            'ForexRate':forex,\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovrI,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '12mLIBOR': i12month},\n",
        "                            ignore_index=True)\n",
        "\n",
        "#print(completeDf)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9gVEULcO0zD",
        "colab_type": "text"
      },
      "source": [
        "# Variable Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpiLy6YcO5-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables = ['CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR']\n",
        "\n",
        "forex = completeDf['ForexRate'].tolist()\n",
        "correlations = []\n",
        "\n",
        "for x in range(len(variables)):\n",
        "    \n",
        "    column = completeDf[variables[x]].tolist()\n",
        "\n",
        "    r = np.corrcoef(forex, column)\n",
        "\n",
        "    correlations.append(r[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7MnSU94FOw",
        "colab_type": "code",
        "outputId": "211bcf6a-bfb6-4228-b819-47be6300515e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "y_pos = np.arange(0,14,2)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(y_pos, correlations, align='center', alpha=0.5, color=(0.0, 0.0, 0.0, 1))\n",
        "plt.xticks(y_pos, variables)\n",
        "plt.ylabel('Usage')\n",
        "plt.title('Correlations')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMlG3PXw4dX",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSvQDGXwFVJ",
        "colab_type": "text"
      },
      "source": [
        "## Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4_5GXRVwHR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "EPOCHS = 1\n",
        "EVALUATION_INTERVAL = 100\n",
        "VALIDATION_STEPS = 50\n",
        "BATCH_SIZE = 30\n",
        "FOLDS = 5\n",
        "\n",
        "HISTORY_STEPS = 20\n",
        "FUTURE_STEPS = 3\n",
        "\n",
        "features = ['ForexRate']\n",
        "\n",
        "dataSet = completeDf[features]\n",
        "dataSet = dataSet.values\n",
        "\n",
        "fold_steps = math.floor(len(dataSet) / FOLDS)\n",
        "fold_locations = []\n",
        "results = []\n",
        "\n",
        "for x in range(0,len(dataSet), fold_steps):\n",
        "    fold_locations.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4r-1IZnpzKj",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzFM320p1Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index - 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index - 22\n",
        "\n",
        "    indices = list(reversed(indices))\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def singleStepDataSplit(dataset, target, startIndex, endIndex,\n",
        "                steps, future_steps):  \n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "\n",
        "    max_index = 22 * future_steps\n",
        "    target_size = round(21.75 * future_steps)\n",
        "\n",
        "    startIndex = startIndex + history_size\n",
        "\n",
        "    if endIndex is None:\n",
        "        endIndex = len(dataset) - max_index\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        dataIndices = getIndices(i,steps)\n",
        "        data.append(dataset[dataIndices])\n",
        "        labels.append(target[i+target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def getFutureIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex + 22\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index + 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index + 22\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def splitData(dataset, target, start_index, end_index, steps, future_steps):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "    target_size = 22 * future_steps\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = getIndices(i,steps)\n",
        "        data.append(dataset[indices])\n",
        "        indiciesL = getFutureIndices(i, future_steps)\n",
        "        labels.append(target[indiciesL])\n",
        "\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nd5E-y_o1HY",
        "colab_type": "text"
      },
      "source": [
        "## Single-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseG60kHb2hB",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYFUp6Mb98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def singleStepLSTM():\n",
        "    singleStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(32, input_shape=(HISTORY_STEPS, len(features))),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    singleStepLSTMModel.compile(optimizer='adam', loss='mse')\n",
        "    return singleStepLSTMModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJqrxLV9xCEB",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmajAmS4xEs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "39fe0b72-5a73-468e-f873-e5b99c568799"
      },
      "source": [
        "dataVal = []\n",
        "\n",
        "def trainModel(history_steps, future_step):\n",
        "\n",
        "    models = []\n",
        "    results = []\n",
        "\n",
        "    for x in range(1, FOLDS):\n",
        "\n",
        "        model = singleStepLSTM()\n",
        "\n",
        "        valIndex = fold_locations[x]\n",
        "        \n",
        "        if (x==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[x+1]\n",
        "\n",
        "        xTrain, yTrain = singleStepDataSplit(dataSet, dataSet[:, 0], 0, valIndex, history_steps, future_step)\n",
        "        xVal, yVal = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, history_steps, future_step)\n",
        "\n",
        "        dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "        dataTrain = dataTrain.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "        dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        print(\"--------------------- Model validated on fold \", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "        result = model.fit(dataTrain, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                            validation_data=dataVal, validation_steps=50)\n",
        "        \n",
        "        models.append(model)\n",
        "        results.append(result)\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def createModelsForAllSteps():\n",
        "\n",
        "    for i in range(1,FUTURE_STEPS+1):\n",
        "\n",
        "        print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month\", \"%d/%d &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\" % (i, FUTURE_STEPS))\n",
        "\n",
        "        models = trainModel(HISTORY_STEPS, i)\n",
        "        allModels.append(models)\n",
        "\n",
        "\n",
        "    return allModels\n",
        "\n",
        "allModels = createModelsForAllSteps()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 1/3 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1573 - val_loss: 0.1675\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "100/100 [==============================] - 1s 15ms/step - loss: 0.2768 - val_loss: 0.3894\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4264 - val_loss: 0.2383\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3627 - val_loss: 0.0265\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 2/3 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1564 - val_loss: 0.2692\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2032 - val_loss: 0.2014\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.4179 - val_loss: 0.1929\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3737 - val_loss: 0.0432\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 3/3 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.1346 - val_loss: 0.3576\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.3645 - val_loss: 0.4644\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2528 - val_loss: 0.2570\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "100/100 [==============================] - 1s 14ms/step - loss: 0.2455 - val_loss: 0.0439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpsQrU84mv0",
        "colab_type": "text"
      },
      "source": [
        "### Single-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEgXTi80WseN",
        "colab_type": "code",
        "outputId": "3af34eac-ef32-44d3-cc90-748c812c82ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "allMses = []\n",
        "allClassifications = []\n",
        "bestGuessClassifications = []\n",
        "relaxedGuessClassifications = []\n",
        "\n",
        "def singleStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    correctDirection = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    print(noDatapoints)\n",
        "\n",
        "    noPredictions = 6\n",
        "\n",
        "    mse = model.evaluate(xTest,yTest)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        prediction = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        if((current > prediction) == (current > future)):\n",
        "                correctDirection = correctDirection + 1\n",
        "\n",
        "    #print(\"-------------------------------\")\n",
        "    #print(\"MSE: \" + str(round(mse,3)))\n",
        "    directionClass = correctDirection / noDatapoints\n",
        "    #print(\"Direction classification: \" + str(round(directionClass,3)))\n",
        "    #print(\"-------------------------------\")\n",
        "\n",
        "    mses.append(mse)\n",
        "    classifications.append(directionClass)\n",
        "\n",
        "    return mses, classifications\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        print(\"running test\")\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTest, yTest = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        mses,classifications = singleStepModelTests(models[i-1], xTest, yTest)\n",
        "\n",
        "        modelMses.append(mses)\n",
        "        modelClassifications.append(classifications)\n",
        "\n",
        "        meanMse = np.mean(modelMses)\n",
        "        meanClass = np.mean(modelClassifications)\n",
        "    \n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "    #print(\"Average MSE: \" + str(meanMse))\n",
        "    #print(\"Average classification: \" + str(np.mean(classifications)))\n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "\n",
        "    return modelMses, modelClassifications\n",
        "\n",
        "\n",
        "def bestGuessTests(models):\n",
        "\n",
        "    valIndex = fold_locations[FOLDS-1]\n",
        "    endIndex = None\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    xTest, yTest = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    for datapoint in range(len(xTest)):\n",
        "\n",
        "        past = tf.constant([xTest[datapoint]])\n",
        "        future = yTest[datapoint]\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "\n",
        "            prediction = models[j].predict(past)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        actualMax = np.argmax(future)\n",
        "        predictedMax = np.argmax(predictions)\n",
        "\n",
        "        futureRemovingMax = np.delete(future, actualMax)\n",
        "        actual2ndMax = np.argmax(futureRemovingMax)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "    #print(\"---------------\")\n",
        "    bestMonthClass = correctMax / len(xTest)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xTest)\n",
        "\n",
        "    #print(\"Correct best month: \" + str(round(bestMonthClass,3)))\n",
        "\n",
        "    return bestMonthClass, bestMonthRelaxedClass\n",
        "\n",
        "def runBestGuessTests(allModels):\n",
        "\n",
        "    foldPerformances = []\n",
        "    relaxedFoldperformances = []\n",
        "\n",
        "    for i in range(len(allModels[0])):\n",
        "\n",
        "        print(\"running best guess test\")\n",
        "\n",
        "        foldModels = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "            foldModels.append(allModels[j][i])\n",
        "\n",
        "        foldPerformance, relaxedFoldperformance = bestGuessTests(foldModels)\n",
        "\n",
        "        foldPerformances.append(foldPerformance)\n",
        "        relaxedFoldperformances.append(relaxedFoldperformance)\n",
        "\n",
        "    return foldPerformances, relaxedFoldperformances\n",
        "\n",
        "\n",
        "def singleStepExperiments():\n",
        "    \n",
        "    print(\"MODELS CREATED\")\n",
        "\n",
        "    for modelsForOneStep in allModels:\n",
        "        print(\"MODEL STEP TESTS\")\n",
        "\n",
        "        modelMses, modelClassifications = runModels(modelsForOneStep)\n",
        "        allMses.append(modelMses)\n",
        "        allClassifications.append(modelClassifications)\n",
        "\n",
        "    print(\"MODEL STEP TESTS COMPLETE\")\n",
        "    print(\"TESTING BEST GUESS ABILITY\")\n",
        "\n",
        "    bestGuessClassifications, relaxedGuessClassifications = runBestGuessTests(allModels)\n",
        "\n",
        "    #bestGuessClassifications.append(bestGuess)\n",
        "    #relaxedGuessClassifications.append(relaxedGuess)\n",
        "\n",
        "    print(bestGuessClassifications)\n",
        "    print(relaxedGuessClassifications)\n",
        "\n",
        "    print(\"TESTING COMPLETE\")\n",
        "\n",
        "singleStepExperiments()\n",
        "\n",
        "print(bestGuessClassifications) \n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODELS CREATED\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2821\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3548\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3477\n",
            "running test\n",
            "445\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0272\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3391\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.1927\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2395\n",
            "running test\n",
            "445\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0419\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3723\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4548\n",
            "running test\n",
            "507\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.2552\n",
            "running test\n",
            "445\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.0453\n",
            "MODEL STEP TESTS COMPLETE\n",
            "TESTING BEST GUESS ABILITY\n",
            "running best guess test\n",
            "running best guess test\n",
            "running best guess test\n",
            "running best guess test\n",
            "[[0.3842696629213483, 0.37303370786516854, 0.21123595505617979, 0.29213483146067415]]\n",
            "[[0.5955056179775281, 0.37303370786516854, 0.5101123595505618, 0.3842696629213483]]\n",
            "TESTING COMPLETE\n",
            "[[0.3842696629213483, 0.37303370786516854, 0.21123595505617979, 0.29213483146067415]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-8mJXyPjrpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ba404977-9233-48db-ae63-1c4884a45311"
      },
      "source": [
        "print(allMses)                      #shape = FUTURE_STEPS, FOLDS\n",
        "print(allClassifications)           #shape = FUTURE_STEPS, FOLDS\n",
        "print(bestGuessClassifications)      #shape = FOLDS\n",
        "print(relaxedGuessClassifications)   #shape = FOLDS"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.28208333253860474], [0.35479700565338135], [0.3477408289909363], [0.027156421914696693]], [[0.3391296863555908], [0.19265110790729523], [0.2394864857196808], [0.04186803475022316]], [[0.3722698986530304], [0.4547564387321472], [0.25516942143440247], [0.04531000927090645]]]\n",
            "[[[0.32741617357001973], [0.6587771203155819], [0.21893491124260356], [0.6876404494382022]], [[0.33925049309664695], [0.6587771203155819], [0.21893491124260356], [0.6449438202247191]], [[0.3333333333333333], [0.6587771203155819], [0.21893491124260356], [0.6134831460674157]]]\n",
            "[[0.3842696629213483, 0.37303370786516854, 0.21123595505617979, 0.29213483146067415]]\n",
            "[[0.5955056179775281, 0.37303370786516854, 0.5101123595505618, 0.3842696629213483]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rudFJZfKboB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd05683b-e391-4df7-896c-afe75dfff760"
      },
      "source": [
        "print(allMses[0])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.28208333253860474], [0.35479700565338135], [0.3477408289909363], [0.027156421914696693]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwgG0U6-gUrZ",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DGg4vGuUmRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(mses,directionClass,bestClass):\n",
        "\n",
        "    for i in range(FUTURE_STEPS):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(mses[i]))\n",
        "        print(\"Dir: \" + str(directionClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "printResults(allMses, allClassifications, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uwx3VvAnnRN",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TYzy6YXnpjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_time_steps(length,steps):\n",
        "    return list(np.arange(-length, 0,step=steps))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\n",
        "    marker = ['.-', 'rx', 'go']\n",
        "    time_steps = create_time_steps(TIME_LAGS,STEP)\n",
        "\n",
        "    if delta:\n",
        "        future = delta\n",
        "    else:\n",
        "        future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "        if i:\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                    label=labels[i])\n",
        "        else:\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt\n",
        "\n",
        "\n",
        "for x, y in dataVal.take(1):\n",
        "    plot = show_plot([x[0][:, 0].numpy(), y[0].numpy(),\n",
        "                        model.predict(x)[0]], PREDICTION_HORIZON,\n",
        "                    'Single Step Prediction')\n",
        "    print(model.predict(x)[0])\n",
        "    plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1syGFxznuVLK",
        "colab_type": "text"
      },
      "source": [
        "## Multi-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHJMXYsuZWp",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0P_sbFRuhMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiStepLSTM():\n",
        "    multiStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(units=32, return_sequences=True, input_shape = (HISTORY_STEPS, len(features))),\n",
        "        layers.LSTM(16, activation='relu'),\n",
        "        layers.Dense(FUTURE_STEPS)\n",
        "    ])\n",
        "\n",
        "    multiStepLSTMModel.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mse')\n",
        "    return multiStepLSTMModel\n",
        "\n",
        "multiStepModel = multiStepLSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IwcoGcu3mP",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UAjl2pn0eT",
        "colab_type": "code",
        "outputId": "f5a027cf-8cb6-44b6-efaa-7770b1fba15d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "models = []\n",
        "results = []\n",
        "dataTrainMulti = []\n",
        "\n",
        "for x in range(1, FOLDS):\n",
        "\n",
        "    valIndex = fold_locations[x]\n",
        "\n",
        "    multiStepModel = multiStepLSTM()\n",
        "    \n",
        "    if (x==FOLDS-1):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[x+1]\n",
        "\n",
        "    xTrainMulti, yTrainMulti = splitData(dataSet, dataSet[:, 0], 0, valIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "    xValMulti, yValMulti = splitData(dataSet, dataSet[:, 0], valIndex, None, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    dataTrainMulti = tf.data.Dataset.from_tensor_slices((xTrainMulti, yTrainMulti))\n",
        "    dataTrainMulti = dataTrainMulti.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    dataValMulti = tf.data.Dataset.from_tensor_slices((xValMulti, yValMulti))\n",
        "    dataValMulti = dataValMulti.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    print(\"--------------------- Model\", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "    result = multiStepModel.fit(dataTrainMulti, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                        validation_data=dataValMulti, validation_steps=50)\n",
        "    \n",
        "    models.append(multiStepModel)\n",
        "    results.append(result)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------- Model 1/4 --------------------------\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.1267 - val_loss: 0.9395\n",
            "--------------------- Model 2/4 --------------------------\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.1384 - val_loss: 0.4291\n",
            "--------------------- Model 3/4 --------------------------\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.6042 - val_loss: 0.3162\n",
            "--------------------- Model 4/4 --------------------------\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.2574 - val_loss: 0.3167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Uaxl7U4rEH",
        "colab_type": "text"
      },
      "source": [
        "### Multi-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMsesMulti = []\n",
        "allClassificationsMulti = []\n",
        "bestGuessClassificationsMulti = []\n",
        "relaxedGuessClassificationsMulti = []\n",
        "\n",
        "def multiStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    correctDirection = [0,0,0]\n",
        "    totalSquaredError = [0,0,0]\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    noPredictions = len(totalSquaredError)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        predictions = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        futureRemovingMax = np.delete(future, actualMax)\n",
        "        actual2ndMax = np.argmax(futureRemovingMax)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "        for y in range(noPredictions):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "\n",
        "    #print(\"---------------\")\n",
        "    for x in range(noPredictions):\n",
        "        mse = totalSquaredError[x] / noDatapoints\n",
        "        mses.append(mse)\n",
        "        #print(\"MSE (Month \" + str(x+1) + \"): \" + str(round(mse,3)))\n",
        "\n",
        "    averageMSE = (sum(totalSquaredError) / noDatapoints) / noPredictions\n",
        "    #print(\"Average MSE: \" + str(round(averageMSE,3)))\n",
        "\n",
        "\n",
        "    #print(\"---------------\")\n",
        "    for x in range(noPredictions):\n",
        "        percentInterval = correctDirection[x] / noDatapoints\n",
        "        classifications.append(percentInterval)\n",
        "        #print(\"Direction (Month \" + str(x+1) + \"): \" + str(round(percentInterval,3)))\n",
        "\n",
        "    directionClass = (sum(correctDirection) / noDatapoints) / noPredictions\n",
        "    #print(\"Average classification: \" + str(round(directionClass,3)))\n",
        "\n",
        "    bestMonthClass = correctMax / noDatapoints\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / noDatapoints\n",
        "\n",
        "    allMsesMulti.append(mses)\n",
        "    allClassificationsMulti.append(classifications)\n",
        "    bestGuessClassificationsMulti.append(bestMonthClass)\n",
        "    relaxedGuessClassificationsMulti.append(bestMonthRelaxedClass)\n",
        "\n",
        "    #return mses, classifications\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTestMulti, yTestMulti = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        multiStepModelTests(models[i-1], xTestMulti, yTestMulti)\n",
        "\n",
        "        #modelMses.append(mses)\n",
        "        #modelClassifications.append(classifications)\n",
        "\n",
        "    #monthAverageMses = []\n",
        "    #monthAverageClass = []\n",
        "\n",
        "    #for i in range(FUTURE_STEPS):\n",
        "\n",
        "    #    totalMse = 0\n",
        "    #    totalClass = 0\n",
        "\n",
        "    #    for j in range(len(modelMses)):\n",
        "    #        totalMse = totalMse + modelMses[j][i]\n",
        "    #        totalClass = totalClass + modelClassifications[j][i]\n",
        "\n",
        "    #    meanMse = totalMse / len(modelMses)\n",
        "    #    meanClass = totalClass / len(modelMses)\n",
        "\n",
        "    #    monthAverageMses.append(meanMse)\n",
        "    #    monthAverageClass.append(meanClass)\n",
        "\n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "    #print(\"Average MSE: \" + str(meanMse))\n",
        "    #print(\"Average classification: \" + str(np.mean(classifications)))\n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "\n",
        "    #return monthAverageMses, monthAverageClass\n",
        "\n",
        "runModels(models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GoqA1iO8TQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ec5a7832-6d94-4ba8-c1cb-b2106bd624b4"
      },
      "source": [
        "allMsesMulti = list(map(list, zip(*allMsesMulti)))\n",
        "allClassificationsMulti = list(map(list, zip(*allClassificationsMulti)))\n",
        "\n",
        "print(allMsesMulti)\n",
        "print(allClassificationsMulti)\n",
        "print(bestGuessClassificationsMulti)\n",
        "print(relaxedGuessClassificationsMulti)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.368149258477947, 0.7458649629555281, 0.18965386960754538, 0.17624082139322075], [0.5418028138295523, 0.7402328365651868, 0.21322863096489184, 0.20829377411543798], [0.4679014906467884, 0.6405907022683212, 0.20986167706327624, 0.5573958810242827]]\n",
            "[[0.40433925049309666, 0.6074950690335306, 0.45956607495069035, 0.4764044943820225], [0.45759368836291914, 0.6094674556213018, 0.3905325443786982, 0.5438202247191011], [0.3530571992110454, 0.6587771203155819, 0.46745562130177515, 0.5797752808988764]]\n",
            "[0.1992110453648915, 0.22879684418145957, 0.6193293885601578, 0.37303370786516854]\n",
            "[0.47731755424063116, 0.7120315581854043, 0.6232741617357002, 0.37303370786516854]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSYYPtFgP4i",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2SBad6gSMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(monthAverageMses,monthAverageClass,bestClass):\n",
        "\n",
        "    for i in range(len(monthAverageMses)):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(monthAverageMses[i]))\n",
        "        print(\"Dir: \" + str(monthAverageClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "printResults(monthAverageMses, monthAverageClass, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tii3SZcOw1qb",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR0uE5bfw5uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(TIME_LAGS,STEP)\n",
        "  num_out = len(true_future) * FUTURE_STEP\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
        "  plt.plot(np.arange(num_out, step=FUTURE_STEP), np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out,step=FUTURE_STEP), np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "model = models[-1]\n",
        "\n",
        "for x, y in dataTrainMulti.take(1):\n",
        "\n",
        "    print(x)\n",
        "\n",
        "    #print((multiStepModel.predict(x)[0]).index(max(multiStepModel.predict(x)[0])))\n",
        "    print(model.predict(x)[0])\n",
        "    multi_step_plot(x[0], y[0], model.predict(x)[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJ7pc31UP8k",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKanocQUSfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "68a50911-c20d-417d-f0d8-22bbd3b07834"
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "gc.create(title=\"TestResults01\",folder=\"1zb8cLLf2RtYz9RuofDhGDgmTAoXD2VnE\")\n",
        "\n",
        "sh = gc.open('TestResults01')\n",
        "\n",
        "sh.add_worksheet('test2',rows=5, cols=20) \n",
        "\n",
        "wk1 = sh[0]\n",
        "\n",
        "titles = ['SINGLE_STEP','MSE(Fold1)','MSE(Fold2)','MSE(Fold3)','MSE(Fold4)','MSE(avg)',\n",
        "          'Dir(Fold1)','Dir(Fold2)','Dir(Fold3)','Dir(Fold4)','Dir(avg)']\n",
        "\n",
        "shiftSize = FUTURE_STEPS+5\n",
        "\n",
        "wk1.insert_rows(row = 1, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "mseAvgs = []\n",
        "dirAvgs = []\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMses[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allMses[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgs.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassifications[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allClassifications[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgs.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = step+1, number = 1, values = row)\n",
        "\n",
        "\n",
        "titles[0] = 'MULTI-STEP'\n",
        "\n",
        "wk1.insert_rows(row = shiftSize, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMsesMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allMsesMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgs.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassificationsMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allClassificationsMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgs.append(mean)\n",
        "\n",
        "    print(row)\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+step+2, number = 1, values = row)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Month 1', '0.368149258477947', '0.7458649629555281', '0.18965386960754538', '0.17624082139322075', 0.3699772281085603, '0.40433925049309666', '0.6074950690335306', '0.45956607495069035', '0.4764044943820225', '0.486951222214835']\n",
            "['Month 2', '0.5418028138295523', '0.7402328365651868', '0.21322863096489184', '0.20829377411543798', 0.4258895138687672, '0.45759368836291914', '0.6094674556213018', '0.3905325443786982', '0.5438202247191011', '0.500353478270505']\n",
            "['Month 3', '0.4679014906467884', '0.6405907022683212', '0.20986167706327624', '0.5573958810242827', 0.4689374377506671, '0.3530571992110454', '0.6587771203155819', '0.46745562130177515', '0.5797752808988764', '0.5147663054318197']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_1JpTDehzM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a49a80aa-3af9-4d35-a952-26dd2f58becb"
      },
      "source": [
        "print(allMsesMulti[0][0])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.368149258477947\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}