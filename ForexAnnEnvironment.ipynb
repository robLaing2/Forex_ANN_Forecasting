{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOskYm0ZPdYzSIAlhg/1Nmf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "67e0f987-b4c7-445c-d192-ab08017b0b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "#!pip install FRB\n",
        "!pip install fred\n",
        "!pip install mock\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.0.0\n",
        "\n",
        "import fred\n",
        "from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: requests>=2.7.0 in /tensorflow-2.1.0/python3.6 (from quandl) (2.22.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.25.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.8 in /tensorflow-2.1.0/python3.6 (from quandl) (1.18.1)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.3.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from quandl) (1.14.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.7.0->quandl) (1.25.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /tensorflow-2.1.0/python3.6 (from dbnomics) (2.22.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (0.25.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.18.4->dbnomics) (1.25.8)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /tensorflow-2.1.0/python3.6 (from pandas>=0.21->dbnomics) (1.18.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /tensorflow-2.1.0/python3.6 (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.14.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from fred) (2.22.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->fred) (1.25.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->fred) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->fred) (2019.11.28)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Interest Rate data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBT7oI__I2MS",
        "colab_type": "code",
        "outputId": "2b7f65ed-3cad-4981-f221-fd9675156b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=2016-01-01')\n",
        "\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]\n",
        "\n",
        "def getRatioValues(datasetX, datasetY):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "\n",
        "    for x in range(len(datasetX)):\n",
        "        if (datasetX[x][\"value\"] == '.' or datasetY[x][\"value\"] == '.'):\n",
        "            continue\n",
        "\n",
        "        dates.append(pd.Timestamp(datasetX[x][\"date\"]))\n",
        "        valuesX.append(float(datasetX[x][\"value\"]))\n",
        "        valuesY.append(float(datasetY[x][\"value\"]))\n",
        "\n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    ratioValues = datasetXarr / datasetYarr\n",
        "\n",
        "    data_mean = ratioValues.mean()\n",
        "    data_std = ratioValues.std()\n",
        "    dataNormalised = (ratioValues - data_mean) / data_std\n",
        "\n",
        "    res = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return res\n",
        "\n",
        "GBPEURovrRatio = getRatioValues(GBRovrJson,EURovrJson)\n",
        "\n",
        "print(GBPEURovrRatio[pd.Timestamp('2016-01-04 00:00:00')])\n",
        "\n",
        "GBPEUR1mRatio = getRatioValues(GBR1mJson,EUR1mJson)\n",
        "GBPEUR3mRatio = getRatioValues(GBR3mJson,EUR3mJson)\n",
        "GBPEUR6mRatio = getRatioValues(GBR6mJson,EUR6mJson)\n",
        "GBPEUR12mRatio = getRatioValues(GBR12mJson,EUR12mJson)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.5681298271229611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Inflation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '2018-01-01' and period < '2019-06-01'\"\n",
        "\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "ukCPIdates = []\n",
        "for x in ukCPI.period:\n",
        "    ukCPIdates.append(x)\n",
        "\n",
        "ukCPIarr = np.array(ukCPI.value, dtype=np.float)\n",
        "euCPIarr = np.array(euCPI.value, dtype=np.float)\n",
        "\n",
        "ukEuCpiRatio = ukCPIarr*1000 / euCPIarr*1000\n",
        "\n",
        "# Normalise CPI data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "cpiDict = {ukCPIdates[i]: ukEuCpiRatio[i] for i in range(len(ukCPIdates))}\n",
        "\n",
        "cpiData = {'Date':ukCPI.period, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing International Reserves data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '2018-01-01' and period < '2019-06-01'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRdates = []\n",
        "for x in ukIR.period:\n",
        "    ukIRdates.append(x)\n",
        "\n",
        "ukIRarr = np.array(ukIR.value, dtype=np.float)\n",
        "euIRarr = np.array(euIR.value, dtype=np.float)\n",
        "\n",
        "ukEuIRRatio = ukIRarr*1000 / euIRarr*1000\n",
        "\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {ukIRdates[i]: ukEuIRRatio[i] for i in range(len(ukIRdates))}\n",
        "\n",
        "irData = {'Date':ukIR.period, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Balance of Payments data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "outputId": "8f1c2893-3256-4c6d-a26b-f7a17afe74cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '2018-01-01' and period < '2019-06-01'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPdates = []\n",
        "for x in ukBOP.period:\n",
        "    ukBOPdates.append(x)\n",
        "\n",
        "ukBOParr = np.array(ukBOP.value, dtype=np.float)\n",
        "euBOParr = np.array(euBOP.value, dtype=np.float)\n",
        "\n",
        "ukEuBOPRatio = ukBOParr*1000 / euBOParr*1000\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {ukBOPdates[i]: ukEuBOPRatio[i] for i in range(len(ukBOPdates))}\n",
        "\n",
        "bopData = {'Date':ukBOP.period, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)\n",
        "\n",
        "print (bopDf)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          Date     Value\n",
            "192 2018-01-01  0.819045\n",
            "193 2018-04-01  0.917203\n",
            "194 2018-07-01  0.657281\n",
            "195 2018-10-01  0.281403\n",
            "196 2019-01-01 -0.890774\n",
            "197 2019-04-01 -1.784158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YSsNlwQPnPr",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing FOREX data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "startDate = '2018-01-01'\n",
        "endDate = '2019-01-01'\n",
        "\n",
        "# Get FOREX data\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=startDate, end_date=endDate, returns=\"numpy\")\n",
        "forexDataN = dataGbpEurRate.Value\n",
        "\n",
        "# Normalise data\n",
        "forex_mean = forexDataN.mean()\n",
        "forex_std = forexDataN.std()\n",
        "forexDataN = (forexDataN - forex_mean) / forex_std\n",
        "\n",
        "forexData = {'Date':dataGbpEurRate.Date,'Value':forexDataN}\n",
        "forexDf = pd.DataFrame(forexData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "# Creating full data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaLD_2QagA8w",
        "colab_type": "code",
        "outputId": "6deeb252-ece5-40c4-f507-d1934f5b3ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 12)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "mainDf = pd.DataFrame(columns=['Date','ForexRate','CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR', '1mLIBOR','3mLIBOR','6mLIBOR','12mLIBOR'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        "\n",
        "for index, row in forexDf.iterrows():\n",
        "\n",
        "    newD = row['Date']\n",
        "    roundD = newD.replace(day=1)\n",
        "    quarterD = 1\n",
        "\n",
        "    quarter = newD.quarter\n",
        "\n",
        "    cpi = cpiDict.get(roundD,0)\n",
        "    ir = irDict.get(roundD,0)\n",
        "\n",
        "    switcher={\n",
        "        1:newD.replace(month=1,day=1),\n",
        "        2:newD.replace(month=4,day=1),\n",
        "        3:newD.replace(month=7,day=1),\n",
        "        4:newD.replace(month=10,day=1)\n",
        "    }\n",
        "\n",
        "    quarterD = switcher.get(newD.quarter)\n",
        "\n",
        "    bop = bopDict.get(quarterD,0)\n",
        "\n",
        "    ovrI = GBPEURovrRatio.get(row['Date'], 0)\n",
        "    i1month = GBPEUR1mRatio.get(row['Date'], 0)\n",
        "    i3month = GBPEUR3mRatio.get(row['Date'], 0)\n",
        "    i6month = GBPEUR6mRatio.get(row['Date'], 0)\n",
        "    i12month = GBPEUR12mRatio.get(row['Date'], 0)\n",
        "\n",
        "    mainDf = mainDf.append({'Date':row['Date'],\n",
        "                            'ForexRate':row['Value'],\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovrI,\n",
        "                            '1mLIBOR': i1month,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '12mLIBOR': i12month},\n",
        "                            ignore_index=True)\n",
        "\n",
        "print(mainDf)\n",
        "\n",
        "# Split and format data\n",
        "futureDistance = 0\n",
        "historySize = 6"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          Date  ForexRate  CPIRatio   IRRatio  BOPRatio  OvrLIBOR   1mLIBOR  \\\n",
            "0   2018-01-02 -0.264857   2.020758 -2.182594  0.819045 -0.003623  0.159075   \n",
            "1   2018-01-03 -0.558328   2.020758 -2.182594  0.819045 -0.009908  0.152681   \n",
            "2   2018-01-04 -0.696432   2.020758 -2.182594  0.819045 -0.020413  0.151342   \n",
            "3   2018-01-05 -0.308015   2.020758 -2.182594  0.819045 -0.022456  0.176140   \n",
            "4   2018-01-08  0.296189   2.020758 -2.182594  0.819045 -0.024732  0.156163   \n",
            "..         ...       ...        ...       ...       ...       ...       ...   \n",
            "249 2018-12-24 -1.775367  -0.204977  0.399432  0.281403 -0.970879 -1.114289   \n",
            "250 2018-12-26 -1.775367  -0.204977  0.399432  0.281403  0.000000  0.000000   \n",
            "251 2018-12-27 -1.904839  -0.204977  0.399432  0.281403 -1.072306 -1.105415   \n",
            "252 2018-12-28 -1.818525  -0.204977  0.399432  0.281403 -1.056812 -1.116854   \n",
            "253 2018-12-31 -1.343793  -0.204977  0.399432  0.281403 -0.919842 -1.100619   \n",
            "\n",
            "      3mLIBOR   6mLIBOR  12mLIBOR  \n",
            "0    0.613045  0.601350  0.054938  \n",
            "1    0.619259  0.603643  0.056504  \n",
            "2    0.613131  0.607150  0.056503  \n",
            "3    0.586940  0.606568  0.056294  \n",
            "4    0.584790  0.605566  0.056187  \n",
            "..        ...       ...       ...  \n",
            "249 -1.198815 -0.322285  0.015835  \n",
            "250  0.000000  0.000000  0.000000  \n",
            "251 -1.224960 -0.324191  0.014884  \n",
            "252 -1.158239 -0.331533  0.015407  \n",
            "253 -1.217043 -0.360579  0.015095  \n",
            "\n",
            "[254 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3pUL5P8rC_d",
        "colab_type": "text"
      },
      "source": [
        "# Standard ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wFbpmT0sFOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def formatData(data, start, end, history, target):\n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    startIndex = start + historySize\n",
        "    endIndex = len(data) - futureDistance\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        indices = range(i-historySize, i)\n",
        "        # Reshape data from (history_size,) to (history_size, 1)\n",
        "        x.append(data[indices])\n",
        "        y.append(data[i+futureDistance])\n",
        "        \n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "TRAIN_SPLIT = round(len(forexData) * 0.7)\n",
        "VALIDATION_SPLIT = round(len(forexData) * 0.85)\n",
        "\n",
        "xTrain, yTrain = formatData(forexData, 0, TRAIN_SPLIT, historySize, futureDistance)\n",
        "xVal, yVal = formatData(forexData, TRAIN_SPLIT, VALIDATION_SPLIT, historySize, futureDistance)\n",
        "xTest, yTest = formatData(forexData, VALIDATION_SPLIT, None, historySize, futureDistance)\n",
        "\n",
        "BATCH_SIZE = 30\n",
        "BUFFER_SIZE = 10\n",
        "\n",
        "# Form training tensors and shuffle etc.\n",
        "dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "dataTrain = dataTrain.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "# Form validation tensors and shuffle etc.\n",
        "dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "# Create model\n",
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 100\n",
        "\n",
        "def standard_ann_model():\n",
        "\tmodel = keras.Sequential([\n",
        "        layers.Dense(6,input_dim=(6),kernel_initializer='normal',activation='relu'),\n",
        "        layers.Dense(8, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "\tmodel.compile(optimizer='adam', loss='mse')\n",
        "\treturn model\n",
        "\n",
        "model = standard_ann_model()\n",
        "\n",
        "model.fit(dataTrain, epochs=EPOCHS,\n",
        "                     steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=dataVal,\n",
        "                      validation_steps=50)\n",
        "\n",
        "\n",
        "result = model.evaluate(xTest, yTest, batch_size=30)\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Model loss:\", result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIg8KNPOqiyn",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HeS-tpxf97i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def formatData(data, start, end, history, target):\n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    startIndex = start + historySize\n",
        "    endIndex = len(data) - futureDistance\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        indices = range(i-historySize, i)\n",
        "        # Reshape data from (history_size,) to (history_size, 1)\n",
        "        x.append(np.reshape(data[indices], (historySize, 1)))\n",
        "        y.append(data[i+futureDistance])\n",
        "        \n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "TRAIN_SPLIT = round(len(forexData) * 0.7)\n",
        "VALIDATION_SPLIT = round(len(forexData) * 0.85)\n",
        "\n",
        "xTrain, yTrain = formatData(forexData, 0, TRAIN_SPLIT, historySize, futureDistance)\n",
        "xVal, yVal = formatData(forexData, TRAIN_SPLIT, VALIDATION_SPLIT, historySize, futureDistance)\n",
        "xTest, yTest = formatData(forexData, VALIDATION_SPLIT, None, historySize, futureDistance)\n",
        "\n",
        "BATCH_SIZE = 30\n",
        "BUFFER_SIZE = 10\n",
        "\n",
        "# Form training tensors and shuffle etc.\n",
        "dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "dataTrain = dataTrain.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "# Form validation tensors and shuffle etc.\n",
        "dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "# Create model\n",
        "EVALUATION_INTERVAL = 200\n",
        "EPOCHS = 100\n",
        "\n",
        "def lstm_ann_model():\n",
        "    lstm_model = keras.Sequential([\n",
        "        layers.LSTM(8, input_shape=xTrain.shape[-2:]),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    lstm_model.compile(optimizer='adam', loss='mse')\n",
        "    return lstm_model\n",
        "\n",
        "model = lstm_ann_model()\n",
        "\n",
        "model.fit(dataTrain, epochs=EPOCHS,\n",
        "                     steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=dataVal,\n",
        "                      validation_steps=50)\n",
        "\n",
        "\n",
        "result = model.evaluate(xTest, yTest, batch_size=30)\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Model loss:\", result)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsAv1nRFUBD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in dataVal.take(3):\n",
        "  plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
        "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
        "  plot.show()\n",
        "\n",
        "def create_time_steps(length):\n",
        "  return list(range(-length, 0))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "               label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}