{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y23CLo2oUco-O4CAkKZhYsjzzzbnTeLP",
      "authorship_tag": "ABX9TyO781ZTB+/wu0RL5yST9F+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "e6d99200-e8f4-4bed-a9ac-e34bab95f4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "#!pip install FRB\n",
        "!pip install fred\n",
        "!pip install mock\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.0.0\n",
        "\n",
        "import fred\n",
        "from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, CuDNNLSTM\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.0.3)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.12.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.18.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (1.0.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2.8)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (1.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.12.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fred) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (1.24.3)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knovwSza04MP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSX-AVfVGK6s",
        "colab_type": "code",
        "outputId": "85a95c14-9903-4045-a3ef-a22b9b788ea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "START_DATE = '2001-01-01'\n",
        "END_DATE = '2020-02-01'\n",
        "\n",
        "pd.set_option('display.max_rows', 25)\n",
        "pd.set_option('display.max_columns', 25)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mBJkhEqGfRq",
        "colab_type": "text"
      },
      "source": [
        "## Moving average function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpuooBtRGero",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMovingAverages(data, windowSize):\n",
        "\n",
        "    movingAverages = []\n",
        "\n",
        "    for x in range(len(data)):\n",
        "        if (x < windowSize):\n",
        "            window = data[:x+1]\n",
        "        else:\n",
        "            window = data[x-(windowSize - 1):x+1]\n",
        "        \n",
        "        total = sum(window)\n",
        "        average = total / len(window)\n",
        "        movingAverages.append(average)\n",
        "\n",
        "    return movingAverages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n68WYYVB6UK7",
        "colab_type": "text"
      },
      "source": [
        "## FOREX data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "outputId": "21243607-a294-456d-f8e7-3647a17f07be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Get FOREX data\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=START_DATE, end_date=END_DATE, returns=\"numpy\")\n",
        "forexDataN = dataGbpEurRate.Value\n",
        "\n",
        "forexMonthMovAvg = getMovingAverages(forexDataN, 22)\n",
        "forexMonthMovAvg = np.asarray(forexMonthMovAvg)\n",
        "\n",
        "# Normalise data\n",
        "forex_mean = forexMonthMovAvg.mean()\n",
        "forex_std = forexMonthMovAvg.std()\n",
        "forexMonthMovAvg = (forexMonthMovAvg - forex_mean) / forex_std\n",
        "\n",
        "ukFOREXdates = []\n",
        "for x in dataGbpEurRate.Date:\n",
        "    ukFOREXdates.append(pd.Timestamp(x))\n",
        "\n",
        "forexData = {'Date':ukFOREXdates,'Value':forexMonthMovAvg}\n",
        "mainDf = pd.DataFrame(forexData)\n",
        "\n",
        "print(forex_mean)\n",
        "print(forex_std)"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.309593875180065\n",
            "0.16475970732268408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "## Interest Rate Data (INT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUTeDp07W41L",
        "colab_type": "text"
      },
      "source": [
        "### INT data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0f5HNs21pcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgecCRUBkiR",
        "colab_type": "text"
      },
      "source": [
        "### INT data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkAjnFLBlhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanDataSets(dataset):\n",
        "\n",
        "    dataDict = {pd.Timestamp(dataset[i][\"date\"]): dataset[i][\"value\"] for i in range(len(dataset))}\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "        value = dataDict.get(row['Date'], 1000000)\n",
        "\n",
        "        if (value=='.'):\n",
        "            value = 1000000\n",
        "\n",
        "        if(value==1000000):\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataDict.get(dateBelow, 1000000)\n",
        "            valueAbove = dataDict.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "GBRovrC = cleanDataSets(GBRovrJson)\n",
        "EURovrC = cleanDataSets(EURovrJson)\n",
        "GBR3mC = cleanDataSets(GBR3mJson)\n",
        "EUR3mC = cleanDataSets(EUR3mJson)\n",
        "GBR6mC = cleanDataSets(GBR6mJson)\n",
        "EUR6mC = cleanDataSets(EUR6mJson)\n",
        "GBR12mC = cleanDataSets(GBR12mJson)\n",
        "EUR12mC = cleanDataSets(EUR12mJson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euiAqH5oXFmC",
        "colab_type": "text"
      },
      "source": [
        "### INT feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjzi_yf1sjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDifferenceFeatures(xDict, yDict):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "    ratioValues = []                      \n",
        "\n",
        "    for k,v in xDict.items():\n",
        "\n",
        "        match = yDict.get(k, 0)\n",
        "        valuesX.append(float(v))\n",
        "        valuesY.append(float(match))\n",
        "        dates.append(k)\n",
        " \n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    diffValues = datasetXarr - datasetYarr\n",
        "\n",
        "    movingAvg = getMovingAverages(diffValues, 22)\n",
        "    movingAvg = np.asarray(movingAvg)\n",
        "\n",
        "    data_mean = movingAvg.mean()\n",
        "    data_std = movingAvg.std()\n",
        "    dataNormalised = (movingAvg - data_mean) - data_std\n",
        "\n",
        "    res = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return res\n",
        "\n",
        "ovrRatioMovAvg = getDifferenceFeatures(GBRovrC,EURovrC)\n",
        "threeMRatioMovAvg = getDifferenceFeatures(GBR3mC,EUR3mC)\n",
        "sixMRatioMovAvg = getDifferenceFeatures(GBR6mC,EUR6mC)\n",
        "twelveMRatioMovAvg = getDifferenceFeatures(GBR12mC,EUR12mC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "## Inflation data (CPI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUCPuwpYOnn",
        "colab_type": "text"
      },
      "source": [
        "### CPI data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVanjbf-n1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "ukCPIDict = {ukCPI.period.iloc[i]: ukCPI.value.iloc[i] for i in range(len(ukCPI))}\n",
        "euCPIDict = {euCPI.period.iloc[i]: euCPI.value.iloc[i] for i in range(len(euCPI))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhffkl2I-kY0",
        "colab_type": "text"
      },
      "source": [
        "### CPI data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxREJ3rFVj5",
        "colab_type": "code",
        "outputId": "796ac611-bb5b-417a-9deb-849816d7dd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def cleanMonthlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        roundD = row['Date'].replace(day=1)\n",
        "\n",
        "        value= dataset.get(pd.Timestamp(roundD),1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            clean = False\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataset.get(dateBelow, 1000000)\n",
        "            valueAbove = dataset.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    if(clean==True):\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukCPIDictC = cleanMonthlyData(ukCPIDict)\n",
        "euCPIDictC = cleanMonthlyData(euCPIDict)"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T2dZu4RA6Sl",
        "colab_type": "text"
      },
      "source": [
        "### CPI feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = []\n",
        "ukCPIarr = []\n",
        "euCPIarr = []\n",
        "\n",
        "for k,v in ukCPIDictC.items():\n",
        "\n",
        "    match = euCPIDictC.get(k, 0)\n",
        "\n",
        "    ukCPIarr.append(v)\n",
        "    euCPIarr.append(match)\n",
        "    dates.append(k)\n",
        "\n",
        "ukCPIarr = np.array(ukCPIarr, dtype=np.float)\n",
        "euCPIarr = np.array(euCPIarr, dtype=np.float)\n",
        "\n",
        "ukEuCpiRatio = ukCPIarr - euCPIarr\n",
        "\n",
        "# Normalise CPI data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "cpiDict = {dates[i]: ukEuCpiRatio[i] for i in range(len(dates))}\n",
        "\n",
        "cpiData = {'Date':dates, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "## International Reserves data (IR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeoJsXNEQA_m",
        "colab_type": "text"
      },
      "source": [
        "### IR data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXRsvqQIQMG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRDict = {ukIR.period.iloc[i]: ukIR.value.iloc[i] for i in range(len(ukIR))}\n",
        "euIRDict = {euIR.period.iloc[i]: euIR.value.iloc[i] for i in range(len(euIR))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj0vLPaBQFde",
        "colab_type": "text"
      },
      "source": [
        "### IR data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZbMYaFhQREG",
        "colab_type": "code",
        "outputId": "f68c9ded-0381-40fe-c67a-a4d461970cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ukIRDictC = cleanMonthlyData(ukIRDict)\n",
        "euIRDictC = cleanMonthlyData(euIRDict)"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCU1PotbQH3d",
        "colab_type": "text"
      },
      "source": [
        "### IR feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IRdates = []\n",
        "ukIRarr = []\n",
        "euIRarr = []\n",
        "\n",
        "for k,v in ukIRDictC.items():\n",
        "\n",
        "    match = euIRDictC.get(k, 0)\n",
        "\n",
        "    ukIRarr.append(v)\n",
        "    euIRarr.append(match)\n",
        "    IRdates.append(k)\n",
        "\n",
        "\n",
        "ukIRarr = np.array(ukIRarr, dtype=np.float)\n",
        "euIRarr = np.array(euIRarr, dtype=np.float)\n",
        "\n",
        "ukEuIRRatio = ukIRarr / euIRarr\n",
        "\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {IRdates[i]: ukEuIRRatio[i] for i in range(len(IRdates))}\n",
        "\n",
        "irData = {'Date':IRdates, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Balance of Payments data (BOP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FpSuRNLR8Rb",
        "colab_type": "text"
      },
      "source": [
        "### BOP data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_2Bg9PSEym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPDict = {ukBOP.period.iloc[i]: ukBOP.value.iloc[i] for i in range(len(ukBOP))}\n",
        "euBOPDict = {euBOP.period.iloc[i]: euBOP.value.iloc[i] for i in range(len(euBOP))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EsjDOHjR_Q-",
        "colab_type": "text"
      },
      "source": [
        "### BOP data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsVJ5XKGSmu_",
        "colab_type": "code",
        "outputId": "a198334d-450e-404a-c938-75c6b7187d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def cleanQuarterlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        date = row['Date']\n",
        "        dateMonth = date.replace(day=1)\n",
        "        dateQuarter = date.quarter\n",
        "        \n",
        "        switcher={\n",
        "            1:date.replace(month=1,day=1),\n",
        "            2:date.replace(month=4,day=1),\n",
        "            3:date.replace(month=7,day=1),\n",
        "            4:date.replace(month=10,day=1)\n",
        "        }\n",
        "\n",
        "        dateRoundedQuarter = switcher.get(dateQuarter)\n",
        "\n",
        "        value = dataset.get(dateRoundedQuarter,1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            mainDf.drop([index], inplace=True)\n",
        "        else:\n",
        "            cleanedDataDict[row['Date']] = value\n",
        "\n",
        "\n",
        "    clean = True\n",
        "    for k,v in cleanedDataDict.items():\n",
        "        if (v==1000000):\n",
        "            clean = False;\n",
        "\n",
        "    if (clean==False):\n",
        "        print(\"Data is unlcean\")\n",
        "    else:\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukBOPDictC = cleanQuarterlyData(ukBOPDict)\n",
        "euBOPDictC = cleanQuarterlyData(euBOPDict)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5T04eISB7G",
        "colab_type": "text"
      },
      "source": [
        "### BOP feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOPdates = []\n",
        "ukBOParr = []\n",
        "euBOParr = []\n",
        "\n",
        "for k,v in ukBOPDictC.items():\n",
        "\n",
        "    match = euBOPDictC.get(k, 0)\n",
        "\n",
        "    ukBOParr.append(v)\n",
        "    euBOParr.append(match)\n",
        "    BOPdates.append(k)\n",
        "\n",
        "ukBOParr = np.array(ukBOParr, dtype=np.float)\n",
        "euBOParr = np.array(euBOParr, dtype=np.float)\n",
        "\n",
        "ukEuBOPRatio = ukBOParr / euBOParr\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {BOPdates[i]: ukEuBOPRatio[i] for i in range(len(BOPdates))}\n",
        "\n",
        "bopData = {'Date':BOPdates, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "## Creating full data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOlDl_FgRI8",
        "colab_type": "code",
        "outputId": "42d4fafc-2d3f-407b-b119-ef010f666728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "completeDf = pd.DataFrame(columns=['Date','ForexRate','CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        " \n",
        "for index, row in mainDf.iterrows():\n",
        "\n",
        "    date = row['Date']\n",
        "    forex = row['Value']\n",
        "    \n",
        "    cpi = cpiDict.get(date, 0)\n",
        "    ir = irDict.get(date,0)\n",
        "    bop = bopDict.get(date,0)\n",
        "\n",
        "    ovrI = ovrRatioMovAvg.get(date, 0)\n",
        "    i3month = threeMRatioMovAvg.get(date, 0)\n",
        "    i6month = sixMRatioMovAvg.get(date, 0)\n",
        "    i12month = twelveMRatioMovAvg.get(date, 0)\n",
        "\n",
        "    completeDf = completeDf.append({'Date':date,\n",
        "                            'ForexRate':forex,\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovrI,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '12mLIBOR': i12month},\n",
        "                            ignore_index=True)\n",
        "\n",
        "#print(completeDf)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9gVEULcO0zD",
        "colab_type": "text"
      },
      "source": [
        "# Variable Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpiLy6YcO5-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables = ['CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR']\n",
        "\n",
        "forex = completeDf['ForexRate'].tolist()\n",
        "correlations = []\n",
        "\n",
        "for x in range(len(variables)):\n",
        "    \n",
        "    column = completeDf[variables[x]].tolist()\n",
        "\n",
        "    r = np.corrcoef(forex, column)\n",
        "\n",
        "    correlations.append(r[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7MnSU94FOw",
        "colab_type": "code",
        "outputId": "ee2ca539-810c-479a-98d9-7eb628dafc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "y_pos = np.arange(0,14,2)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(y_pos, correlations, align='center', alpha=0.5, color=(0.0, 0.0, 0.0, 1))\n",
        "plt.xticks(y_pos, variables)\n",
        "plt.ylabel('Usage')\n",
        "plt.title('Correlations')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMlG3PXw4dX",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSvQDGXwFVJ",
        "colab_type": "text"
      },
      "source": [
        "## Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4_5GXRVwHR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "EPOCHS = 10\n",
        "EVALUATION_INTERVAL = 480\n",
        "VALIDATION_STEPS = 50\n",
        "BATCH_SIZE = 1\n",
        "FOLDS = 5\n",
        "\n",
        "HISTORY_STEPS = 24\n",
        "FUTURE_STEPS = 6\n",
        "\n",
        "features = ['ForexRate']\n",
        "\n",
        "dataSet = completeDf[features]\n",
        "dataSet = dataSet.values\n",
        "\n",
        "fold_steps = math.floor(len(dataSet) / FOLDS)\n",
        "fold_locations = []\n",
        "results = []\n",
        "\n",
        "for x in range(0,len(dataSet), fold_steps):\n",
        "    fold_locations.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4r-1IZnpzKj",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzFM320p1Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index - 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index - 22\n",
        "\n",
        "    indices = list(reversed(indices))\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def singleStepDataSplit(dataset, target, startIndex, endIndex,\n",
        "                steps, future_steps):  \n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "\n",
        "    max_index = 22 * future_steps\n",
        "    target_size = round(21.75 * future_steps)\n",
        "\n",
        "    startIndex = startIndex + history_size\n",
        "\n",
        "    if endIndex is None:\n",
        "        endIndex = len(dataset) - max_index\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        dataIndices = getIndices(i,steps)\n",
        "        data.append(dataset[dataIndices])\n",
        "        labels.append(target[i+target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def getFutureIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex + 22\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index + 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index + 22\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def splitData(dataset, target, start_index, end_index, steps, future_steps):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "    target_size = 22 * future_steps\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = getIndices(i,steps)\n",
        "        data.append(dataset[indices])\n",
        "        indiciesL = getFutureIndices(i, future_steps)\n",
        "        labels.append(target[indiciesL])\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nd5E-y_o1HY",
        "colab_type": "text"
      },
      "source": [
        "## Single-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseG60kHb2hB",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYFUp6Mb98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def singleStepLSTM():\n",
        "    singleStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(32, input_shape=(HISTORY_STEPS, len(features))),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    singleStepLSTMModel.compile(optimizer='adam', loss='mse')\n",
        "    return singleStepLSTMModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJqrxLV9xCEB",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmajAmS4xEs-",
        "colab_type": "code",
        "outputId": "c1a7bfe3-28b4-465a-9e6b-a9d002846f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataVal = []\n",
        "\n",
        "def trainModel(history_steps, future_step):\n",
        "\n",
        "    models = []\n",
        "    results = []\n",
        "\n",
        "    for x in range(1, FOLDS):\n",
        "\n",
        "        model = singleStepLSTM()\n",
        "\n",
        "        valIndex = fold_locations[x]\n",
        "        \n",
        "        if (x==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[x+1]\n",
        "\n",
        "        xTrain, yTrain = singleStepDataSplit(dataSet, dataSet[:, 0], 0, valIndex, history_steps, future_step)\n",
        "        xVal, yVal = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, history_steps, future_step)\n",
        "\n",
        "\n",
        "        dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "        dataTrain = dataTrain.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "        dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        print(\"--------------------- Model validated on fold \", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "        result = model.fit(dataTrain, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                            validation_data=dataVal, validation_steps=50)\n",
        "        \n",
        "        models.append(model)\n",
        "        results.append(result)\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def createModelsForAllSteps():\n",
        "\n",
        "    allModels = []\n",
        "\n",
        "    for i in range(1,FUTURE_STEPS+1):\n",
        "\n",
        "        print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month\", \"%d/%d &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\" % (i, FUTURE_STEPS))\n",
        "\n",
        "        models = trainModel(HISTORY_STEPS, i)\n",
        "        allModels.append(models)\n",
        "\n",
        "\n",
        "    return allModels\n",
        "\n",
        "allModels = createModelsForAllSteps()"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 1/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.0077 - val_loss: 0.4335\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.5855e-04 - val_loss: 0.2292\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 6.1896e-04 - val_loss: 0.0631\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.4127e-04 - val_loss: 0.0250\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0010 - val_loss: 0.0056\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0015 - val_loss: 0.0158\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0028 - val_loss: 0.0507\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0040 - val_loss: 0.3448\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0053 - val_loss: 0.2007\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0048 - val_loss: 0.1177\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0201 - val_loss: 0.3209\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.3946e-04 - val_loss: 0.2106\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0251 - val_loss: 0.2797\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0034 - val_loss: 0.0456\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0028 - val_loss: 0.0441\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0288 - val_loss: 0.0685\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0037 - val_loss: 0.0545\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0025 - val_loss: 0.2894\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0376 - val_loss: 0.0789\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0044 - val_loss: 1.5251\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0132 - val_loss: 0.0313\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 3.9802e-04 - val_loss: 0.0136\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0010 - val_loss: 0.0621\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 6.3983e-04 - val_loss: 0.2322\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0240 - val_loss: 0.0459\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0026 - val_loss: 0.0496\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0027 - val_loss: 0.0605\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0073 - val_loss: 0.4565\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0031 - val_loss: 0.1560\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0340 - val_loss: 0.0061\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0498 - val_loss: 0.9046\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0016 - val_loss: 0.7260\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0013 - val_loss: 1.6693\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0013 - val_loss: 0.0824\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 3.9268e-04 - val_loss: 0.6848\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 3.6457e-04 - val_loss: 0.6179\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0116 - val_loss: 3.5198\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0024 - val_loss: 4.1623\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0019 - val_loss: 4.3113\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0044 - val_loss: 0.1204\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 2/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0436 - val_loss: 0.3709\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0015 - val_loss: 0.2506\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0013 - val_loss: 0.2820\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0017 - val_loss: 0.0129\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0023 - val_loss: 0.0052\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0034 - val_loss: 0.0196\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0053 - val_loss: 0.1190\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0078 - val_loss: 0.2927\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0064 - val_loss: 0.1997\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0064 - val_loss: 0.1943\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0166 - val_loss: 0.3555\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 2.8138e-04 - val_loss: 0.2568\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0264 - val_loss: 0.2771\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0023 - val_loss: 0.1407\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0023 - val_loss: 0.1231\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0231 - val_loss: 0.1242\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0041 - val_loss: 0.0105\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0020 - val_loss: 0.0273\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0328 - val_loss: 0.0131\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0036 - val_loss: 0.3733\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0038 - val_loss: 0.0028\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 2.2454e-04 - val_loss: 6.8394e-04\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.8764e-04 - val_loss: 0.0134\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.2046e-04 - val_loss: 0.5770\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0206 - val_loss: 0.0107\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0020 - val_loss: 0.0072\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0018 - val_loss: 0.0208\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0035 - val_loss: 0.5575\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.2153e-04 - val_loss: 0.1632\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0182 - val_loss: 0.3612\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0334 - val_loss: 0.6705\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.0947e-04 - val_loss: 0.5740\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0011 - val_loss: 1.5279\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.8455e-04 - val_loss: 0.0194\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 9.1115e-05 - val_loss: 0.2722\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.4425e-04 - val_loss: 0.5508\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0128 - val_loss: 2.0697\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0026 - val_loss: 3.6427\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0016 - val_loss: 3.1829\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0023 - val_loss: 0.0150\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 3/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.0149 - val_loss: 0.3146\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 6.9287e-04 - val_loss: 0.2397\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.5793e-04 - val_loss: 0.1740\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.6013e-04 - val_loss: 0.0123\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.0509e-04 - val_loss: 0.0169\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 3.9583e-04 - val_loss: 0.0394\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.2157e-04 - val_loss: 0.1227\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.0671e-04 - val_loss: 0.2841\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.1203e-04 - val_loss: 0.1989\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 6.9035e-04 - val_loss: 0.1282\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0047 - val_loss: 0.2170\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.6496e-04 - val_loss: 0.1197\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0129 - val_loss: 0.2200\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0027 - val_loss: 0.0130\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0022 - val_loss: 0.0497\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0225 - val_loss: 0.6625\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0024 - val_loss: 2.7983\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0013 - val_loss: 3.3741\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0240 - val_loss: 2.0854\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0027 - val_loss: 4.2451\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0074 - val_loss: 0.0104\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.4739e-04 - val_loss: 0.0017\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.4536e-04 - val_loss: 0.0727\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.0748e-04 - val_loss: 0.5425\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0130 - val_loss: 0.3570\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0029 - val_loss: 0.7754\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0017 - val_loss: 0.8653\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0032 - val_loss: 0.5821\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0010 - val_loss: 0.5279\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0212 - val_loss: 0.7156\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.0076 - val_loss: 0.5012\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 2.4432e-04 - val_loss: 0.3478\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.0306e-04 - val_loss: 1.5423\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 1.5428e-04 - val_loss: 0.0425\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.4269e-05 - val_loss: 0.0963\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.6107e-05 - val_loss: 0.7831\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0112 - val_loss: 0.9041\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0023 - val_loss: 0.9216\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0011 - val_loss: 0.8800\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0027 - val_loss: 5.8972e-04\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 4/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0036 - val_loss: 0.1508\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0025 - val_loss: 0.0231\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0026 - val_loss: 9.9604e-04\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0028 - val_loss: 0.0120\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0032 - val_loss: 0.0482\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0035 - val_loss: 0.0350\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0039 - val_loss: 0.1140\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0043 - val_loss: 0.1002\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0038 - val_loss: 0.0392\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0049 - val_loss: 0.0025\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.0041 - val_loss: 0.2175\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 1.4489e-04 - val_loss: 0.2026\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0086 - val_loss: 0.1655\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.5124e-04 - val_loss: 0.1161\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 3.5482e-04 - val_loss: 0.0654\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0143 - val_loss: 0.2320\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0034 - val_loss: 0.1703\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0021 - val_loss: 0.2505\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0191 - val_loss: 0.0261\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0033 - val_loss: 0.0967\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0037 - val_loss: 0.0029\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 9.5947e-05 - val_loss: 0.0015\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 3.3425e-04 - val_loss: 0.0237\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.0752e-04 - val_loss: 0.7132\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0198 - val_loss: 0.0638\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0026 - val_loss: 0.0865\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0010 - val_loss: 0.1128\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0041 - val_loss: 0.1880\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0022 - val_loss: 0.6396\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0133 - val_loss: 1.1360\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0048 - val_loss: 0.5839\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.0221e-04 - val_loss: 0.5316\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.6491e-04 - val_loss: 0.7212\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 6.0286e-05 - val_loss: 0.0520\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.4055e-05 - val_loss: 0.7566\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 4.0573e-05 - val_loss: 1.2043\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0283 - val_loss: 0.4176\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0023 - val_loss: 0.2543\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 9.6111e-04 - val_loss: 0.2362\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0029 - val_loss: 1.7650\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 5/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0017 - val_loss: 0.1308\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0010 - val_loss: 0.0743\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.6590e-04 - val_loss: 0.0128\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.4525e-04 - val_loss: 0.0641\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 6.9213e-04 - val_loss: 0.0016\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 6.2163e-04 - val_loss: 0.0349\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 6.6406e-04 - val_loss: 0.0466\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.4258e-04 - val_loss: 0.1131\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 5.3162e-04 - val_loss: 0.1563\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 6.3481e-04 - val_loss: 3.2620e-04\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0133 - val_loss: 0.2489\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.5951e-04 - val_loss: 0.2169\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0247 - val_loss: 0.1559\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0020 - val_loss: 0.0227\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.8386e-04 - val_loss: 0.0179\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0241 - val_loss: 0.0057\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0024 - val_loss: 0.0129\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0013 - val_loss: 0.0020\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 0.0270 - val_loss: 0.2890\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0027 - val_loss: 0.2674\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0052 - val_loss: 6.4585e-04\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.3238e-04 - val_loss: 6.0593e-04\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 3.7749e-04 - val_loss: 0.0687\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.3204e-04 - val_loss: 0.7392\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0213 - val_loss: 0.1368\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 0.0031 - val_loss: 0.2619\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0012 - val_loss: 0.2478\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0061 - val_loss: 0.2344\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0050 - val_loss: 0.5652\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0176 - val_loss: 1.4432\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0025 - val_loss: 0.3864\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 5s 9ms/step - loss: 2.0486e-04 - val_loss: 0.3435\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.6841e-04 - val_loss: 1.7400\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.4931e-05 - val_loss: 0.0065\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 2.5583e-05 - val_loss: 0.1976\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 4.2274e-05 - val_loss: 0.8256\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0100 - val_loss: 0.2855\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0018 - val_loss: 0.0941\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.1195e-04 - val_loss: 0.0675\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0025 - val_loss: 2.1314\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 6/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0039 - val_loss: 0.1442\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0023 - val_loss: 0.0576\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0023 - val_loss: 0.0374\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0025 - val_loss: 0.0202\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0028 - val_loss: 0.0076\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0030 - val_loss: 0.0397\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0036 - val_loss: 0.0631\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0031 - val_loss: 0.0824\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0035 - val_loss: 0.0742\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0037 - val_loss: 0.0118\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 11ms/step - loss: 0.0016 - val_loss: 0.2215\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.8071e-05 - val_loss: 0.2404\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0467 - val_loss: 0.1660\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 0.0019 - val_loss: 0.0612\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 7.9606e-04 - val_loss: 0.0615\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 0.0425 - val_loss: 0.0174\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0017 - val_loss: 0.0213\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0014 - val_loss: 0.0401\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0499 - val_loss: 1.1893\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0021 - val_loss: 1.1974\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0011 - val_loss: 0.0091\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.2077e-05 - val_loss: 0.0045\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 3.1438e-04 - val_loss: 0.0252\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 6.0522e-05 - val_loss: 0.8739\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 8ms/step - loss: 0.0225 - val_loss: 0.0033\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0018 - val_loss: 0.0080\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.7849e-04 - val_loss: 0.0116\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0040 - val_loss: 0.0223\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 8.7347e-04 - val_loss: 0.7256\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0135 - val_loss: 1.4286\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 5s 10ms/step - loss: 0.0056 - val_loss: 0.9096\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.9196e-04 - val_loss: 0.9385\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 7.1231e-04 - val_loss: 2.3284\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.0187e-04 - val_loss: 0.0048\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 3.9655e-05 - val_loss: 0.0604\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 1.8874e-05 - val_loss: 1.7278\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0362 - val_loss: 0.7208\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0036 - val_loss: 0.4192\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0018 - val_loss: 0.5337\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 4s 9ms/step - loss: 0.0037 - val_loss: 3.1040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpsQrU84mv0",
        "colab_type": "text"
      },
      "source": [
        "### Single-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEgXTi80WseN",
        "colab_type": "code",
        "outputId": "a905f023-dced-4a92-ac9a-94ef9c45cb57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "allMses = []\n",
        "allClassifications = []\n",
        "bestGuessClassifications = []\n",
        "relaxedGuessClassifications = []\n",
        "\n",
        "def singleStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    correctDirection = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    print(noDatapoints)\n",
        "\n",
        "    noPredictions = 6\n",
        "\n",
        "    mse = model.evaluate(xTest,yTest)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        prediction = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        if((current > prediction) == (current > future)):\n",
        "                correctDirection = correctDirection + 1\n",
        "\n",
        "    #print(\"-------------------------------\")\n",
        "    #print(\"MSE: \" + str(round(mse,3)))\n",
        "    directionClass = correctDirection / noDatapoints\n",
        "    #print(\"Direction classification: \" + str(round(directionClass,3)))\n",
        "    #print(\"-------------------------------\")\n",
        "\n",
        "    mses.append(mse)\n",
        "    classifications.append(directionClass)\n",
        "\n",
        "    return mses, classifications\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        print(\"running test\")\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTest, yTest = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        mses,classifications = singleStepModelTests(models[i-1], xTest, yTest)\n",
        "\n",
        "        modelMses.append(mses)\n",
        "        modelClassifications.append(classifications)\n",
        "\n",
        "        meanMse = np.mean(modelMses)\n",
        "        meanClass = np.mean(modelClassifications)\n",
        "    \n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "    #print(\"Average MSE: \" + str(meanMse))\n",
        "    #print(\"Average classification: \" + str(np.mean(classifications)))\n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "\n",
        "    return modelMses, modelClassifications\n",
        "\n",
        "\n",
        "def bestGuessTests(models, fold):\n",
        "\n",
        "    valIndex = fold_locations[fold+1]\n",
        "    \n",
        "    if (fold==FOLDS-2):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[fold+2]\n",
        "\n",
        "    print(valIndex)\n",
        "    print(endIndex)\n",
        "\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    xTest, yTest = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    for datapoint in range(len(xTest)):\n",
        "\n",
        "        past = tf.constant([xTest[datapoint]])\n",
        "        future = yTest[datapoint]\n",
        "\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "\n",
        "            prediction = models[j].predict(past)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        actualMax = np.argmax(future)\n",
        "        predictedMax = np.argmax(predictions)\n",
        "\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "    \n",
        "    print(\"--------------------------------\")\n",
        "            \n",
        "\n",
        "\n",
        "    #print(\"---------------\")\n",
        "    bestMonthClass = correctMax / len(xTest)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xTest)\n",
        "\n",
        "    #print(\"Correct best month: \" + str(round(bestMonthClass,3)))\n",
        "\n",
        "    print(\"------------\")\n",
        "    print(correctMax)\n",
        "    print(bestMonthRelaxedClass)\n",
        "\n",
        "    return bestMonthClass, bestMonthRelaxedClass\n",
        "\n",
        "def runBestGuessTests(allModels):\n",
        "\n",
        "    foldPerformances = []\n",
        "    relaxedFoldperformances = []\n",
        "\n",
        "    for i in range(len(allModels[0])):\n",
        "\n",
        "        print(\"running best guess test\")\n",
        "\n",
        "        foldModels = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "            foldModels.append(allModels[j][i])\n",
        "\n",
        "        foldPerformance, relaxedFoldperformance = bestGuessTests(foldModels, i)\n",
        "\n",
        "        foldPerformances.append(foldPerformance)\n",
        "        relaxedFoldperformances.append(relaxedFoldperformance)\n",
        "\n",
        "    return foldPerformances, relaxedFoldperformances\n",
        "\n",
        "\n",
        "def singleStepExperiments():\n",
        "    \n",
        "    print(\"MODELS CREATED\")\n",
        "\n",
        "    for modelsForOneStep in allModels:\n",
        "        print(\"MODEL STEP TESTS\")\n",
        "\n",
        "        modelMses, modelClassifications = runModels(modelsForOneStep)\n",
        "        allMses.append(modelMses)\n",
        "        allClassifications.append(modelClassifications)\n",
        "\n",
        "    print(\"MODEL STEP TESTS COMPLETE\")\n",
        "    print(\"TESTING BEST GUESS ABILITY\")\n",
        "\n",
        "    bestGuess, relaxedGuess = runBestGuessTests(allModels)\n",
        "\n",
        "    bestGuessClassifications.append(bestGuess)\n",
        "    relaxedGuessClassifications.append(relaxedGuess)\n",
        "\n",
        "\n",
        "    print(\"TESTING COMPLETE\")\n",
        "\n",
        "singleStepExperiments()\n",
        "\n"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODELS CREATED\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.0135\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.1902\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.3612\n",
            "running test\n",
            "291\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0952\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.9284\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6710\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3110\n",
            "running test\n",
            "291\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0142\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1677\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 4.7968\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3337\n",
            "running test\n",
            "291\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.8990\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2631\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.1406\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.5798\n",
            "running test\n",
            "291\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.7956\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4059\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4907\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.8792\n",
            "running test\n",
            "291\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.1562\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.6366\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.9500\n",
            "running test\n",
            "419\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.8701\n",
            "running test\n",
            "291\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.0400\n",
            "MODEL STEP TESTS COMPLETE\n",
            "TESTING BEST GUESS ABILITY\n",
            "running best guess test\n",
            "947\n",
            "1894\n",
            "--------------------------------\n",
            "------------\n",
            "23\n",
            "0.1288782816229117\n",
            "running best guess test\n",
            "1894\n",
            "2841\n",
            "--------------------------------\n",
            "------------\n",
            "36\n",
            "0.19809069212410502\n",
            "running best guess test\n",
            "2841\n",
            "3788\n",
            "--------------------------------\n",
            "------------\n",
            "59\n",
            "0.5059665871121718\n",
            "running best guess test\n",
            "3788\n",
            "None\n",
            "--------------------------------\n",
            "------------\n",
            "51\n",
            "0.30584192439862545\n",
            "TESTING COMPLETE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-8mJXyPjrpm",
        "colab_type": "code",
        "outputId": "ea1c7cf8-315a-48ee-a590-aae053c6dd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(allMses)                      #shape = FUTURE_STEPS, FOLDS\n",
        "print(allClassifications)           #shape = FUTURE_STEPS, FOLDS\n",
        "print(bestGuessClassifications)      #shape = FOLDS\n",
        "print(relaxedGuessClassifications)   #shape = FOLDS"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1.0135433673858643], [2.1902196407318115], [0.3611575663089752], [0.09519992768764496]], [[0.9283941984176636], [0.6709871292114258], [0.31097009778022766], [0.014190931804478168]], [[1.1677017211914062], [4.796783447265625], [0.33365732431411743], [0.8990475535392761]], [[1.263148546218872], [0.14056025445461273], [0.5798228979110718], [2.7955987453460693]], [[1.4058904647827148], [0.49066177010536194], [0.8791778683662415], [2.156179904937744]], [[1.6365615129470825], [1.9500356912612915], [0.8701071739196777], [3.0400068759918213]]]\n",
            "[[[0.6085918854415274], [0.4033412887828162], [0.4105011933174224], [0.5807560137457045]], [[0.6706443914081146], [0.4033412887828162], [0.6014319809069213], [0.7869415807560137]], [[0.6109785202863962], [0.4033412887828162], [0.6205250596658711], [0.5120274914089347]], [[0.548926014319809], [0.5966587112171837], [0.6014319809069213], [0.41924398625429554]], [[0.38902147971360385], [0.4033412887828162], [0.6014319809069213], [0.41924398625429554]], [[0.1431980906921241], [0.4033412887828162], [0.6014319809069213], [0.41924398625429554]]]\n",
            "[[0.05489260143198091, 0.08591885441527446, 0.14081145584725538, 0.17525773195876287]]\n",
            "[[0.1288782816229117, 0.19809069212410502, 0.5059665871121718, 0.30584192439862545]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rudFJZfKboB6",
        "colab_type": "code",
        "outputId": "bd6da44d-0911-481a-defe-eada4e780f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(allMses[0])\n",
        "\n",
        "print(bestGuessClassifications[0])"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0135433673858643], [2.1902196407318115], [0.3611575663089752], [0.09519992768764496]]\n",
            "[0.05489260143198091, 0.08591885441527446, 0.14081145584725538, 0.17525773195876287]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwgG0U6-gUrZ",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DGg4vGuUmRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(mses,directionClass,bestClass):\n",
        "\n",
        "    for i in range(FUTURE_STEPS):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(mses[i]))\n",
        "        print(\"Dir: \" + str(directionClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "#printResults(allMses, allClassifications, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uwx3VvAnnRN",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TYzy6YXnpjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_time_steps(length,steps):\n",
        "    return list(np.arange(-length, 0,step=steps))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\n",
        "    marker = ['.-', 'rx', 'go']\n",
        "    time_steps = create_time_steps(TIME_LAGS,STEP)\n",
        "\n",
        "    if delta:\n",
        "        future = delta\n",
        "    else:\n",
        "        future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "        if i:\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                    label=labels[i])\n",
        "        else:\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt\n",
        "\n",
        "\n",
        "#for x, y in dataVal.take(1):\n",
        "#    plot = show_plot([x[0][:, 0].numpy(), y[0].numpy(),\n",
        "#                        model.predict(x)[0]], PREDICTION_HORIZON,\n",
        "#                    'Single Step Prediction')\n",
        "#    print(model.predict(x)[0])\n",
        "#    plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1syGFxznuVLK",
        "colab_type": "text"
      },
      "source": [
        "## Multi-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHJMXYsuZWp",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0P_sbFRuhMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiStepLSTM():\n",
        "    multiStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(units=32, return_sequences=True, input_shape = (HISTORY_STEPS, len(features))),\n",
        "        layers.LSTM(16, activation='relu'),\n",
        "        layers.Dense(FUTURE_STEPS)\n",
        "    ])\n",
        "\n",
        "    multiStepLSTMModel.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mse')\n",
        "    return multiStepLSTMModel\n",
        "\n",
        "multiStepModel = multiStepLSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IwcoGcu3mP",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UAjl2pn0eT",
        "colab_type": "code",
        "outputId": "a06f7fb2-e0e0-436a-e78e-11551123f70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "results = []\n",
        "dataTrainMulti = []\n",
        "\n",
        "for x in range(1, FOLDS):\n",
        "\n",
        "    valIndex = fold_locations[x]\n",
        "\n",
        "    multiStepModel = multiStepLSTM()\n",
        "    \n",
        "    if (x==FOLDS-1):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[x+1]\n",
        "\n",
        "    xTrainMulti, yTrainMulti = splitData(dataSet, dataSet[:, 0], 0, valIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "    xValMulti, yValMulti = splitData(dataSet, dataSet[:, 0], valIndex, None, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    dataTrainMulti = tf.data.Dataset.from_tensor_slices((xTrainMulti, yTrainMulti))\n",
        "    dataTrainMulti = dataTrainMulti.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    dataValMulti = tf.data.Dataset.from_tensor_slices((xValMulti, yValMulti))\n",
        "    dataValMulti = dataValMulti.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    print(\"--------------------- Model\", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "    result = multiStepModel.fit(dataTrainMulti, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                        validation_data=dataValMulti, validation_steps=50)\n",
        "    \n",
        "    models.append(multiStepModel)\n",
        "    results.append(result)"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------- Model 1/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 8s 18ms/step - loss: 0.0218 - val_loss: 0.1863\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0014 - val_loss: 0.1106\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 9.9472e-04 - val_loss: 0.0705\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 7.7434e-04 - val_loss: 0.0211\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 6.8695e-04 - val_loss: 0.0104\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 9s 18ms/step - loss: 6.0665e-04 - val_loss: 0.0461\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 6.0915e-04 - val_loss: 0.0941\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 5.1918e-04 - val_loss: 0.1365\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 4.5461e-04 - val_loss: 0.0836\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 8s 18ms/step - loss: 4.5542e-04 - val_loss: 0.0694\n",
            "--------------------- Model 2/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 9s 18ms/step - loss: 0.0147 - val_loss: 0.8449\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 8s 16ms/step - loss: 0.0020 - val_loss: 0.8778\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0387 - val_loss: 0.8276\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0025 - val_loss: 0.8847\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 8s 16ms/step - loss: 0.0010 - val_loss: 0.8760\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 8s 16ms/step - loss: 0.0263 - val_loss: 0.7744\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0017 - val_loss: 0.7737\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 9.2622e-04 - val_loss: 0.8128\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0172 - val_loss: 0.8305\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 8.3579e-04 - val_loss: 0.8622\n",
            "--------------------- Model 3/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 9s 18ms/step - loss: 0.0107 - val_loss: 0.1436\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0011 - val_loss: 0.1529\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0030 - val_loss: 0.1345\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0047 - val_loss: 0.3557\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0198 - val_loss: 0.0894\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 9.3043e-04 - val_loss: 0.5328\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 8s 18ms/step - loss: 6.2710e-04 - val_loss: 0.8376\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0034 - val_loss: 0.4001\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0018 - val_loss: 0.4914\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0235 - val_loss: 0.0310\n",
            "--------------------- Model 4/4 --------------------------\n",
            "Epoch 1/10\n",
            "480/480 [==============================] - 9s 19ms/step - loss: 0.0149 - val_loss: 1.2714\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0013 - val_loss: 1.3174\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 8s 16ms/step - loss: 0.0021 - val_loss: 1.1383\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 8s 16ms/step - loss: 0.0043 - val_loss: 0.0684\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0015 - val_loss: 0.3984\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 8s 16ms/step - loss: 6.7686e-04 - val_loss: 0.6120\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0232 - val_loss: 1.1287\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0017 - val_loss: 1.6949\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 8.8195e-04 - val_loss: 3.5721\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 8s 17ms/step - loss: 0.0032 - val_loss: 0.8710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Uaxl7U4rEH",
        "colab_type": "text"
      },
      "source": [
        "### Multi-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMsesMulti = []\n",
        "allClassificationsMulti = []\n",
        "bestGuessClassificationsMulti = []\n",
        "relaxedGuessClassificationsMulti = []\n",
        "\n",
        "def multiStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    correctDirection = [0,0,0,0,0,0]\n",
        "    totalSquaredError = [0,0,0,0,0,0]\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    noPredictions = len(totalSquaredError)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        predictions = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        temp = future[actualMax]\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "        future[actualMax]=temp\n",
        "\n",
        "        for y in range(noPredictions):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    for x in range(noPredictions):\n",
        "        mse = totalSquaredError[x] / noDatapoints\n",
        "        mses.append(mse)\n",
        "\n",
        "    for x in range(noPredictions):\n",
        "        percentInterval = correctDirection[x] / noDatapoints\n",
        "        classifications.append(percentInterval)\n",
        "\n",
        "    bestMonthClass = correctMax / noDatapoints\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / noDatapoints\n",
        "\n",
        "    allMsesMulti.append(mses)\n",
        "    allClassificationsMulti.append(classifications)\n",
        "    bestGuessClassificationsMulti.append(bestMonthClass)\n",
        "    relaxedGuessClassificationsMulti.append(bestMonthRelaxedClass)\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTestMulti, yTestMulti = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        multiStepModelTests(models[i-1], xTestMulti, yTestMulti)\n",
        "\n",
        "runModels(models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GoqA1iO8TQV",
        "colab_type": "code",
        "outputId": "02096d9b-7fda-46de-eef5-f386e9e7c854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "allMsesMulti = list(map(list, zip(*allMsesMulti)))\n",
        "allClassificationsMulti = list(map(list, zip(*allClassificationsMulti)))\n",
        "\n",
        "print(allMsesMulti)\n",
        "print(allClassificationsMulti)\n",
        "print(bestGuessClassificationsMulti)\n",
        "print(relaxedGuessClassificationsMulti)"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.31463614202951434, 0.7566421007132816, 0.1592127213561846, 1.3562376720806801], [0.34103004236719486, 1.2892695129845935, 0.10050628847478454, 1.0790423883549427], [0.5139460525327576, 1.2557698124718215, 0.29641121105507556, 0.6714902147166041], [0.7722972443020335, 0.9230132498651296, 0.12394635130647143, 0.7703756621965445], [0.9756402760770883, 0.8182646323756015, 0.21522461806953386, 1.2286892903200595], [1.1757757222970502, 0.27468414280476317, 0.21977374617523995, 0.9631725834529969]]\n",
            "[[0.431980906921241, 0.5656324582338902, 0.5274463007159904, 0.4879725085910653], [0.49403341288782815, 0.5441527446300716, 0.6109785202863962, 0.570446735395189], [0.39856801909307876, 0.6515513126491647, 0.45584725536992843, 0.584192439862543], [0.48448687350835323, 0.6515513126491647, 0.837708830548926, 0.5463917525773195], [0.1909307875894988, 0.6229116945107399, 0.8210023866348448, 0.39862542955326463], [0.13126491646778043, 0.5966587112171837, 0.837708830548926, 0.40893470790378006]]\n",
            "[0.11455847255369929, 0.050119331742243436, 0.13365155131264916, 0.15807560137457044]\n",
            "[0.15035799522673032, 0.14797136038186157, 0.26730310262529833, 0.20618556701030927]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSYYPtFgP4i",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2SBad6gSMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(monthAverageMses,monthAverageClass,bestClass):\n",
        "\n",
        "    for i in range(len(monthAverageMses)):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(monthAverageMses[i]))\n",
        "        print(\"Dir: \" + str(monthAverageClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "#printResults(monthAverageMses, monthAverageClass, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tii3SZcOw1qb",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR0uE5bfw5uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(TIME_LAGS,STEP)\n",
        "  num_out = len(true_future) * FUTURE_STEP\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
        "  plt.plot(np.arange(num_out, step=FUTURE_STEP), np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out,step=FUTURE_STEP), np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "#model = models[-1]\n",
        "\n",
        "#for x, y in dataTrainMulti.take(1):\n",
        "#\n",
        "#    print(x)\n",
        "\n",
        "    #print((multiStepModel.predict(x)[0]).index(max(multiStepModel.predict(x)[0])))\n",
        "#    print(model.predict(x)[0])\n",
        "#    multi_step_plot(x[0], y[0], model.predict(x)[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_dvGN0dnK_y",
        "colab_type": "text"
      },
      "source": [
        "# Run all tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sub9ApHanOdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJ7pc31UP8k",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKanocQUSfm",
        "colab_type": "code",
        "outputId": "3bda35e5-8f0b-4fdc-c964-a24fe7637f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "gc.create(title=\"22mov1bat!\",folder=\"1zb8cLLf2RtYz9RuofDhGDgmTAoXD2VnE\")\n",
        "\n",
        "sh = gc.open('22mov1bat!')\n",
        "\n",
        "#sh.add_worksheet('test2',rows=5, cols=20) \n",
        "\n",
        "wk1 = sh[0]\n",
        "\n",
        "titles = ['SINGLE_STEP','MSE(Fold1)','MSE(Fold2)','MSE(Fold3)','MSE(Fold4)','MSE(avg)',\n",
        "          'Dir(Fold1)','Dir(Fold2)','Dir(Fold3)','Dir(Fold4)','Dir(avg)']\n",
        "\n",
        "shiftSize = FUTURE_STEPS+5\n",
        "\n",
        "wk1.insert_rows(row = 0, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "mseAvgsSingle = []\n",
        "dirAvgsSingle = []\n",
        "bestSingle = []\n",
        "relaxedSingle = []\n",
        "\n",
        "mseAvgsMulti = []\n",
        "dirAvgsMulti = []\n",
        "bestMulti = []\n",
        "relaxedMultti = []\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMses[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allMses[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsSingle.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassifications[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allClassifications[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsSingle.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = step+1, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassifications[0])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestSingle = mean\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassifications[0])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedSingle = mean\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "\n",
        "titles[0] = 'MULTI-STEP'\n",
        "\n",
        "wk1.insert_rows(row = shiftSize, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "\n",
        "        print(step)\n",
        "        print(fold)\n",
        "        row.append(str(allMsesMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allMsesMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsMulti.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassificationsMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allClassificationsMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsMulti.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+step+2, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+3, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassificationsMulti)\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestMulti = mean\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassificationsMulti)\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedMulti = mean\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+4, number = 1, values = guessResults)\n",
        "\n",
        "for i in range(FUTURE_STEPS):\n",
        "\n",
        "    month = 'Month ' + str(i+1)\n",
        "    row = [month]\n",
        "    row.append(str(mseAvgsSingle[i]))\n",
        "    row.append(str(dirAvgsSingle[i]))\n",
        "    row.append(str(mseAvgsMulti[i]))\n",
        "    row.append(str(dirAvgsMulti[i]))\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+FUTURE_STEPS+i+7, number = 1, values = row)\n",
        "\n",
        "row = ['Guesses']\n",
        "row.append(str(bestSingle))\n",
        "row.append(str(relaxedSingle))\n",
        "row.append(str(bestMulti))\n",
        "row.append(str(relaxedMulti))\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+FUTURE_STEPS+7, number = 1, values = row)"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "2\n",
            "0\n",
            "3\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "1\n",
            "3\n",
            "2\n",
            "0\n",
            "2\n",
            "1\n",
            "2\n",
            "2\n",
            "2\n",
            "3\n",
            "3\n",
            "0\n",
            "3\n",
            "1\n",
            "3\n",
            "2\n",
            "3\n",
            "3\n",
            "4\n",
            "0\n",
            "4\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "3\n",
            "5\n",
            "0\n",
            "5\n",
            "1\n",
            "5\n",
            "2\n",
            "5\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_1JpTDehzM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33617c4d-24f4-4c61-f4eb-e7d354ac5616"
      },
      "source": [
        "print(allMsesMulti[0][0])"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.31463614202951434\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}