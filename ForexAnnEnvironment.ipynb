{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y23CLo2oUco-O4CAkKZhYsjzzzbnTeLP",
      "authorship_tag": "ABX9TyPvi7WxyNlxRf5zn/GGxxEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "69c2d4ad-36da-453d-d32e-64b9f1d88021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "#!pip install FRB\n",
        "!pip install fred\n",
        "!pip install mock\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.0.0\n",
        "\n",
        "import fred\n",
        "from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, CuDNNLSTM\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.18.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.8.1)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.0.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (1.18.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.12.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fred) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knovwSza04MP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSX-AVfVGK6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "START_DATE = '2001-01-01'\n",
        "END_DATE = '2020-02-01'\n",
        "\n",
        "pd.set_option('display.max_rows', 25)\n",
        "pd.set_option('display.max_columns', 25)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mBJkhEqGfRq",
        "colab_type": "text"
      },
      "source": [
        "## Moving average function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpuooBtRGero",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMovingAverages(data, windowSize):\n",
        "\n",
        "    movingAverages = []\n",
        "\n",
        "    for x in range(len(data)):\n",
        "        if (x < windowSize):\n",
        "            window = data[:x+1]\n",
        "        else:\n",
        "            window = data[x-(windowSize - 1):x+1]\n",
        "        \n",
        "        total = sum(window)\n",
        "        average = total / len(window)\n",
        "        movingAverages.append(average)\n",
        "\n",
        "    return movingAverages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n68WYYVB6UK7",
        "colab_type": "text"
      },
      "source": [
        "## FOREX data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get FOREX data\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=START_DATE, end_date=END_DATE, returns=\"numpy\")\n",
        "forexDataN = dataGbpEurRate.Value\n",
        "\n",
        "forexRaw = np.asarray(forexDataN)\n",
        "forex_mean_raw = forexRaw.mean()\n",
        "forex_std_raw = forexRaw.std()\n",
        "forexRaw = (forexRaw - forex_mean_raw) / forex_std_raw\n",
        "\n",
        "forexMonthMovAvg = getMovingAverages(forexDataN, 10)\n",
        "\n",
        "forexMonthMovAvg = np.asarray(forexMonthMovAvg)\n",
        "forex_mean_avg = forexMonthMovAvg.mean()\n",
        "forex_std_avg = forexMonthMovAvg.std()\n",
        "forexMonthMovAvg = (forexMonthMovAvg - forex_mean_avg) / forex_std_avg\n",
        "\n",
        "ukFOREXdates = []\n",
        "for x in dataGbpEurRate.Date:\n",
        "    ukFOREXdates.append(pd.Timestamp(x))\n",
        "\n",
        "\n",
        "forexData = {'Date':ukFOREXdates,'Value':forexMonthMovAvg}\n",
        "\n",
        "forexRawDict = {ukFOREXdates[i]: forexRaw[i] for i in range(len(ukFOREXdates))}\n",
        "\n",
        "mainDf = pd.DataFrame(forexData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "## Interest Rate Data (INT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUTeDp07W41L",
        "colab_type": "text"
      },
      "source": [
        "### INT data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0f5HNs21pcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgecCRUBkiR",
        "colab_type": "text"
      },
      "source": [
        "### INT data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkAjnFLBlhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanDataSets(dataset):\n",
        "\n",
        "    dataDict = {pd.Timestamp(dataset[i][\"date\"]): dataset[i][\"value\"] for i in range(len(dataset))}\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "        value = dataDict.get(row['Date'], 1000000)\n",
        "\n",
        "        if (value=='.'):\n",
        "            value = 1000000\n",
        "\n",
        "        if(value==1000000):\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataDict.get(dateBelow, 1000000)\n",
        "            valueAbove = dataDict.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "GBRovrC = cleanDataSets(GBRovrJson)\n",
        "EURovrC = cleanDataSets(EURovrJson)\n",
        "GBR3mC = cleanDataSets(GBR3mJson)\n",
        "EUR3mC = cleanDataSets(EUR3mJson)\n",
        "GBR6mC = cleanDataSets(GBR6mJson)\n",
        "EUR6mC = cleanDataSets(EUR6mJson)\n",
        "GBR12mC = cleanDataSets(GBR12mJson)\n",
        "EUR12mC = cleanDataSets(EUR12mJson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euiAqH5oXFmC",
        "colab_type": "text"
      },
      "source": [
        "### INT feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjzi_yf1sjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDifferenceFeatures(xDict, yDict, avg):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "    ratioValues = []                      \n",
        "\n",
        "    for k,v in xDict.items():\n",
        "\n",
        "        match = yDict.get(k, 0)\n",
        "        valuesX.append(float(v))\n",
        "        valuesY.append(float(match))\n",
        "        dates.append(k)\n",
        " \n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    diffValues = datasetXarr - datasetYarr\n",
        "\n",
        "    if(avg):\n",
        "        diffValues = getMovingAverages(diffValues, 10)\n",
        "\n",
        "    diffValues = np.asarray(diffValues)\n",
        "\n",
        "    data_mean = diffValues.mean()\n",
        "    data_std = diffValues.std()\n",
        "    dataNormalised = (diffValues - data_mean) - data_std\n",
        "\n",
        "    res = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return res\n",
        "\n",
        "ovrRatio = getDifferenceFeatures(GBRovrC,EURovrC, False)\n",
        "threeMRatio = getDifferenceFeatures(GBR3mC,EUR3mC, False)\n",
        "sixMRatio = getDifferenceFeatures(GBR6mC,EUR6mC, False)\n",
        "twelveMRatio = getDifferenceFeatures(GBR12mC,EUR12mC, False)\n",
        "\n",
        "ovrRatioMovAvg = getDifferenceFeatures(GBRovrC,EURovrC, True)\n",
        "threeMRatioMovAvg = getDifferenceFeatures(GBR3mC,EUR3mC, True)\n",
        "sixMRatioMovAvg = getDifferenceFeatures(GBR6mC,EUR6mC, True)\n",
        "twelveMRatioMovAvg = getDifferenceFeatures(GBR12mC,EUR12mC, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "## Inflation data (CPI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUCPuwpYOnn",
        "colab_type": "text"
      },
      "source": [
        "### CPI data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVanjbf-n1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "ukCPIDict = {ukCPI.period.iloc[i]: ukCPI.value.iloc[i] for i in range(len(ukCPI))}\n",
        "euCPIDict = {euCPI.period.iloc[i]: euCPI.value.iloc[i] for i in range(len(euCPI))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhffkl2I-kY0",
        "colab_type": "text"
      },
      "source": [
        "### CPI data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxREJ3rFVj5",
        "colab_type": "code",
        "outputId": "d6204672-4668-436e-f430-588cde827e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def cleanMonthlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        roundD = row['Date'].replace(day=1)\n",
        "\n",
        "        value= dataset.get(pd.Timestamp(roundD),1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            clean = False\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataset.get(dateBelow, 1000000)\n",
        "            valueAbove = dataset.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    if(clean==True):\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukCPIDictC = cleanMonthlyData(ukCPIDict)\n",
        "euCPIDictC = cleanMonthlyData(euCPIDict)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T2dZu4RA6Sl",
        "colab_type": "text"
      },
      "source": [
        "### CPI feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = []\n",
        "ukCPIarr = []\n",
        "euCPIarr = []\n",
        "\n",
        "for k,v in ukCPIDictC.items():\n",
        "\n",
        "    match = euCPIDictC.get(k, 0)\n",
        "\n",
        "    ukCPIarr.append(v)\n",
        "    euCPIarr.append(match)\n",
        "    dates.append(k)\n",
        "\n",
        "ukCPIarr = np.array(ukCPIarr, dtype=np.float)\n",
        "euCPIarr = np.array(euCPIarr, dtype=np.float)\n",
        "\n",
        "ukEuCpiRatio = ukCPIarr - euCPIarr\n",
        "\n",
        "# Normalise CPI data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "cpiDict = {dates[i]: ukEuCpiRatio[i] for i in range(len(dates))}\n",
        "\n",
        "cpiData = {'Date':dates, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "## International Reserves data (IR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeoJsXNEQA_m",
        "colab_type": "text"
      },
      "source": [
        "### IR data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXRsvqQIQMG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRDict = {ukIR.period.iloc[i]: ukIR.value.iloc[i] for i in range(len(ukIR))}\n",
        "euIRDict = {euIR.period.iloc[i]: euIR.value.iloc[i] for i in range(len(euIR))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj0vLPaBQFde",
        "colab_type": "text"
      },
      "source": [
        "### IR data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZbMYaFhQREG",
        "colab_type": "code",
        "outputId": "03722ad8-e44b-4365-80da-acd7fa62acc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ukIRDictC = cleanMonthlyData(ukIRDict)\n",
        "euIRDictC = cleanMonthlyData(euIRDict)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCU1PotbQH3d",
        "colab_type": "text"
      },
      "source": [
        "### IR feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IRdates = []\n",
        "ukIRarr = []\n",
        "euIRarr = []\n",
        "\n",
        "for k,v in ukIRDictC.items():\n",
        "\n",
        "    match = euIRDictC.get(k, 0)\n",
        "\n",
        "    ukIRarr.append(v)\n",
        "    euIRarr.append(match)\n",
        "    IRdates.append(k)\n",
        "\n",
        "\n",
        "ukIRarr = np.array(ukIRarr, dtype=np.float)\n",
        "euIRarr = np.array(euIRarr, dtype=np.float)\n",
        "\n",
        "ukEuIRRatio = ukIRarr / euIRarr\n",
        "\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {IRdates[i]: ukEuIRRatio[i] for i in range(len(IRdates))}\n",
        "\n",
        "irData = {'Date':IRdates, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Balance of Payments data (BOP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FpSuRNLR8Rb",
        "colab_type": "text"
      },
      "source": [
        "### BOP data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_2Bg9PSEym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPDict = {ukBOP.period.iloc[i]: ukBOP.value.iloc[i] for i in range(len(ukBOP))}\n",
        "euBOPDict = {euBOP.period.iloc[i]: euBOP.value.iloc[i] for i in range(len(euBOP))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EsjDOHjR_Q-",
        "colab_type": "text"
      },
      "source": [
        "### BOP data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsVJ5XKGSmu_",
        "colab_type": "code",
        "outputId": "911a84b6-024a-411f-953c-86a73dada775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def cleanQuarterlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        date = row['Date']\n",
        "        dateMonth = date.replace(day=1)\n",
        "        dateQuarter = date.quarter\n",
        "        \n",
        "        switcher={\n",
        "            1:date.replace(month=1,day=1),\n",
        "            2:date.replace(month=4,day=1),\n",
        "            3:date.replace(month=7,day=1),\n",
        "            4:date.replace(month=10,day=1)\n",
        "        }\n",
        "\n",
        "        dateRoundedQuarter = switcher.get(dateQuarter)\n",
        "\n",
        "        value = dataset.get(dateRoundedQuarter,1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            mainDf.drop([index], inplace=True)\n",
        "        else:\n",
        "            cleanedDataDict[row['Date']] = value\n",
        "\n",
        "\n",
        "    clean = True\n",
        "    for k,v in cleanedDataDict.items():\n",
        "        if (v==1000000):\n",
        "            clean = False;\n",
        "\n",
        "    if (clean==False):\n",
        "        print(\"Data is unlcean\")\n",
        "    else:\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukBOPDictC = cleanQuarterlyData(ukBOPDict)\n",
        "euBOPDictC = cleanQuarterlyData(euBOPDict)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5T04eISB7G",
        "colab_type": "text"
      },
      "source": [
        "### BOP feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOPdates = []\n",
        "ukBOParr = []\n",
        "euBOParr = []\n",
        "\n",
        "for k,v in ukBOPDictC.items():\n",
        "\n",
        "    match = euBOPDictC.get(k, 0)\n",
        "\n",
        "    ukBOParr.append(v)\n",
        "    euBOParr.append(match)\n",
        "    BOPdates.append(k)\n",
        "\n",
        "ukBOParr = np.array(ukBOParr, dtype=np.float)\n",
        "euBOParr = np.array(euBOParr, dtype=np.float)\n",
        "\n",
        "ukEuBOPRatio = ukBOParr / euBOParr\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {BOPdates[i]: ukEuBOPRatio[i] for i in range(len(BOPdates))}\n",
        "\n",
        "bopData = {'Date':BOPdates, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "## Creating full data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOlDl_FgRI8",
        "colab_type": "code",
        "outputId": "8a2a0402-aa1b-4e04-c03f-487e94f7dcbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "completeDf = pd.DataFrame(columns=['Date','ForexAvg','ForexRaw','CPIRatio', 'IRRatio',\n",
        "                                   'BOPRatio', 'OvrLIBOR','OvrAvg','3mLIBOR', '3mAvg',\n",
        "                                   '6mLIBOR','6mAvg','12mLIBOR', '12mAvg'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        " \n",
        "for index, row in mainDf.iterrows():\n",
        "\n",
        "    date = row['Date']\n",
        "    forex = row['Value']\n",
        "\n",
        "    forexRaw = forexRawDict.get(date, 0)\n",
        "    \n",
        "    cpi = cpiDict.get(date, 0)\n",
        "    ir = irDict.get(date,0)\n",
        "    bop = bopDict.get(date,0)\n",
        "\n",
        "    ovrI = ovrRatio.get(date, 0)\n",
        "    ovrImov = ovrRatioMovAvg.get(date, 0)\n",
        "    i3month = threeMRatio.get(date, 0)\n",
        "    i3monthmov = threeMRatioMovAvg.get(date, 0)\n",
        "    i6month = sixMRatio.get(date, 0)\n",
        "    i6monthmov = sixMRatioMovAvg.get(date, 0)\n",
        "    i12month = twelveMRatio.get(date, 0)\n",
        "    i12monthmov = twelveMRatioMovAvg.get(date, 0)\n",
        "\n",
        "    completeDf = completeDf.append({'Date':date,\n",
        "                            'ForexAvg':forex,\n",
        "                            'ForexRaw':forexRaw,\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovrI,\n",
        "                            'OvrAvg':ovrImov,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '3mAvg':i3monthmov,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '6mAvg':i6monthmov,\n",
        "                            '12mLIBOR': i12month,\n",
        "                            '12mAvg':i12monthmov},\n",
        "                            ignore_index=True)\n",
        "\n",
        "print(completeDf)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Date  ForexAvg  ForexRaw  CPIRatio   IRRatio  BOPRatio  OvrLIBOR  \\\n",
            "0    2001-01-02  1.636760  1.638603 -1.445720  4.969333  0.295915 -0.772414   \n",
            "1    2001-01-03  1.674689  1.714443 -1.445720  4.969333  0.295915 -0.477104   \n",
            "2    2001-01-04  1.665890  1.650130 -1.445720  4.969333  0.295915 -0.993354   \n",
            "3    2001-01-05  1.646925  1.591885 -1.445720  4.969333  0.295915 -1.143974   \n",
            "4    2001-01-08  1.643678  1.632535 -1.445720  4.969333  0.295915 -1.018354   \n",
            "...         ...       ...       ...       ...       ...       ...       ...   \n",
            "4734 2019-09-24 -1.097566 -1.055864  0.563933  0.376361  0.144160 -0.502294   \n",
            "4735 2019-09-25 -1.093258 -1.087414  0.563933  0.376361  0.144160 -0.488964   \n",
            "4736 2019-09-26 -1.087432 -1.100155  0.563933  0.376361  0.144160 -0.497724   \n",
            "4737 2019-09-27 -1.087371 -1.118357  0.563933  0.376361  0.144160 -0.503184   \n",
            "4738 2019-09-30 -1.086885 -1.083167  0.563933  0.376361  0.144160 -0.502714   \n",
            "\n",
            "        OvrAvg   3mLIBOR     3mAvg   6mLIBOR     6mAvg  12mLIBOR    12mAvg  \n",
            "0    -0.742444 -0.652288 -0.651632 -0.684519 -0.683848 -0.666377 -0.665553  \n",
            "1    -0.594789 -0.623068 -0.637022 -0.629989 -0.656583 -0.624667 -0.644698  \n",
            "2    -0.717654 -0.610878 -0.628089 -0.618739 -0.643745 -0.612477 -0.633683  \n",
            "3    -0.816742 -0.601038 -0.621162 -0.603189 -0.633438 -0.591537 -0.622941  \n",
            "4    -0.851070 -0.609318 -0.618662 -0.623429 -0.631302 -0.605907 -0.619369  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "4734 -0.528107 -0.535958 -0.515632 -0.489249 -0.488665 -0.483677 -0.480624  \n",
            "4735 -0.516770 -0.534278 -0.521064 -0.479419 -0.490425 -0.489427 -0.483676  \n",
            "4736 -0.505546 -0.525638 -0.525677 -0.475109 -0.492161 -0.490657 -0.488426  \n",
            "4737 -0.495247 -0.527358 -0.526652 -0.499669 -0.491533 -0.521017 -0.491726  \n",
            "4738 -0.485692 -0.526388 -0.527090 -0.500849 -0.492294 -0.519787 -0.495226  \n",
            "\n",
            "[4739 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9gVEULcO0zD",
        "colab_type": "text"
      },
      "source": [
        "# Variable Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpiLy6YcO5-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables = ['CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR']\n",
        "\n",
        "forex = completeDf['ForexAvg'].tolist()\n",
        "correlations = []\n",
        "\n",
        "for x in range(len(variables)):\n",
        "    \n",
        "    column = completeDf[variables[x]].tolist()\n",
        "\n",
        "    r = np.corrcoef(forex, column)\n",
        "\n",
        "    correlations.append(r[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7MnSU94FOw",
        "colab_type": "code",
        "outputId": "d4bcb556-0f4b-45ba-e9c9-e8148b7a7e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "y_pos = np.arange(0,14,2)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(y_pos, correlations, align='center', alpha=0.5, color=(0.0, 0.0, 0.0, 1))\n",
        "plt.xticks(y_pos, variables)\n",
        "plt.ylabel('Usage')\n",
        "plt.title('Correlations')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMlG3PXw4dX",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSvQDGXwFVJ",
        "colab_type": "text"
      },
      "source": [
        "## Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4_5GXRVwHR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1a03a3c-e7e6-4a90-bf89-58c9503cb922"
      },
      "source": [
        "import math\n",
        "\n",
        "EPOCHS = 10\n",
        "#EVALUATION_INTERVAL = 16\n",
        "VALIDATION_STEPS = 50\n",
        "BATCH_SIZE = 30\n",
        "FOLDS = 5\n",
        "\n",
        "HISTORY_STEPS = 6\n",
        "FUTURE_STEPS = 6\n",
        "\n",
        "target = ['ForexAvg']\n",
        "features = ['ForexAvg']\n",
        "\n",
        "dataSet = completeDf[features]\n",
        "dataSet = dataSet.values\n",
        "\n",
        "target = completeDf[target]\n",
        "target = target.values\n",
        "\n",
        "\n",
        "fold_steps = math.floor(len(dataSet) / FOLDS)\n",
        "fold_locations = []\n",
        "results = []\n",
        "\n",
        "print(fold_steps)\n",
        "\n",
        "for x in range(0,len(dataSet), fold_steps):\n",
        "    fold_locations.append(x)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4r-1IZnpzKj",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzFM320p1Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index - 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index - 22\n",
        "\n",
        "    indices = list(reversed(indices))\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def singleStepDataSplit(dataset, target, startIndex, endIndex,\n",
        "                steps, future_steps):  \n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "\n",
        "    max_index = 22 * future_steps\n",
        "    target_size = round(21.75 * future_steps)\n",
        "\n",
        "    startIndex = startIndex + history_size\n",
        "\n",
        "    if endIndex is None:\n",
        "        endIndex = len(dataset) - max_index\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        dataIndices = getIndices(i,steps)\n",
        "        data.append(dataset[dataIndices])\n",
        "        labels.append(target[i+target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def getFutureIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex + 22\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index + 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index + 22\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def splitData(dataset, target, start_index, end_index, steps, future_steps):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "    target_size = 22 * future_steps\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = getIndices(i,steps)\n",
        "        data.append(dataset[indices])\n",
        "        indiciesL = getFutureIndices(i, future_steps)\n",
        "        labels.append(target[indiciesL])\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nd5E-y_o1HY",
        "colab_type": "text"
      },
      "source": [
        "## Single-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseG60kHb2hB",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYFUp6Mb98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def singleStepLSTM():\n",
        "    singleStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(32, input_shape=(HISTORY_STEPS, len(features))),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    singleStepLSTMModel.compile(optimizer='adam', loss='mse')\n",
        "    return singleStepLSTMModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJqrxLV9xCEB",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmajAmS4xEs-",
        "colab_type": "code",
        "outputId": "97f354a3-314f-4b30-dae4-b2f88692b42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataVal = []\n",
        "\n",
        "def trainModel(history_steps, future_step):\n",
        "\n",
        "    models = []\n",
        "    results = []\n",
        "\n",
        "    for x in range(1, FOLDS):\n",
        "\n",
        "        model = singleStepLSTM()\n",
        "\n",
        "        valIndex = fold_locations[x]\n",
        "        \n",
        "        if (x==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[x+1]\n",
        "\n",
        "        xTrain, yTrain = singleStepDataSplit(dataSet, target, 0, valIndex, history_steps, future_step)\n",
        "        xVal, yVal = singleStepDataSplit(dataSet, target, valIndex, endIndex, history_steps, future_step)\n",
        "\n",
        "\n",
        "        dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "        dataTrain = dataTrain.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "        dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        print(\"--------------------- Model validated on fold \", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "        steps_per = math.floor(len(xTrain)/BATCH_SIZE)\n",
        "        print(steps_per)\n",
        "\n",
        "        result = model.fit(dataTrain, epochs=EPOCHS, steps_per_epoch=steps_per,\n",
        "                            validation_data=dataVal, validation_steps=50)\n",
        "        \n",
        "        models.append(model)\n",
        "        results.append(result)\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def createModelsForAllSteps():\n",
        "\n",
        "    allModels = []\n",
        "\n",
        "    for i in range(1,FUTURE_STEPS+1):\n",
        "\n",
        "        print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month\", \"%d/%d &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\" % (i, FUTURE_STEPS))\n",
        "\n",
        "        models = trainModel(HISTORY_STEPS, i)\n",
        "        allModels.append(models)\n",
        "\n",
        "\n",
        "    return allModels\n",
        "\n",
        "allModels = createModelsForAllSteps()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 1/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 20ms/step - loss: 1.5623 - val_loss: 0.2070\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2710 - val_loss: 0.0966\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0896 - val_loss: 0.0665\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0958 - val_loss: 0.0677\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.0856 - val_loss: 0.0640\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0835 - val_loss: 0.0626\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0808 - val_loss: 0.0612\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0812 - val_loss: 0.0604\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0790 - val_loss: 0.0598\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0772 - val_loss: 0.0597\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4797 - val_loss: 0.4389\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.4045\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0752 - val_loss: 0.3673\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0701 - val_loss: 0.3359\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0653 - val_loss: 0.3096\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0645 - val_loss: 0.2875\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0637 - val_loss: 0.2686\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0616 - val_loss: 0.2520\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0599 - val_loss: 0.2372\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.2234\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4344 - val_loss: 0.0737\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0857 - val_loss: 0.0980\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0855 - val_loss: 0.1101\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0777 - val_loss: 0.1145\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.1144\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0714 - val_loss: 0.1116\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0686 - val_loss: 0.1074\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0656 - val_loss: 0.1026\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.0980\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0608 - val_loss: 0.0937\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.6297 - val_loss: 0.0911\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1079 - val_loss: 0.1000\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1089 - val_loss: 0.0902\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0964 - val_loss: 0.0797\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0854 - val_loss: 0.0699\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0613\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0714 - val_loss: 0.0540\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.0479\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.0431\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0590 - val_loss: 0.0392\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 2/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 1.3627 - val_loss: 0.2113\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2421 - val_loss: 0.1118\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.0899\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1124 - val_loss: 0.0905\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1007 - val_loss: 0.0884\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1035 - val_loss: 0.0880\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.0990 - val_loss: 0.0873\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1012 - val_loss: 0.0872\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1022 - val_loss: 0.0873\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1012 - val_loss: 0.0879\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.6550 - val_loss: 0.5675\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1179 - val_loss: 0.5367\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1112 - val_loss: 0.4977\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1000 - val_loss: 0.4635\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1002 - val_loss: 0.4348\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0968 - val_loss: 0.4110\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0988 - val_loss: 0.3914\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0985 - val_loss: 0.3750\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0970 - val_loss: 0.3608\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0952 - val_loss: 0.3482\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.9099 - val_loss: 0.1535\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1460 - val_loss: 0.1455\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1199 - val_loss: 0.1643\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1176 - val_loss: 0.1748\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.1112 - val_loss: 0.1773\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1080 - val_loss: 0.1747\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.1050 - val_loss: 0.1697\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1023 - val_loss: 0.1637\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0993 - val_loss: 0.1576\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.0970 - val_loss: 0.1520\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.3780 - val_loss: 0.1028\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.1184 - val_loss: 0.1096\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.1179 - val_loss: 0.0985\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.1110 - val_loss: 0.0881\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 1s 5ms/step - loss: 0.1036 - val_loss: 0.0789\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0974 - val_loss: 0.0710\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0642\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0880 - val_loss: 0.0584\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0840 - val_loss: 0.0538\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.0840 - val_loss: 0.0502\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 3/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 0s 19ms/step - loss: 1.7667 - val_loss: 0.3017\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.3917 - val_loss: 0.1560\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1421 - val_loss: 0.1276\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1455 - val_loss: 0.1311\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1346 - val_loss: 0.1273\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1331 - val_loss: 0.1261\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1304 - val_loss: 0.1250\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1295 - val_loss: 0.1248\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1305 - val_loss: 0.1253\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1297 - val_loss: 0.1266\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.4568 - val_loss: 0.4353\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1434 - val_loss: 0.4001\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1345 - val_loss: 0.3641\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1235 - val_loss: 0.3339\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1163 - val_loss: 0.3098\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1191 - val_loss: 0.2909\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1183 - val_loss: 0.2760\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1206 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1199 - val_loss: 0.2540\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1186 - val_loss: 0.2452\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.5016 - val_loss: 0.1442\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1419 - val_loss: 0.1932\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1367 - val_loss: 0.2085\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1343 - val_loss: 0.2166\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1295 - val_loss: 0.2189\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.1275 - val_loss: 0.2166\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1252 - val_loss: 0.2119\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1227 - val_loss: 0.2062\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1202 - val_loss: 0.2003\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1179 - val_loss: 0.1949\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.3317 - val_loss: 0.1201\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1446 - val_loss: 0.1275\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1442 - val_loss: 0.1148\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1363 - val_loss: 0.1034\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1303 - val_loss: 0.0934\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1233 - val_loss: 0.0847\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1190 - val_loss: 0.0774\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1144 - val_loss: 0.0711\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1102 - val_loss: 0.0660\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1094 - val_loss: 0.0620\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 4/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 1.3748 - val_loss: 0.3152\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.4473 - val_loss: 0.1578\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1676 - val_loss: 0.1674\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1498 - val_loss: 0.1608\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1490 - val_loss: 0.1601\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1439 - val_loss: 0.1580\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1423 - val_loss: 0.1571\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1401 - val_loss: 0.1569\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1402 - val_loss: 0.1576\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1419 - val_loss: 0.1593\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.5068 - val_loss: 0.4202\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1672 - val_loss: 0.3972\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1630 - val_loss: 0.3670\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1529 - val_loss: 0.3407\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1420 - val_loss: 0.3187\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1416 - val_loss: 0.3012\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1446 - val_loss: 0.2873\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1467 - val_loss: 0.2762\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1484 - val_loss: 0.2671\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1472 - val_loss: 0.2593\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4750 - val_loss: 0.1641\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1745 - val_loss: 0.2118\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1688 - val_loss: 0.2267\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1655 - val_loss: 0.2340\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1605 - val_loss: 0.2370\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1568 - val_loss: 0.2363\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1548 - val_loss: 0.2332\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1524 - val_loss: 0.2289\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1500 - val_loss: 0.2244\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1474 - val_loss: 0.2200\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.5073 - val_loss: 0.1660\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1883 - val_loss: 0.1505\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1890 - val_loss: 0.1361\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1801 - val_loss: 0.1225\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1735 - val_loss: 0.1107\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1671 - val_loss: 0.1003\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1589 - val_loss: 0.0911\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1546 - val_loss: 0.0833\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1502 - val_loss: 0.0766\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1469 - val_loss: 0.0712\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 5/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 0.5983 - val_loss: 0.1748\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1623 - val_loss: 0.1897\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1356 - val_loss: 0.1815\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1407 - val_loss: 0.1834\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1404 - val_loss: 0.1829\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1356 - val_loss: 0.1830\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1325 - val_loss: 0.1834\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1330 - val_loss: 0.1844\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1313 - val_loss: 0.1860\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.1332 - val_loss: 0.1884\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.8241 - val_loss: 0.8055\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2151 - val_loss: 0.7419\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2067 - val_loss: 0.6757\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1963 - val_loss: 0.6203\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1857 - val_loss: 0.5744\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.5367\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.1831 - val_loss: 0.5060\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1843 - val_loss: 0.4807\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1880 - val_loss: 0.4594\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.1885 - val_loss: 0.4411\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.8328 - val_loss: 0.2031\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2348 - val_loss: 0.2523\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2049 - val_loss: 0.2985\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2058 - val_loss: 0.3113\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1989 - val_loss: 0.3180\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1939 - val_loss: 0.3188\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1904 - val_loss: 0.3156\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1876 - val_loss: 0.3101\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1845 - val_loss: 0.3040\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1816 - val_loss: 0.2979\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.3381 - val_loss: 0.1747\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.2056 - val_loss: 0.1673\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.2061 - val_loss: 0.1495\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1990 - val_loss: 0.1338\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1906 - val_loss: 0.1207\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1865 - val_loss: 0.1095\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1803 - val_loss: 0.0998\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1731 - val_loss: 0.0914\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1707 - val_loss: 0.0843\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1683 - val_loss: 0.0783\n",
            "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month 6/6 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "--------------------- Model validated on fold  1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 19ms/step - loss: 1.0004 - val_loss: 0.2927\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2388 - val_loss: 0.3239\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1601 - val_loss: 0.2937\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1633 - val_loss: 0.2992\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1617 - val_loss: 0.2990\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1590 - val_loss: 0.2989\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1531 - val_loss: 0.2995\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1516 - val_loss: 0.3009\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1515 - val_loss: 0.3034\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.1509 - val_loss: 0.3071\n",
            "--------------------- Model validated on fold  2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 0.6101 - val_loss: 0.4782\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2433 - val_loss: 0.4456\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2389 - val_loss: 0.4082\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2279 - val_loss: 0.3751\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2170 - val_loss: 0.3464\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2086 - val_loss: 0.3219\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2034 - val_loss: 0.3011\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2119 - val_loss: 0.2834\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2128 - val_loss: 0.2681\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.2164 - val_loss: 0.2547\n",
            "--------------------- Model validated on fold  3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.6137 - val_loss: 0.2036\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2323 - val_loss: 0.2617\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2205 - val_loss: 0.2925\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2174 - val_loss: 0.3040\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2124 - val_loss: 0.3103\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2087 - val_loss: 0.3124\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2052 - val_loss: 0.3116\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2031 - val_loss: 0.3087\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.2008 - val_loss: 0.3047\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 4ms/step - loss: 0.1984 - val_loss: 0.3004\n",
            "--------------------- Model validated on fold  4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.4348 - val_loss: 0.2651\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.2290 - val_loss: 0.1826\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.2223 - val_loss: 0.1651\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.2174 - val_loss: 0.1500\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.2116 - val_loss: 0.1371\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.2058 - val_loss: 0.1266\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.2035 - val_loss: 0.1165\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1964 - val_loss: 0.1080\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 0s 4ms/step - loss: 0.1926 - val_loss: 0.0998\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 4ms/step - loss: 0.1917 - val_loss: 0.0932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpsQrU84mv0",
        "colab_type": "text"
      },
      "source": [
        "### Single-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEgXTi80WseN",
        "colab_type": "code",
        "outputId": "eb95ca9b-37e2-4166-cc39-ef6ca468d911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "allMses = []\n",
        "allClassifications = []\n",
        "bestGuessClassifications = []\n",
        "relaxedGuessClassifications = []\n",
        "\n",
        "def singleStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    correctDirection = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    print(noDatapoints)\n",
        "\n",
        "    noPredictions = 6\n",
        "\n",
        "    mse = model.evaluate(xTest,yTest)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "\n",
        "        current = xTest[x][-1][0]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        prediction = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        if((current > prediction) == (current > future)):\n",
        "                correctDirection = correctDirection + 1\n",
        "\n",
        "    #print(\"-------------------------------\")\n",
        "    #print(\"MSE: \" + str(round(mse,3)))\n",
        "    directionClass = correctDirection / noDatapoints\n",
        "    #print(\"Direction classification: \" + str(round(directionClass,3)))\n",
        "    #print(\"-------------------------------\")\n",
        "\n",
        "    mses.append(mse)\n",
        "    classifications.append(directionClass)\n",
        "\n",
        "    return mses, classifications\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        print(\"running test\")\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTest, yTest = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        mses,classifications = singleStepModelTests(models[i-1], xTest, yTest)\n",
        "\n",
        "        modelMses.append(mses)\n",
        "        modelClassifications.append(classifications)\n",
        "\n",
        "        meanMse = np.mean(modelMses)\n",
        "        meanClass = np.mean(modelClassifications)\n",
        "    \n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "    #print(\"Average MSE: \" + str(meanMse))\n",
        "    #print(\"Average classification: \" + str(np.mean(classifications)))\n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "\n",
        "    return modelMses, modelClassifications\n",
        "\n",
        "\n",
        "def bestGuessTests(models, fold):\n",
        "\n",
        "    valIndex = fold_locations[fold+1]\n",
        "    \n",
        "    if (fold==FOLDS-2):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[fold+2]\n",
        "\n",
        "    print(valIndex)\n",
        "    print(endIndex)\n",
        "\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    xTest, yTest = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    for datapoint in range(len(xTest)):\n",
        "\n",
        "        past = tf.constant([xTest[datapoint]])\n",
        "        future = yTest[datapoint]\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "\n",
        "            prediction = models[j].predict(past)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        actualMax = np.argmax(future)\n",
        "        predictedMax = np.argmax(predictions)\n",
        "\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "    \n",
        "    print(\"--------------------------------\")\n",
        "            \n",
        "\n",
        "\n",
        "    #print(\"---------------\")\n",
        "    bestMonthClass = correctMax / len(xTest)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xTest)\n",
        "\n",
        "    #print(\"Correct best month: \" + str(round(bestMonthClass,3)))\n",
        "\n",
        "    print(\"------------\")\n",
        "    print(correctMax)\n",
        "    print(bestMonthRelaxedClass)\n",
        "\n",
        "    return bestMonthClass, bestMonthRelaxedClass\n",
        "\n",
        "def runBestGuessTests(allModels):\n",
        "\n",
        "    foldPerformances = []\n",
        "    relaxedFoldperformances = []\n",
        "\n",
        "    for i in range(len(allModels[0])):\n",
        "\n",
        "        print(\"running best guess test\")\n",
        "\n",
        "        foldModels = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "            foldModels.append(allModels[j][i])\n",
        "\n",
        "        foldPerformance, relaxedFoldperformance = bestGuessTests(foldModels, i)\n",
        "\n",
        "        foldPerformances.append(foldPerformance)\n",
        "        relaxedFoldperformances.append(relaxedFoldperformance)\n",
        "\n",
        "    return foldPerformances, relaxedFoldperformances\n",
        "\n",
        "\n",
        "def singleStepExperiments():\n",
        "    \n",
        "    print(\"MODELS CREATED\")\n",
        "\n",
        "    for modelsForOneStep in allModels:\n",
        "        print(\"MODEL STEP TESTS\")\n",
        "\n",
        "        modelMses, modelClassifications = runModels(modelsForOneStep)\n",
        "        allMses.append(modelMses)\n",
        "        allClassifications.append(modelClassifications)\n",
        "\n",
        "    print(\"MODEL STEP TESTS COMPLETE\")\n",
        "    print(\"TESTING BEST GUESS ABILITY\")\n",
        "\n",
        "    bestGuess, relaxedGuess = runBestGuessTests(allModels)\n",
        "\n",
        "    bestGuessClassifications.append(bestGuess)\n",
        "    relaxedGuessClassifications.append(relaxedGuess)\n",
        "\n",
        "\n",
        "    print(\"TESTING COMPLETE\")\n",
        "\n",
        "singleStepExperiments()\n",
        "\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODELS CREATED\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3757\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.1708\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2844\n",
            "running test\n",
            "687\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0517\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3736\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2701\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3036\n",
            "running test\n",
            "687\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0557\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3997\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2034\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3042\n",
            "running test\n",
            "687\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0607\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3934\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2251\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2847\n",
            "running test\n",
            "687\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0740\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3317\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3981\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3232\n",
            "running test\n",
            "687\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0818\n",
            "MODEL STEP TESTS\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.3736\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2313\n",
            "running test\n",
            "815\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.2844\n",
            "running test\n",
            "687\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.0941\n",
            "MODEL STEP TESTS COMPLETE\n",
            "TESTING BEST GUESS ABILITY\n",
            "running best guess test\n",
            "947\n",
            "1894\n",
            "--------------------------------\n",
            "------------\n",
            "228\n",
            "0.4147239263803681\n",
            "running best guess test\n",
            "1894\n",
            "2841\n",
            "--------------------------------\n",
            "------------\n",
            "160\n",
            "0.449079754601227\n",
            "running best guess test\n",
            "2841\n",
            "3788\n",
            "--------------------------------\n",
            "------------\n",
            "313\n",
            "0.501840490797546\n",
            "running best guess test\n",
            "3788\n",
            "None\n",
            "--------------------------------\n",
            "------------\n",
            "118\n",
            "0.3173216885007278\n",
            "TESTING COMPLETE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-8mJXyPjrpm",
        "colab_type": "code",
        "outputId": "abe3d9c0-7a6f-4414-ae93-681b9fe80577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(allMses)                      #shape = FUTURE_STEPS, FOLDS\n",
        "print(allClassifications)           #shape = FUTURE_STEPS, FOLDS\n",
        "print(bestGuessClassifications)      #shape = FOLDS\n",
        "print(relaxedGuessClassifications)   #shape = FOLDS"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.37574145197868347], [0.17078211903572083], [0.28442180156707764], [0.05168940871953964]], [[0.37362560629844666], [0.2701045870780945], [0.30362141132354736], [0.05568969249725342]], [[0.3996758759021759], [0.20336085557937622], [0.30416470766067505], [0.0606694333255291]], [[0.39340466260910034], [0.22506402432918549], [0.28473907709121704], [0.07402651011943817]], [[0.3317168056964874], [0.3981090188026428], [0.3232356607913971], [0.08182618767023087]], [[0.37357091903686523], [0.23133672773838043], [0.2844029664993286], [0.09411440044641495]]]\n",
            "[[[0.5226993865030675], [0.5803680981595092], [0.39754601226993863], [0.5385735080058224]], [[0.5312883435582823], [0.5803680981595092], [0.4049079754601227], [0.5109170305676856]], [[0.5435582822085889], [0.5803680981595092], [0.40736196319018403], [0.49199417758369723]], [[0.5447852760736196], [0.5803680981595092], [0.41226993865030676], [0.4570596797671033]], [[0.5791411042944785], [0.5803680981595092], [0.4134969325153374], [0.4512372634643377]], [[0.5705521472392638], [0.5803680981595092], [0.4269938650306748], [0.44395924308588064]]]\n",
            "[[0.27975460122699386, 0.19631901840490798, 0.38404907975460123, 0.1717612809315866]]\n",
            "[[0.4147239263803681, 0.449079754601227, 0.501840490797546, 0.3173216885007278]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rudFJZfKboB6",
        "colab_type": "code",
        "outputId": "73112b58-f984-4812-d2ea-d50158718b23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(allMses[0])\n",
        "\n",
        "print(bestGuessClassifications[0])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.37574145197868347], [0.17078211903572083], [0.28442180156707764], [0.05168940871953964]]\n",
            "[0.27975460122699386, 0.19631901840490798, 0.38404907975460123, 0.1717612809315866]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwgG0U6-gUrZ",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DGg4vGuUmRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(mses,directionClass,bestClass):\n",
        "\n",
        "    for i in range(FUTURE_STEPS):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(mses[i]))\n",
        "        print(\"Dir: \" + str(directionClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "#printResults(allMses, allClassifications, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uwx3VvAnnRN",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TYzy6YXnpjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_time_steps(length,steps):\n",
        "    return list(np.arange(-length, 0,step=steps))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\n",
        "    marker = ['.-', 'rx', 'go']\n",
        "    time_steps = create_time_steps(TIME_LAGS,STEP)\n",
        "\n",
        "    if delta:\n",
        "        future = delta\n",
        "    else:\n",
        "        future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "        if i:\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                    label=labels[i])\n",
        "        else:\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt\n",
        "\n",
        "\n",
        "#for x, y in dataVal.take(1):\n",
        "#    plot = show_plot([x[0][:, 0].numpy(), y[0].numpy(),\n",
        "#                        model.predict(x)[0]], PREDICTION_HORIZON,\n",
        "#                    'Single Step Prediction')\n",
        "#    print(model.predict(x)[0])\n",
        "#    plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1syGFxznuVLK",
        "colab_type": "text"
      },
      "source": [
        "## Multi-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHJMXYsuZWp",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0P_sbFRuhMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiStepLSTM():\n",
        "    multiStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(units=32, return_sequences=True, input_shape = (HISTORY_STEPS, len(features))),\n",
        "        layers.LSTM(16, activation='relu'),\n",
        "        layers.Dense(FUTURE_STEPS)\n",
        "    ])\n",
        "\n",
        "    multiStepLSTMModel.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mse')\n",
        "    return multiStepLSTMModel\n",
        "\n",
        "multiStepModel = multiStepLSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IwcoGcu3mP",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UAjl2pn0eT",
        "colab_type": "code",
        "outputId": "77c19739-9570-4529-8319-872f629c254f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "models = []\n",
        "results = []\n",
        "dataTrainMulti = []\n",
        "\n",
        "for x in range(1, FOLDS):\n",
        "\n",
        "    valIndex = fold_locations[x]\n",
        "\n",
        "    multiStepModel = multiStepLSTM()\n",
        "    \n",
        "    if (x==FOLDS-1):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[x+1]\n",
        "\n",
        "    xTrainMulti, yTrainMulti = splitData(dataSet, target, 0, valIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "    xValMulti, yValMulti = splitData(dataSet, target, valIndex, None, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    dataTrainMulti = tf.data.Dataset.from_tensor_slices((xTrainMulti, yTrainMulti))\n",
        "    dataTrainMulti = dataTrainMulti.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    dataValMulti = tf.data.Dataset.from_tensor_slices((xValMulti, yValMulti))\n",
        "    dataValMulti = dataValMulti.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    print(\"--------------------- Model\", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "    steps_per = math.floor(len(xTrainMulti)/BATCH_SIZE)\n",
        "    print(steps_per)\n",
        "\n",
        "    result = multiStepModel.fit(dataTrainMulti, epochs=EPOCHS, steps_per_epoch=steps_per,\n",
        "                        validation_data=dataValMulti, validation_steps=50)\n",
        "    \n",
        "    models.append(multiStepModel)\n",
        "    results.append(result)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------- Model 1/4 --------------------------\n",
            "27\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 1.3409 - val_loss: 0.6527\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2690 - val_loss: 0.6033\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0857 - val_loss: 0.6364\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.0839 - val_loss: 0.6509\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0822 - val_loss: 0.6490\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0788 - val_loss: 0.6434\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0768 - val_loss: 0.6415\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0780 - val_loss: 0.6442\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0801 - val_loss: 0.6490\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.6551\n",
            "--------------------- Model 2/4 --------------------------\n",
            "58\n",
            "Epoch 1/10\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 0.7935 - val_loss: 0.6308\n",
            "Epoch 2/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2279 - val_loss: 0.6351\n",
            "Epoch 3/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1692 - val_loss: 0.6352\n",
            "Epoch 4/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1619 - val_loss: 0.6336\n",
            "Epoch 5/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1602 - val_loss: 0.6325\n",
            "Epoch 6/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1602 - val_loss: 0.6314\n",
            "Epoch 7/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1624 - val_loss: 0.6296\n",
            "Epoch 8/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1649 - val_loss: 0.6271\n",
            "Epoch 9/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1663 - val_loss: 0.6247\n",
            "Epoch 10/10\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1678 - val_loss: 0.6219\n",
            "--------------------- Model 3/4 --------------------------\n",
            "90\n",
            "Epoch 1/10\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.8078 - val_loss: 0.3239\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3929 - val_loss: 0.2131\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2311 - val_loss: 0.1901\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1647 - val_loss: 0.1776\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1432 - val_loss: 0.1733\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1332 - val_loss: 0.1815\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1254 - val_loss: 0.2072\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1176 - val_loss: 0.2359\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1133 - val_loss: 0.2703\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1093 - val_loss: 0.2780\n",
            "--------------------- Model 4/4 --------------------------\n",
            "121\n",
            "Epoch 1/10\n",
            "121/121 [==============================] - 1s 11ms/step - loss: 0.5825 - val_loss: 0.5296\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.2152 - val_loss: 0.4501\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.1508 - val_loss: 0.4757\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.1367 - val_loss: 0.5523\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.1267 - val_loss: 0.6146\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.1213 - val_loss: 0.6958\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.1152 - val_loss: 0.7906\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.1098 - val_loss: 0.8092\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 1s 7ms/step - loss: 0.1052 - val_loss: 0.7696\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 1s 6ms/step - loss: 0.1042 - val_loss: 0.6999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Uaxl7U4rEH",
        "colab_type": "text"
      },
      "source": [
        "### Multi-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMsesMulti = []\n",
        "allClassificationsMulti = []\n",
        "bestGuessClassificationsMulti = []\n",
        "relaxedGuessClassificationsMulti = []\n",
        "\n",
        "def multiStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    correctDirection = [0,0,0,0,0,0]\n",
        "    totalSquaredError = [0,0,0,0,0,0]\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    noPredictions = len(totalSquaredError)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1][0]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        predictions = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        temp = future[actualMax]\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "        future[actualMax]=temp\n",
        "\n",
        "        for y in range(noPredictions):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    for x in range(noPredictions):\n",
        "        mse = totalSquaredError[x] / noDatapoints\n",
        "        mses.append(mse)\n",
        "\n",
        "    for x in range(noPredictions):\n",
        "        percentInterval = correctDirection[x] / noDatapoints\n",
        "        classifications.append(percentInterval)\n",
        "\n",
        "    bestMonthClass = correctMax / noDatapoints\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / noDatapoints\n",
        "\n",
        "    allMsesMulti.append(mses)\n",
        "    allClassificationsMulti.append(classifications)\n",
        "    bestGuessClassificationsMulti.append(bestMonthClass)\n",
        "    relaxedGuessClassificationsMulti.append(bestMonthRelaxedClass)\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTestMulti, yTestMulti = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        multiStepModelTests(models[i-1], xTestMulti, yTestMulti)\n",
        "\n",
        "runModels(models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GoqA1iO8TQV",
        "colab_type": "code",
        "outputId": "c0ae01d7-9ab3-43a0-914a-92a57daad040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "allMsesMulti = list(map(list, zip(*allMsesMulti)))\n",
        "allClassificationsMulti = list(map(list, zip(*allClassificationsMulti)))\n",
        "\n",
        "print(allMsesMulti)\n",
        "print(allClassificationsMulti)\n",
        "print(bestGuessClassificationsMulti)\n",
        "print(relaxedGuessClassificationsMulti)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1317547737764125, 0.8228568941894123, 0.3814350659204064, 0.4080429215100614], [0.16915026160426602, 0.929306287712178, 0.3654188448295189, 0.7049553403983151], [0.18338584934600452, 0.9011635310950867, 0.5125760806423945, 0.7607118689400008], [0.2282895195661945, 0.9739380055559929, 0.46335026081392494, 0.6751744026754343], [0.25467822233151655, 0.7438374291282924, 0.5054446369340408, 0.9081553380133742], [0.3198712218655316, 0.6795721759678822, 0.6725066499939667, 0.9630535477904828]]\n",
            "[[0.4699386503067485, 0.5840490797546012, 0.4429447852760736, 0.46142649199417757], [0.49079754601226994, 0.5815950920245399, 0.3815950920245399, 0.48180494905385735], [0.4588957055214724, 0.6613496932515337, 0.32883435582822085, 0.519650655021834], [0.5190184049079755, 0.6539877300613497, 0.36319018404907977, 0.5065502183406113], [0.554601226993865, 0.6257668711656442, 0.35337423312883437, 0.46142649199417757], [0.550920245398773, 0.5803680981595092, 0.3239263803680982, 0.4279475982532751]]\n",
            "[0.37423312883435583, 0.1325153374233129, 0.03803680981595092, 0.16885007278020378]\n",
            "[0.498159509202454, 0.2883435582822086, 0.18159509202453988, 0.314410480349345]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSYYPtFgP4i",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2SBad6gSMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(monthAverageMses,monthAverageClass,bestClass):\n",
        "\n",
        "    for i in range(len(monthAverageMses)):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(monthAverageMses[i]))\n",
        "        print(\"Dir: \" + str(monthAverageClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "#printResults(monthAverageMses, monthAverageClass, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tii3SZcOw1qb",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR0uE5bfw5uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(TIME_LAGS,STEP)\n",
        "  num_out = len(true_future) * FUTURE_STEP\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
        "  plt.plot(np.arange(num_out, step=FUTURE_STEP), np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out,step=FUTURE_STEP), np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "#model = models[-1]\n",
        "\n",
        "#for x, y in dataTrainMulti.take(1):\n",
        "#\n",
        "#    print(x)\n",
        "\n",
        "    #print((multiStepModel.predict(x)[0]).index(max(multiStepModel.predict(x)[0])))\n",
        "#    print(model.predict(x)[0])\n",
        "#    multi_step_plot(x[0], y[0], model.predict(x)[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJ7pc31UP8k",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKanocQUSfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "gc.create(title=\"ExperimentResultsforex6\",folder=\"1zb8cLLf2RtYz9RuofDhGDgmTAoXD2VnE\")\n",
        "\n",
        "sh = gc.open('ExperimentResultsforex6')\n",
        "\n",
        "#sh.add_worksheet('OvrLibor') \n",
        "\n",
        "wk1 = sh[0]\n",
        "\n",
        "titles = ['SINGLE_STEP','MSE(Fold1)','MSE(Fold2)','MSE(Fold3)','MSE(Fold4)','MSE(avg)',\n",
        "          'Dir(Fold1)','Dir(Fold2)','Dir(Fold3)','Dir(Fold4)','Dir(avg)']\n",
        "\n",
        "shiftSize = FUTURE_STEPS + 5\n",
        "\n",
        "wk1.insert_rows(row = 0, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "mseAvgsSingle = []\n",
        "dirAvgsSingle = []\n",
        "bestSingle = []\n",
        "relaxedSingle = []\n",
        "\n",
        "mseAvgsMulti = []\n",
        "dirAvgsMulti = []\n",
        "bestMulti = []\n",
        "relaxedMultti = []\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMses[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allMses[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsSingle.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassifications[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allClassifications[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsSingle.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = step+1, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassifications[0])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestSingle = mean\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassifications[0])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedSingle = mean\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "\n",
        "titles[0] = 'MULTI-STEP'\n",
        "\n",
        "wk1.insert_rows(row = shiftSize, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMsesMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allMsesMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsMulti.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassificationsMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allClassificationsMulti[step])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsMulti.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+step+1, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassificationsMulti)\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestMulti = mean\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassificationsMulti)\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedMulti = mean\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "for i in range(FUTURE_STEPS):\n",
        "\n",
        "    month = 'Month ' + str(i+1)\n",
        "    row = [month]\n",
        "    row.append(str(mseAvgsSingle[i]))\n",
        "    row.append(str(dirAvgsSingle[i]))\n",
        "    row.append(str(mseAvgsMulti[i]))\n",
        "    row.append(str(dirAvgsMulti[i]))\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+FUTURE_STEPS+i+7, number = 1, values = row)\n",
        "\n",
        "row = ['Guesses']\n",
        "row.append(str(bestSingle))\n",
        "row.append(str(relaxedSingle))\n",
        "row.append(str(bestMulti))\n",
        "row.append(str(relaxedMulti))\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+FUTURE_STEPS+7, number = 1, values = row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4TyRi68dwuB",
        "colab_type": "text"
      },
      "source": [
        "# Visualising Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4k6qY-KcmWW",
        "colab_type": "text"
      },
      "source": [
        "## Importing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v140SYMbeHIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b7a787df-5cdb-4757-c2b5-e5efdec0d4fb"
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "import pygsheets\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "msesSingleAll = []\n",
        "msesMultiAll = []\n",
        "dirSingleAll = []\n",
        "dirMultiAll = []\n",
        "bestGuessSingle = []\n",
        "bestGuessMulti = []\n",
        "relaxedGuessSingle = []\n",
        "relaxedGuessMulti = []\n",
        "\n",
        "worksheetIndices = [1,2,3,4,6,8,10,12]\n",
        "\n",
        "def importWorksheet(index):\n",
        "\n",
        "    auth.authenticate_user()\n",
        "    credentials, _ = google.auth.default()\n",
        "    gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "    #gc.create(title=\"ExperimentResultsforexraw\",folder=\"1wdAbtGXmMA8xbW_ItVbXASyfhVUmyV8a\")\n",
        "\n",
        "    sh = gc.open('Copy of ExperimentResultsF')\n",
        "\n",
        "    wk1 = sh[index]\n",
        "\n",
        "    summaryRow = 25\n",
        "\n",
        "    msesSingle = []\n",
        "    msesMulti = []\n",
        "    dirSingle = []\n",
        "    dirMulti = []\n",
        "    guesses = []\n",
        "\n",
        "    for i in range(6):\n",
        "\n",
        "        row = wk1.get_row(summaryRow)\n",
        "\n",
        "        msesSingle.append(float(row[1]))\n",
        "        msesMulti.append(float(row[3]))\n",
        "        dirSingle.append(float(row[2]))\n",
        "        dirMulti.append(float(row[4]))\n",
        "\n",
        "        summaryRow = summaryRow + 1\n",
        "\n",
        "    guesses = wk1.get_row(summaryRow)\n",
        "\n",
        "    bestGuessSingle.append(float(guesses[1]))\n",
        "    bestGuessMulti.append(float(guesses[3]))\n",
        "    relaxedGuessSingle.append(float(guesses[2]))\n",
        "    relaxedGuessMulti.append(float(guesses[4]))\n",
        "\n",
        "    msesSingleAll.append(msesSingle)\n",
        "    msesMultiAll.append(msesMulti)\n",
        "    dirSingleAll.append(dirSingle)\n",
        "    dirMultiAll.append(dirMulti)\n",
        "\n",
        "\n",
        "def importAllWorksheets():\n",
        "\n",
        "    for index in worksheetIndices:\n",
        "\n",
        "        importWorksheet(index)\n",
        "\n",
        "\n",
        "importAllWorksheets()\n",
        "\n",
        "#monthGraph(msesSingleAll,'Months','MSE','MSE Single-step')\n",
        "#monthGraph(msesMultiAll,'Months','MSE','MSE Multi-step')\n",
        "#monthGraph(dirSingleAll,'Months','Classification','Classification Single-step')\n",
        "#monthGraph(dirMultiAll,'Months','Classification','Classification Multi-step')\n",
        "\n",
        "\n",
        "\n",
        "#plt.savefig('foo.png')\n",
        "#plt.show()"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-b3ee551558e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mimportAllWorksheets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m#monthGraph(msesSingleAll,'Months','MSE','MSE Single-step')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-b3ee551558e2>\u001b[0m in \u001b[0;36mimportAllWorksheets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworksheetIndices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mimportWorksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-133-b3ee551558e2>\u001b[0m in \u001b[0;36mimportWorksheet\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwk1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaryRow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmsesSingle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/worksheet.py\u001b[0m in \u001b[0;36mget_row\u001b[0;34m(self, row, returnas, include_tailing_empty, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \"\"\"\n\u001b[1;32m    522\u001b[0m         row = self.get_values((row, 1), (row, None), returnas=returnas,\n\u001b[0;32m--> 523\u001b[0;31m                               include_tailing_empty=include_tailing_empty, include_tailing_empty_rows=True, **kwargs)\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturnas\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'range'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mgrid_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'grange'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrid_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bounded_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/worksheet.py\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, start, end, returnas, majdim, include_tailing_empty, include_tailing_empty_rows, value_render, date_time_render_option, grange, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m             values = self.client.get_range(self.spreadsheet.id, grange.label, majdim,\n\u001b[1;32m    354\u001b[0m                                            \u001b[0mvalue_render_option\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_render\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                                            date_time_render_option=date_time_render_option, **kwargs)\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0mempty_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/client.py\u001b[0m in \u001b[0;36mget_range\u001b[0;34m(self, spreadsheet_id, value_range, major_dimension, value_render_option, date_time_render_option)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[1;32m    208\u001b[0m         result = self.sheet.values_get(spreadsheet_id, value_range, major_dimension, value_render_option,\n\u001b[0;32m--> 209\u001b[0;31m                                        date_time_render_option)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/sheet.py\u001b[0m in \u001b[0;36mvalues_get\u001b[0;34m(self, spreadsheet_id, value_range, major_dimension, value_render_option, date_time_render_option)\u001b[0m\n\u001b[1;32m    342\u001b[0m                                                            \u001b[0mvalueRenderOption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_render_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                                                            dateTimeRenderOption=date_time_render_option)\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_requests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# TODO: implement as base for batch update.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pygsheets/sheet.py\u001b[0m in \u001b[0;36m_execute_requests\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'429'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         )\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google_auth_httplib2.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Make the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         response, content = self.http.request(\n\u001b[0;32m--> 198\u001b[0;31m             uri, method, body=body, headers=request_headers, **kwargs)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# If the response indicated that the credentials needed to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1989\u001b[0m                         \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m                         \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m                         \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m                     )\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m         (response, content) = self._conn_request(\n\u001b[0;32m-> 1651\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m         )\n\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE9XHJ_AcpfQ",
        "colab_type": "text"
      },
      "source": [
        "## Create Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CywsiBscWCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "titles = ['Forex','CPI','IR','BOP','OVR','3m','6m','12m']\n",
        "months = [1,2,3,4,5,6]\n",
        "\n",
        "\n",
        "def monthGraph(data, xLabel, yLabel, title):\n",
        "\n",
        "    x = months\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "        y1 = data[i]\n",
        "        \n",
        "        plt.plot(x, y1, label = titles[i])\n",
        "\n",
        "    plt.xlabel(xLabel)\n",
        "    plt.ylabel(yLabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def guessBarChart(data1, data2, title, threshold):\n",
        "\n",
        "    x = np.arange(len(titles))\n",
        "    width = 0.35 \n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, data1, width, label='Single-Step')\n",
        "    rects2 = ax.bar(x + width/2, data2, width, label='Multi-step')\n",
        "    ax.plot([-0.35, 7.35], [threshold, threshold], \"k--\")\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('Classification')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(titles)\n",
        "    ax.legend()\n",
        "\n",
        "\n",
        "monthGraph(msesSingleAll,'Months','MSE','MSE Single-step')\n",
        "monthGraph(msesMultiAll,'Months','MSE','MSE Multi-step')\n",
        "monthGraph(dirSingleAll,'Months','Classification','Classification Single-step')\n",
        "monthGraph(dirMultiAll,'Months','Classification','Classification Multi-step')\n",
        "\n",
        "guessBarChart(bestGuessSingle, bestGuessMulti, 'Best Guess Classification', (1/6))\n",
        "guessBarChart(relaxedGuessSingle, relaxedGuessMulti, 'Relaxed Guess Classification', (1/3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRt7fgbEjj4o",
        "colab_type": "text"
      },
      "source": [
        "# ARIMA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WleLhkfMjl3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "xValues, yValues = splitData(dataSet, target, 3500, None, 40, FUTURE_STEPS)\n",
        "\n",
        "mses = []\n",
        "\n",
        "def mseARIMAmodel(p,q,d):\n",
        "\n",
        "    print(\"new\")\n",
        "\n",
        "    tmse = 0\n",
        "\n",
        "    for x in range(len(xValues)):\n",
        "        current = xValues[x][-1][0]\n",
        "        past = xValues[x]\n",
        "        future = yValues[x]\n",
        "\n",
        "        print(future)\n",
        "\n",
        "        model = ARIMA(past, order=(p,q,d))\n",
        "        model_fit = model.fit(disp=0)\n",
        "        predictions = model_fit.forecast(steps=FUTURE_STEPS)[0]\n",
        "\n",
        "        error = mean_squared_error(future,predictions)\n",
        "        tmse = tmse + error\n",
        "\n",
        "    mse = tmse / len(xValues)\n",
        "    print(\"For paramters: \" + str(p) + str(q) + str(d))\n",
        "    print(\"MSE: \" + str(mse))\n",
        "    mses.append(mse)\n",
        "\n",
        "\n",
        "def tuneParamters():\n",
        "    p_values = [4, 6, 8, 10]\n",
        "    d = 1\n",
        "    q = 0\n",
        "\n",
        "    for p in p_values:\n",
        "        mseARIMAmodel(p,d,q)\n",
        "\n",
        "\n",
        "tuneParamters()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuDSDMUEHNQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arimaMSES = []\n",
        "arimaDir = []\n",
        "arimaBestGuess = []\n",
        "arimaRelaxedGuess = []\n",
        "\n",
        "xValues, yValues = splitData(dataSet, target, 950, None, 40, FUTURE_STEPS)\n",
        "\n",
        "def testARIMA():\n",
        "\n",
        "    correctDirection = [0,0,0,0,0,0]\n",
        "    totalSquaredError = [0,0,0,0,0,0]\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    for x in range(len(xValues)):\n",
        "        print(x)\n",
        "        current = xValues[x][-1][0]\n",
        "        past = xValues[x]\n",
        "        future = yValues[x]\n",
        "\n",
        "        model = ARIMA(past, order=(6,1,0))\n",
        "        model_fit = model.fit(disp=0)\n",
        "        predictions = model_fit.forecast(steps=FUTURE_STEPS)[0]\n",
        "\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        temp = future[actualMax][0]\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        print(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "        print(temp)\n",
        "        future[actualMax]=temp\n",
        "\n",
        "        print(future)\n",
        "        \n",
        "\n",
        "        for y in range(FUTURE_STEPS):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            print(prediction)\n",
        "            print(actual)\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "\n",
        "            print(squaredDifference)\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    for x in range(FUTURE_STEPS):\n",
        "        mse = totalSquaredError[x] / len(xValues)\n",
        "        arimaMSES.append(mse)\n",
        "\n",
        "    for x in range(FUTURE_STEPS):\n",
        "        percentInterval = correctDirection[x] / len(xValues)\n",
        "        arimaDir.append(percentInterval)\n",
        "\n",
        "    bestMonthClass = correctMax / len(xValues)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xValues)\n",
        "\n",
        "    #arimaMSES.append(mses)\n",
        "    #arimaDir.append(classifications)\n",
        "    arimaBestGuess.append(bestMonthClass)\n",
        "    arimaRelaxedGuess.append(bestMonthRelaxedClass)\n",
        "\n",
        "testARIMA()\n",
        "\n",
        "print(arimaMSES) \n",
        "print(arimaDir) \n",
        "print(arimaBestGuess) \n",
        "print(arimaRelaxedGuess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1nogEbk1jji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0baa2ed0-9a15-4392-dd53-f1f93383b20d"
      },
      "source": [
        "print(arimaMSES) \n",
        "print(arimaDir) \n",
        "print(arimaBestGuess) \n",
        "print(arimaRelaxedGuess)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.03941905]), array([0.08542518]), array([0.12269653]), array([0.1716153]), array([0.22304451]), array([0.26209918])]\n",
            "[0.4764133957508102, 0.4897371263953907, 0.4792942023766655, 0.48541591645660787, 0.49225783219301406, 0.5091825711199136]\n",
            "[0.19157364061937343]\n",
            "[0.34353619013323733]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}