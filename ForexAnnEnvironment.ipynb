{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ForexAnnEnvironment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Y23CLo2oUco-O4CAkKZhYsjzzzbnTeLP",
      "authorship_tag": "ABX9TyN84E3hnlkIonhWIb3NIRJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robLaing2/Forex_ANN_Forecasting/blob/master/ForexAnnEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo0f_HWfsWuF",
        "colab_type": "text"
      },
      "source": [
        "# Setting up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq2rgCjlTWrR",
        "colab_type": "code",
        "outputId": "77c47737-465f-4678-d97d-e96fa938dc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"j3\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "j3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPPZ27ksNag",
        "colab_type": "code",
        "outputId": "6150f6b3-6590-4319-e3b2-22265c6f14f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "!pip install quandl\n",
        "!pip install dbnomics\n",
        "#!pip install FRB\n",
        "!pip install fred\n",
        "!pip install mock\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow==2.0.0\n",
        "\n",
        "import fred\n",
        "from mock import Mock\n",
        "import requests\n",
        "import json\n",
        "import quandl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, CuDNNLSTM\n",
        "from dbnomics import fetch_series\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl) (8.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl) (1.12.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.0.3)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from quandl) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from quandl) (1.18.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from quandl) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14->quandl) (2018.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: dbnomics in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from dbnomics) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->dbnomics) (1.18.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->dbnomics) (2020.4.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21->dbnomics) (1.12.0)\n",
            "Requirement already satisfied: fred in /usr/local/lib/python3.6/dist-packages (3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fred) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fred) (2.8)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (4.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knovwSza04MP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSX-AVfVGK6s",
        "colab_type": "code",
        "outputId": "ffc1a196-8dc5-488c-f0e8-e05ca522c53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "START_DATE = '2001-01-01'\n",
        "END_DATE = '2020-02-01'\n",
        "\n",
        "pd.set_option('display.max_rows', 25)\n",
        "pd.set_option('display.max_columns', 25)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mBJkhEqGfRq",
        "colab_type": "text"
      },
      "source": [
        "## Moving average function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpuooBtRGero",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getMovingAverages(data, windowSize):\n",
        "\n",
        "    movingAverages = []\n",
        "\n",
        "    for x in range(len(data)):\n",
        "        if (x < windowSize):\n",
        "            window = data[:x+1]\n",
        "        else:\n",
        "            window = data[x-(windowSize - 1):x+1]\n",
        "        \n",
        "        total = sum(window)\n",
        "        average = total / len(window)\n",
        "        movingAverages.append(average)\n",
        "\n",
        "    return movingAverages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n68WYYVB6UK7",
        "colab_type": "text"
      },
      "source": [
        "## FOREX data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf33ycLPPufj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get FOREX data\n",
        "quandl.ApiConfig.api_key = \"VXqfuyrbTE8xxYZzqePw\"\n",
        "dataGbpEurRate = quandl.get(\"BOE/XUDLERS\", start_date=START_DATE, end_date=END_DATE, returns=\"numpy\")\n",
        "forexDataN = dataGbpEurRate.Value\n",
        "\n",
        "forexRaw = np.asarray(forexDataN)\n",
        "forex_mean_raw = forexRaw.mean()\n",
        "forex_std_raw = forexRaw.std()\n",
        "forexRaw = (forexRaw - forex_mean_raw) / forex_std_raw\n",
        "\n",
        "forexMonthMovAvg = getMovingAverages(forexDataN, 10)\n",
        "\n",
        "forexMonthMovAvg = np.asarray(forexMonthMovAvg)\n",
        "forex_mean_avg = forexMonthMovAvg.mean()\n",
        "forex_std_avg = forexMonthMovAvg.std()\n",
        "forexMonthMovAvg = (forexMonthMovAvg - forex_mean_avg) / forex_std_avg\n",
        "\n",
        "ukFOREXdates = []\n",
        "for x in dataGbpEurRate.Date:\n",
        "    ukFOREXdates.append(pd.Timestamp(x))\n",
        "\n",
        "\n",
        "forexData = {'Date':ukFOREXdates,'Value':forexMonthMovAvg}\n",
        "\n",
        "forexRawDict = {ukFOREXdates[i]: forexRaw[i] for i in range(len(ukFOREXdates))}\n",
        "\n",
        "mainDf = pd.DataFrame(forexData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrnOCJajGrND",
        "colab_type": "text"
      },
      "source": [
        "## Interest Rate Data (INT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUTeDp07W41L",
        "colab_type": "text"
      },
      "source": [
        "### INT data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0f5HNs21pcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GBPovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBPONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EURovr = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EURONTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR1month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR1MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start=' + START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR3month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR3MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR6month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR6MTD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "GBP12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=GBP12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "EUR12month = requests.get('https://api.stlouisfed.org/fred/series/observations?series_id=EUR12MD156N&api_key=cdc4dd9f1b0596f6209a77cec5453528&file_type=json&observation_start='+ START_DATE + '&observation_end='+ END_DATE)\n",
        "\n",
        "GBRovrJson = (json.loads(GBPovr.content))[\"observations\"]\n",
        "EURovrJson = (json.loads(EURovr.content))[\"observations\"]\n",
        "GBR1mJson = (json.loads(GBP1month.content))[\"observations\"]\n",
        "EUR1mJson = (json.loads(EUR1month.content))[\"observations\"]\n",
        "GBR3mJson = (json.loads(GBP3month.content))[\"observations\"]\n",
        "EUR3mJson = (json.loads(EUR3month.content))[\"observations\"]\n",
        "GBR6mJson = (json.loads(GBP6month.content))[\"observations\"]\n",
        "EUR6mJson = (json.loads(EUR6month.content))[\"observations\"]\n",
        "GBR12mJson = (json.loads(GBP12month.content))[\"observations\"]\n",
        "EUR12mJson = (json.loads(EUR12month.content))[\"observations\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUgecCRUBkiR",
        "colab_type": "text"
      },
      "source": [
        "### INT data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkkAjnFLBlhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanDataSets(dataset):\n",
        "\n",
        "    dataDict = {pd.Timestamp(dataset[i][\"date\"]): dataset[i][\"value\"] for i in range(len(dataset))}\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "        value = dataDict.get(row['Date'], 1000000)\n",
        "\n",
        "        if (value=='.'):\n",
        "            value = 1000000\n",
        "\n",
        "        if(value==1000000):\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataDict.get(dateBelow, 1000000)\n",
        "            valueAbove = dataDict.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "GBRovrC = cleanDataSets(GBRovrJson)\n",
        "EURovrC = cleanDataSets(EURovrJson)\n",
        "GBR3mC = cleanDataSets(GBR3mJson)\n",
        "EUR3mC = cleanDataSets(EUR3mJson)\n",
        "GBR6mC = cleanDataSets(GBR6mJson)\n",
        "EUR6mC = cleanDataSets(EUR6mJson)\n",
        "GBR12mC = cleanDataSets(GBR12mJson)\n",
        "EUR12mC = cleanDataSets(EUR12mJson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euiAqH5oXFmC",
        "colab_type": "text"
      },
      "source": [
        "### INT feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zjzi_yf1sjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDifferenceFeatures(xDict, yDict, avg):\n",
        "    dates = []\n",
        "    valuesX = []\n",
        "    valuesY = []\n",
        "    ratioValues = []                      \n",
        "\n",
        "    for k,v in xDict.items():\n",
        "\n",
        "        match = yDict.get(k, 0)\n",
        "        valuesX.append(float(v))\n",
        "        valuesY.append(float(match))\n",
        "        dates.append(k)\n",
        " \n",
        "    datasetXarr = np.array(valuesX, dtype=np.float)\n",
        "    datasetYarr = np.array(valuesY, dtype=np.float)\n",
        "\n",
        "    diffValues = datasetXarr - datasetYarr\n",
        "\n",
        "    if(avg):\n",
        "        diffValues = getMovingAverages(diffValues, 10)\n",
        "\n",
        "    diffValues = np.asarray(diffValues)\n",
        "\n",
        "    data_mean = diffValues.mean()\n",
        "    data_std = diffValues.std()\n",
        "    dataNormalised = (diffValues - data_mean) - data_std\n",
        "\n",
        "    res = {dates[i]: dataNormalised[i] for i in range(len(dates))}\n",
        "\n",
        "    return res\n",
        "\n",
        "ovrRatio = getDifferenceFeatures(GBRovrC,EURovrC, False)\n",
        "threeMRatio = getDifferenceFeatures(GBR3mC,EUR3mC, False)\n",
        "sixMRatio = getDifferenceFeatures(GBR6mC,EUR6mC, False)\n",
        "twelveMRatio = getDifferenceFeatures(GBR12mC,EUR12mC, False)\n",
        "\n",
        "ovrRatioMovAvg = getDifferenceFeatures(GBRovrC,EURovrC, True)\n",
        "threeMRatioMovAvg = getDifferenceFeatures(GBR3mC,EUR3mC, True)\n",
        "sixMRatioMovAvg = getDifferenceFeatures(GBR6mC,EUR6mC, True)\n",
        "twelveMRatioMovAvg = getDifferenceFeatures(GBR12mC,EUR12mC, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4pR6Orq9ma",
        "colab_type": "text"
      },
      "source": [
        "## Inflation data (CPI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUCPuwpYOnn",
        "colab_type": "text"
      },
      "source": [
        "### CPI data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVanjbf-n1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukCPI = fetch_series('IMF/CPI/M.GB.PCPIHA_PC_CP_A_PT')\n",
        "euCPI = fetch_series('IMF/CPI/M.U2.PCPIHA_PC_CP_A_PT')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukCPI = ukCPI.query(dbnomicsQuery)\n",
        "euCPI = euCPI.query(dbnomicsQuery)\n",
        "\n",
        "ukCPIDict = {ukCPI.period.iloc[i]: ukCPI.value.iloc[i] for i in range(len(ukCPI))}\n",
        "euCPIDict = {euCPI.period.iloc[i]: euCPI.value.iloc[i] for i in range(len(euCPI))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhffkl2I-kY0",
        "colab_type": "text"
      },
      "source": [
        "### CPI data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxREJ3rFVj5",
        "colab_type": "code",
        "outputId": "71cdaaeb-6b40-4f33-ca2b-9c86812bf447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def cleanMonthlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        roundD = row['Date'].replace(day=1)\n",
        "\n",
        "        value= dataset.get(pd.Timestamp(roundD),1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            clean = False\n",
        "            dateBelow = mainDf.Date.iloc[index-1]\n",
        "            dateAbove = mainDf.Date.iloc[index+1]\n",
        "\n",
        "            valueBelow = dataset.get(dateBelow, 1000000)\n",
        "            valueAbove = dataset.get(dateAbove, 1000000)\n",
        "\n",
        "            average = (float(valueBelow) + float(valueAbove)) / 2\n",
        "\n",
        "            value = average\n",
        "\n",
        "        cleanedDataDict[row['Date']] = value\n",
        "        count = count + 1\n",
        "\n",
        "    if(clean==True):\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukCPIDictC = cleanMonthlyData(ukCPIDict)\n",
        "euCPIDictC = cleanMonthlyData(euCPIDict)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T2dZu4RA6Sl",
        "colab_type": "text"
      },
      "source": [
        "### CPI feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBLa-rIMNPut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = []\n",
        "ukCPIarr = []\n",
        "euCPIarr = []\n",
        "\n",
        "for k,v in ukCPIDictC.items():\n",
        "\n",
        "    match = euCPIDictC.get(k, 0)\n",
        "\n",
        "    ukCPIarr.append(v)\n",
        "    euCPIarr.append(match)\n",
        "    dates.append(k)\n",
        "\n",
        "ukCPIarr = np.array(ukCPIarr, dtype=np.float)\n",
        "euCPIarr = np.array(euCPIarr, dtype=np.float)\n",
        "\n",
        "ukEuCpiRatio = ukCPIarr - euCPIarr\n",
        "\n",
        "# Normalise CPI data\n",
        "cpi_mean = ukEuCpiRatio.mean()\n",
        "cpi_std = ukEuCpiRatio.std()\n",
        "\n",
        "ukEuCpiRatio = (ukEuCpiRatio - cpi_mean) / cpi_std\n",
        "\n",
        "cpiDict = {dates[i]: ukEuCpiRatio[i] for i in range(len(dates))}\n",
        "\n",
        "cpiData = {'Date':dates, 'Value':ukEuCpiRatio}\n",
        "cpiDf = pd.DataFrame(cpiData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz9f5MPUOBva",
        "colab_type": "text"
      },
      "source": [
        "## International Reserves data (IR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeoJsXNEQA_m",
        "colab_type": "text"
      },
      "source": [
        "### IR data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXRsvqQIQMG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukIR = fetch_series('IMF/IFS/M.GB.RAFAGOLDM_USD')\n",
        "euIR = fetch_series('IMF/IFS/M.U2.RAFAGOLDM_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukIR = ukIR.query(dbnomicsQuery)\n",
        "euIR = euIR.query(dbnomicsQuery)\n",
        "\n",
        "ukIRDict = {ukIR.period.iloc[i]: ukIR.value.iloc[i] for i in range(len(ukIR))}\n",
        "euIRDict = {euIR.period.iloc[i]: euIR.value.iloc[i] for i in range(len(euIR))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj0vLPaBQFde",
        "colab_type": "text"
      },
      "source": [
        "### IR data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZbMYaFhQREG",
        "colab_type": "code",
        "outputId": "d8c29030-49d1-4486-a426-6bd28673a214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ukIRDictC = cleanMonthlyData(ukIRDict)\n",
        "euIRDictC = cleanMonthlyData(euIRDict)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCU1PotbQH3d",
        "colab_type": "text"
      },
      "source": [
        "### IR feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu_mv-VUOMyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IRdates = []\n",
        "ukIRarr = []\n",
        "euIRarr = []\n",
        "\n",
        "for k,v in ukIRDictC.items():\n",
        "\n",
        "    match = euIRDictC.get(k, 0)\n",
        "\n",
        "    ukIRarr.append(v)\n",
        "    euIRarr.append(match)\n",
        "    IRdates.append(k)\n",
        "\n",
        "\n",
        "ukIRarr = np.array(ukIRarr, dtype=np.float)\n",
        "euIRarr = np.array(euIRarr, dtype=np.float)\n",
        "\n",
        "ukEuIRRatio = ukIRarr / euIRarr\n",
        "\n",
        "ir_mean = ukEuIRRatio.mean()\n",
        "ir_std = ukEuIRRatio.std()\n",
        "ukEuIRRatio = (ukEuIRRatio - ir_mean) / ir_std\n",
        "\n",
        "irDict = {IRdates[i]: ukEuIRRatio[i] for i in range(len(IRdates))}\n",
        "\n",
        "irData = {'Date':IRdates, 'Value':ukEuIRRatio}\n",
        "irDf = pd.DataFrame(irData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW8UDb5OziA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Balance of Payments data (BOP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FpSuRNLR8Rb",
        "colab_type": "text"
      },
      "source": [
        "### BOP data retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_2Bg9PSEym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ukBOP = fetch_series('IMF/BOP/Q.GB.BACK_BP6_USD')\n",
        "euBOP = fetch_series('IMF/BOP/Q.U2.BACK_BP6_USD')\n",
        "\n",
        "dbnomicsQuery = \"period >= '\" + START_DATE + \"'\"\n",
        "\n",
        "ukBOP = ukBOP.query(dbnomicsQuery)\n",
        "euBOP = euBOP.query(dbnomicsQuery)\n",
        "\n",
        "ukBOPDict = {ukBOP.period.iloc[i]: ukBOP.value.iloc[i] for i in range(len(ukBOP))}\n",
        "euBOPDict = {euBOP.period.iloc[i]: euBOP.value.iloc[i] for i in range(len(euBOP))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EsjDOHjR_Q-",
        "colab_type": "text"
      },
      "source": [
        "### BOP data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsVJ5XKGSmu_",
        "colab_type": "code",
        "outputId": "ffa2cfd6-a102-410d-b2c0-2387b7c802ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def cleanQuarterlyData(dataset):\n",
        "\n",
        "    cleanedDataDict= {}\n",
        "    count = 0\n",
        "    clean=True\n",
        "\n",
        "    for index, row in mainDf.iterrows():\n",
        "\n",
        "        date = row['Date']\n",
        "        dateMonth = date.replace(day=1)\n",
        "        dateQuarter = date.quarter\n",
        "        \n",
        "        switcher={\n",
        "            1:date.replace(month=1,day=1),\n",
        "            2:date.replace(month=4,day=1),\n",
        "            3:date.replace(month=7,day=1),\n",
        "            4:date.replace(month=10,day=1)\n",
        "        }\n",
        "\n",
        "        dateRoundedQuarter = switcher.get(dateQuarter)\n",
        "\n",
        "        value = dataset.get(dateRoundedQuarter,1000000)\n",
        "\n",
        "        if(value==1000000):\n",
        "            mainDf.drop([index], inplace=True)\n",
        "        else:\n",
        "            cleanedDataDict[row['Date']] = value\n",
        "\n",
        "\n",
        "    clean = True\n",
        "    for k,v in cleanedDataDict.items():\n",
        "        if (v==1000000):\n",
        "            clean = False;\n",
        "\n",
        "    if (clean==False):\n",
        "        print(\"Data is unlcean\")\n",
        "    else:\n",
        "        print(\"Data is clean\")\n",
        "\n",
        "\n",
        "    return cleanedDataDict\n",
        "\n",
        "\n",
        "ukBOPDictC = cleanQuarterlyData(ukBOPDict)\n",
        "euBOPDictC = cleanQuarterlyData(euBOPDict)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data is clean\n",
            "Data is clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5T04eISB7G",
        "colab_type": "text"
      },
      "source": [
        "### BOP feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYGfT2feO9Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOPdates = []\n",
        "ukBOParr = []\n",
        "euBOParr = []\n",
        "\n",
        "for k,v in ukBOPDictC.items():\n",
        "\n",
        "    match = euBOPDictC.get(k, 0)\n",
        "\n",
        "    ukBOParr.append(v)\n",
        "    euBOParr.append(match)\n",
        "    BOPdates.append(k)\n",
        "\n",
        "ukBOParr = np.array(ukBOParr, dtype=np.float)\n",
        "euBOParr = np.array(euBOParr, dtype=np.float)\n",
        "\n",
        "ukEuBOPRatio = ukBOParr / euBOParr\n",
        "\n",
        "# Normalise BOP data\n",
        "bop_mean = ukEuBOPRatio.mean()\n",
        "bop_std = ukEuBOPRatio.std()\n",
        "ukEuBOPRatio = (ukEuBOPRatio - bop_mean) / bop_std\n",
        "\n",
        "bopDict = {BOPdates[i]: ukEuBOPRatio[i] for i in range(len(BOPdates))}\n",
        "\n",
        "bopData = {'Date':BOPdates, 'Value':ukEuBOPRatio}\n",
        "bopDf = pd.DataFrame(bopData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtmcOd1QXf-",
        "colab_type": "text"
      },
      "source": [
        "## Creating full data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOlDl_FgRI8",
        "colab_type": "code",
        "outputId": "e9bd2514-09af-4468-d55a-d439adacbee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "completeDf = pd.DataFrame(columns=['Date','ForexAvg','ForexRaw','CPIRatio', 'IRRatio',\n",
        "                                   'BOPRatio', 'OvrLIBOR','OvrAvg','3mLIBOR', '3mAvg',\n",
        "                                   '6mLIBOR','6mAvg','12mLIBOR', '12mAvg'])\n",
        "\n",
        "cpiCounter = 0\n",
        "irCounter = 0\n",
        " \n",
        "for index, row in mainDf.iterrows():\n",
        "\n",
        "    date = row['Date']\n",
        "    forex = row['Value']\n",
        "\n",
        "    forexRaw = forexRawDict.get(date, 0)\n",
        "    \n",
        "    cpi = cpiDict.get(date, 0)\n",
        "    ir = irDict.get(date,0)\n",
        "    bop = bopDict.get(date,0)\n",
        "\n",
        "    ovrI = ovrRatio.get(date, 0)\n",
        "    ovrImov = ovrRatioMovAvg.get(date, 0)\n",
        "    i3month = threeMRatio.get(date, 0)\n",
        "    i3monthmov = threeMRatioMovAvg.get(date, 0)\n",
        "    i6month = sixMRatio.get(date, 0)\n",
        "    i6monthmov = sixMRatioMovAvg.get(date, 0)\n",
        "    i12month = twelveMRatio.get(date, 0)\n",
        "    i12monthmov = twelveMRatioMovAvg.get(date, 0)\n",
        "\n",
        "    completeDf = completeDf.append({'Date':date,\n",
        "                            'ForexAvg':forex,\n",
        "                            'ForexRaw':forexRaw,\n",
        "                            'CPIRatio': cpi,\n",
        "                            'IRRatio' : ir,\n",
        "                            'BOPRatio': bop,\n",
        "                            'OvrLIBOR': ovrI,\n",
        "                            'OvrAvg':ovrImov,\n",
        "                            '3mLIBOR': i3month,\n",
        "                            '3mAvg':i3monthmov,\n",
        "                            '6mLIBOR': i6month,\n",
        "                            '6mAvg':i6monthmov,\n",
        "                            '12mLIBOR': i12month,\n",
        "                            '12mAvg':i12monthmov},\n",
        "                            ignore_index=True)\n",
        "\n",
        "print(completeDf)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "           Date  ForexAvg  ForexRaw  CPIRatio   IRRatio  BOPRatio  OvrLIBOR  \\\n",
            "0    2001-01-02  1.636760  1.638603 -1.445720  4.969333  0.295915 -0.772414   \n",
            "1    2001-01-03  1.674689  1.714443 -1.445720  4.969333  0.295915 -0.477104   \n",
            "2    2001-01-04  1.665890  1.650130 -1.445720  4.969333  0.295915 -0.993354   \n",
            "3    2001-01-05  1.646925  1.591885 -1.445720  4.969333  0.295915 -1.143974   \n",
            "4    2001-01-08  1.643678  1.632535 -1.445720  4.969333  0.295915 -1.018354   \n",
            "...         ...       ...       ...       ...       ...       ...       ...   \n",
            "4734 2019-09-24 -1.097566 -1.055864  0.563933  0.376361  0.144160 -0.502294   \n",
            "4735 2019-09-25 -1.093258 -1.087414  0.563933  0.376361  0.144160 -0.488964   \n",
            "4736 2019-09-26 -1.087432 -1.100155  0.563933  0.376361  0.144160 -0.497724   \n",
            "4737 2019-09-27 -1.087371 -1.118357  0.563933  0.376361  0.144160 -0.503184   \n",
            "4738 2019-09-30 -1.086885 -1.083167  0.563933  0.376361  0.144160 -0.502714   \n",
            "\n",
            "        OvrAvg   3mLIBOR     3mAvg   6mLIBOR     6mAvg  12mLIBOR    12mAvg  \n",
            "0    -0.742444 -0.652288 -0.651632 -0.684519 -0.683848 -0.666377 -0.665553  \n",
            "1    -0.594789 -0.623068 -0.637022 -0.629989 -0.656583 -0.624667 -0.644698  \n",
            "2    -0.717654 -0.610878 -0.628089 -0.618739 -0.643745 -0.612477 -0.633683  \n",
            "3    -0.816742 -0.601038 -0.621162 -0.603189 -0.633438 -0.591537 -0.622941  \n",
            "4    -0.851070 -0.609318 -0.618662 -0.623429 -0.631302 -0.605907 -0.619369  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "4734 -0.528107 -0.535958 -0.515632 -0.489249 -0.488665 -0.483677 -0.480624  \n",
            "4735 -0.516770 -0.534278 -0.521064 -0.479419 -0.490425 -0.489427 -0.483676  \n",
            "4736 -0.505546 -0.525638 -0.525677 -0.475109 -0.492161 -0.490657 -0.488426  \n",
            "4737 -0.495247 -0.527358 -0.526652 -0.499669 -0.491533 -0.521017 -0.491726  \n",
            "4738 -0.485692 -0.526388 -0.527090 -0.500849 -0.492294 -0.519787 -0.495226  \n",
            "\n",
            "[4739 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9gVEULcO0zD",
        "colab_type": "text"
      },
      "source": [
        "# Variable Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpiLy6YcO5-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variables = ['CPIRatio', 'IRRatio', 'BOPRatio', 'OvrLIBOR','3mLIBOR','6mLIBOR','12mLIBOR']\n",
        "\n",
        "forex = completeDf['ForexAvg'].tolist()\n",
        "correlations = []\n",
        "\n",
        "for x in range(len(variables)):\n",
        "    \n",
        "    column = completeDf[variables[x]].tolist()\n",
        "\n",
        "    r = np.corrcoef(forex, column)\n",
        "\n",
        "    correlations.append(r[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7MnSU94FOw",
        "colab_type": "code",
        "outputId": "b8ce2e3a-0917-440b-8733-428741f4339f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "y_pos = np.arange(0,14,2)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.bar(y_pos, correlations, align='center', alpha=0.5, color=(0.0, 0.0, 0.0, 1))\n",
        "plt.xticks(y_pos, variables)\n",
        "plt.ylabel('Usage')\n",
        "plt.title('Correlations')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuMlG3PXw4dX",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSvQDGXwFVJ",
        "colab_type": "text"
      },
      "source": [
        "## Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4_5GXRVwHR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "EPOCHS = 10\n",
        "#EVALUATION_INTERVAL = 16\n",
        "VALIDATION_STEPS = 50\n",
        "BATCH_SIZE = 30\n",
        "FOLDS = 5\n",
        "\n",
        "HISTORY_STEPS = 24\n",
        "FUTURE_STEPS = 6\n",
        "\n",
        "features = ['ForexAvg']\n",
        "\n",
        "dataSet = completeDf[features]\n",
        "dataSet = dataSet.values\n",
        "\n",
        "fold_steps = math.floor(len(dataSet) / FOLDS)\n",
        "fold_locations = []\n",
        "results = []\n",
        "\n",
        "for x in range(0,len(dataSet), fold_steps):\n",
        "    fold_locations.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4r-1IZnpzKj",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGzFM320p1Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index - 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index - 22\n",
        "\n",
        "    indices = list(reversed(indices))\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def singleStepDataSplit(dataset, target, startIndex, endIndex,\n",
        "                steps, future_steps):  \n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "\n",
        "    max_index = 22 * future_steps\n",
        "    target_size = round(21.75 * future_steps)\n",
        "\n",
        "    startIndex = startIndex + history_size\n",
        "\n",
        "    if endIndex is None:\n",
        "        endIndex = len(dataset) - max_index\n",
        "\n",
        "    for i in range(startIndex, endIndex):\n",
        "        dataIndices = getIndices(i,steps)\n",
        "        data.append(dataset[dataIndices])\n",
        "        labels.append(target[i+target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def getFutureIndices(currentIndex, steps):\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    index = currentIndex + 22\n",
        "\n",
        "    for i in range(1, steps + 1):\n",
        "        if i % 4 == 0:\n",
        "            indices.append(index)\n",
        "            index = index + 21\n",
        "        else:\n",
        "            indices.append(index)\n",
        "            index = index + 22\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def splitData(dataset, target, start_index, end_index, steps, future_steps):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    history_size = 22 * steps\n",
        "    target_size = 22 * future_steps\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = getIndices(i,steps)\n",
        "        data.append(dataset[indices])\n",
        "        indiciesL = getFutureIndices(i, future_steps)\n",
        "        labels.append(target[indiciesL])\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nd5E-y_o1HY",
        "colab_type": "text"
      },
      "source": [
        "## Single-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MseG60kHb2hB",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYFUp6Mb98n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def singleStepLSTM():\n",
        "    singleStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(32, input_shape=(HISTORY_STEPS, len(features))),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    singleStepLSTMModel.compile(optimizer='adam', loss='mse')\n",
        "    return singleStepLSTMModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJqrxLV9xCEB",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmajAmS4xEs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataVal = []\n",
        "\n",
        "def trainModel(history_steps, future_step):\n",
        "\n",
        "    models = []\n",
        "    results = []\n",
        "\n",
        "    for x in range(1, FOLDS):\n",
        "\n",
        "        model = singleStepLSTM()\n",
        "\n",
        "        valIndex = fold_locations[x]\n",
        "        \n",
        "        if (x==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[x+1]\n",
        "\n",
        "        xTrain, yTrain = singleStepDataSplit(dataSet, dataSet[:, 0], 0, valIndex, history_steps, future_step)\n",
        "        xVal, yVal = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, history_steps, future_step)\n",
        "\n",
        "\n",
        "        dataTrain = tf.data.Dataset.from_tensor_slices((xTrain, yTrain))\n",
        "        dataTrain = dataTrain.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        dataVal = tf.data.Dataset.from_tensor_slices((xVal, yVal))\n",
        "        dataVal = dataVal.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "        print(\"--------------------- Model validated on fold \", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "        steps_per = math.floor(len(xTrain)/BATCH_SIZE)\n",
        "        print(steps_per)\n",
        "\n",
        "        result = model.fit(dataTrain, epochs=EPOCHS, steps_per_epoch=steps_per,\n",
        "                            validation_data=dataVal, validation_steps=50)\n",
        "        \n",
        "        models.append(model)\n",
        "        results.append(result)\n",
        "\n",
        "    return models\n",
        "\n",
        "\n",
        "def createModelsForAllSteps():\n",
        "\n",
        "    allModels = []\n",
        "\n",
        "    for i in range(1,FUTURE_STEPS+1):\n",
        "\n",
        "        print(\"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Month\", \"%d/%d &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\" % (i, FUTURE_STEPS))\n",
        "\n",
        "        models = trainModel(HISTORY_STEPS, i)\n",
        "        allModels.append(models)\n",
        "\n",
        "\n",
        "    return allModels\n",
        "\n",
        "allModels = createModelsForAllSteps()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpsQrU84mv0",
        "colab_type": "text"
      },
      "source": [
        "### Single-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEgXTi80WseN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMses = []\n",
        "allClassifications = []\n",
        "bestGuessClassifications = []\n",
        "relaxedGuessClassifications = []\n",
        "\n",
        "def singleStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    correctDirection = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    print(noDatapoints)\n",
        "\n",
        "    noPredictions = 6\n",
        "\n",
        "    mse = model.evaluate(xTest,yTest)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        prediction = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        if((current > prediction) == (current > future)):\n",
        "                correctDirection = correctDirection + 1\n",
        "\n",
        "    #print(\"-------------------------------\")\n",
        "    #print(\"MSE: \" + str(round(mse,3)))\n",
        "    directionClass = correctDirection / noDatapoints\n",
        "    #print(\"Direction classification: \" + str(round(directionClass,3)))\n",
        "    #print(\"-------------------------------\")\n",
        "\n",
        "    mses.append(mse)\n",
        "    classifications.append(directionClass)\n",
        "\n",
        "    return mses, classifications\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        print(\"running test\")\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTest, yTest = singleStepDataSplit(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        mses,classifications = singleStepModelTests(models[i-1], xTest, yTest)\n",
        "\n",
        "        modelMses.append(mses)\n",
        "        modelClassifications.append(classifications)\n",
        "\n",
        "        meanMse = np.mean(modelMses)\n",
        "        meanClass = np.mean(modelClassifications)\n",
        "    \n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "    #print(\"Average MSE: \" + str(meanMse))\n",
        "    #print(\"Average classification: \" + str(np.mean(classifications)))\n",
        "    #print(\"-------------------------------------------------------------\")\n",
        "\n",
        "    return modelMses, modelClassifications\n",
        "\n",
        "\n",
        "def bestGuessTests(models, fold):\n",
        "\n",
        "    valIndex = fold_locations[fold+1]\n",
        "    \n",
        "    if (fold==FOLDS-2):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[fold+2]\n",
        "\n",
        "    print(valIndex)\n",
        "    print(endIndex)\n",
        "\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    xTest, yTest = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    for datapoint in range(len(xTest)):\n",
        "\n",
        "        past = tf.constant([xTest[datapoint]])\n",
        "        future = yTest[datapoint]\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "\n",
        "            prediction = models[j].predict(past)\n",
        "            predictions.append(prediction)\n",
        "\n",
        "        actualMax = np.argmax(future)\n",
        "        predictedMax = np.argmax(predictions)\n",
        "\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "    \n",
        "    print(\"--------------------------------\")\n",
        "            \n",
        "\n",
        "\n",
        "    #print(\"---------------\")\n",
        "    bestMonthClass = correctMax / len(xTest)\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / len(xTest)\n",
        "\n",
        "    #print(\"Correct best month: \" + str(round(bestMonthClass,3)))\n",
        "\n",
        "    print(\"------------\")\n",
        "    print(correctMax)\n",
        "    print(bestMonthRelaxedClass)\n",
        "\n",
        "    return bestMonthClass, bestMonthRelaxedClass\n",
        "\n",
        "def runBestGuessTests(allModels):\n",
        "\n",
        "    foldPerformances = []\n",
        "    relaxedFoldperformances = []\n",
        "\n",
        "    for i in range(len(allModels[0])):\n",
        "\n",
        "        print(\"running best guess test\")\n",
        "\n",
        "        foldModels = []\n",
        "\n",
        "        for j in range(FUTURE_STEPS):\n",
        "            foldModels.append(allModels[j][i])\n",
        "\n",
        "        foldPerformance, relaxedFoldperformance = bestGuessTests(foldModels, i)\n",
        "\n",
        "        foldPerformances.append(foldPerformance)\n",
        "        relaxedFoldperformances.append(relaxedFoldperformance)\n",
        "\n",
        "    return foldPerformances, relaxedFoldperformances\n",
        "\n",
        "\n",
        "def singleStepExperiments():\n",
        "    \n",
        "    print(\"MODELS CREATED\")\n",
        "\n",
        "    for modelsForOneStep in allModels:\n",
        "        print(\"MODEL STEP TESTS\")\n",
        "\n",
        "        modelMses, modelClassifications = runModels(modelsForOneStep)\n",
        "        allMses.append(modelMses)\n",
        "        allClassifications.append(modelClassifications)\n",
        "\n",
        "    print(\"MODEL STEP TESTS COMPLETE\")\n",
        "    print(\"TESTING BEST GUESS ABILITY\")\n",
        "\n",
        "    bestGuess, relaxedGuess = runBestGuessTests(allModels)\n",
        "\n",
        "    bestGuessClassifications.append(bestGuess)\n",
        "    relaxedGuessClassifications.append(relaxedGuess)\n",
        "\n",
        "\n",
        "    print(\"TESTING COMPLETE\")\n",
        "\n",
        "singleStepExperiments()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-8mJXyPjrpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(allMses)                      #shape = FUTURE_STEPS, FOLDS\n",
        "print(allClassifications)           #shape = FUTURE_STEPS, FOLDS\n",
        "print(bestGuessClassifications)      #shape = FOLDS\n",
        "print(relaxedGuessClassifications)   #shape = FOLDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rudFJZfKboB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(allMses[0])\n",
        "\n",
        "print(bestGuessClassifications[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwgG0U6-gUrZ",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DGg4vGuUmRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(mses,directionClass,bestClass):\n",
        "\n",
        "    for i in range(FUTURE_STEPS):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(mses[i]))\n",
        "        print(\"Dir: \" + str(directionClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "#printResults(allMses, allClassifications, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uwx3VvAnnRN",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TYzy6YXnpjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_time_steps(length,steps):\n",
        "    return list(np.arange(-length, 0,step=steps))\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = ['History', 'True Future', 'Model Prediction']\n",
        "    marker = ['.-', 'rx', 'go']\n",
        "    time_steps = create_time_steps(TIME_LAGS,STEP)\n",
        "\n",
        "    if delta:\n",
        "        future = delta\n",
        "    else:\n",
        "        future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, x in enumerate(plot_data):\n",
        "        if i:\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "                    label=labels[i])\n",
        "        else:\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlim([time_steps[0], (future+5)*2])\n",
        "    plt.xlabel('Time-Step')\n",
        "    return plt\n",
        "\n",
        "\n",
        "#for x, y in dataVal.take(1):\n",
        "#    plot = show_plot([x[0][:, 0].numpy(), y[0].numpy(),\n",
        "#                        model.predict(x)[0]], PREDICTION_HORIZON,\n",
        "#                    'Single Step Prediction')\n",
        "#    print(model.predict(x)[0])\n",
        "#    plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1syGFxznuVLK",
        "colab_type": "text"
      },
      "source": [
        "## Multi-step LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHJMXYsuZWp",
        "colab_type": "text"
      },
      "source": [
        "### Building network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0P_sbFRuhMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiStepLSTM():\n",
        "    multiStepLSTMModel = keras.Sequential([\n",
        "        layers.LSTM(units=32, return_sequences=True, input_shape = (HISTORY_STEPS, len(features))),\n",
        "        layers.LSTM(16, activation='relu'),\n",
        "        layers.Dense(FUTURE_STEPS)\n",
        "    ])\n",
        "\n",
        "    multiStepLSTMModel.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mse')\n",
        "    return multiStepLSTMModel\n",
        "\n",
        "multiStepModel = multiStepLSTM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_IwcoGcu3mP",
        "colab_type": "text"
      },
      "source": [
        "### Training models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UAjl2pn0eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "results = []\n",
        "dataTrainMulti = []\n",
        "\n",
        "for x in range(1, FOLDS):\n",
        "\n",
        "    valIndex = fold_locations[x]\n",
        "\n",
        "    multiStepModel = multiStepLSTM()\n",
        "    \n",
        "    if (x==FOLDS-1):\n",
        "        endIndex = None\n",
        "    else:\n",
        "        endIndex = fold_locations[x+1]\n",
        "\n",
        "    xTrainMulti, yTrainMulti = splitData(dataSet, dataSet[:, 0], 0, valIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "    xValMulti, yValMulti = splitData(dataSet, dataSet[:, 0], valIndex, None, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "    dataTrainMulti = tf.data.Dataset.from_tensor_slices((xTrainMulti, yTrainMulti))\n",
        "    dataTrainMulti = dataTrainMulti.cache().batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    dataValMulti = tf.data.Dataset.from_tensor_slices((xValMulti, yValMulti))\n",
        "    dataValMulti = dataValMulti.batch(BATCH_SIZE).repeat()\n",
        "\n",
        "    print(\"--------------------- Model\", \"%d/%d --------------------------\" % (x, FOLDS - 1))\n",
        "\n",
        "    steps_per = math.floor(len(xTrainMulti)/BATCH_SIZE)\n",
        "    print(steps_per)\n",
        "\n",
        "    result = multiStepModel.fit(dataTrainMulti, epochs=EPOCHS, steps_per_epoch=steps_per,\n",
        "                        validation_data=dataValMulti, validation_steps=50)\n",
        "    \n",
        "    models.append(multiStepModel)\n",
        "    results.append(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2Uaxl7U4rEH",
        "colab_type": "text"
      },
      "source": [
        "### Multi-step tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CxChDHwvxdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMsesMulti = []\n",
        "allClassificationsMulti = []\n",
        "bestGuessClassificationsMulti = []\n",
        "relaxedGuessClassificationsMulti = []\n",
        "\n",
        "def multiStepModelTests(model, xTest, yTest):\n",
        "\n",
        "    correctDirection = [0,0,0,0,0,0]\n",
        "    totalSquaredError = [0,0,0,0,0,0]\n",
        "    correctMax = 0\n",
        "    correctMaxRelaxed = 0\n",
        "\n",
        "    noDatapoints = len(xTest)\n",
        "    noPredictions = len(totalSquaredError)\n",
        "\n",
        "    for x in range(noDatapoints):\n",
        "        current = xTest[x][-1]\n",
        "        past = tf.constant([xTest[x]])\n",
        "        predictions = model.predict(past)[0]\n",
        "        future = yTest[x]\n",
        "\n",
        "        predictedMax = np.argmax(predictions)\n",
        "        actualMax = np.argmax(future)\n",
        "\n",
        "        temp = future[actualMax]\n",
        "        future[actualMax] = -100000\n",
        "        actual2ndMax = np.argmax(future)\n",
        "\n",
        "        if(predictedMax == actualMax):\n",
        "            correctMax = correctMax + 1\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "        elif(predictedMax == actual2ndMax):\n",
        "            correctMaxRelaxed = correctMaxRelaxed + 1\n",
        "\n",
        "        future[actualMax]=temp\n",
        "\n",
        "        for y in range(noPredictions):\n",
        "            prediction = predictions[y]\n",
        "            actual = future[y]\n",
        "\n",
        "            squaredDifference = abs(prediction - actual) ** 2\n",
        "            totalSquaredError[y] = totalSquaredError[y] + squaredDifference\n",
        "\n",
        "            if ((current > prediction) == (current > actual)):\n",
        "                correctDirection[y] = correctDirection[y] + 1\n",
        "\n",
        "\n",
        "    mses = []\n",
        "    classifications = []\n",
        "\n",
        "    for x in range(noPredictions):\n",
        "        mse = totalSquaredError[x] / noDatapoints\n",
        "        mses.append(mse)\n",
        "\n",
        "    for x in range(noPredictions):\n",
        "        percentInterval = correctDirection[x] / noDatapoints\n",
        "        classifications.append(percentInterval)\n",
        "\n",
        "    bestMonthClass = correctMax / noDatapoints\n",
        "    bestMonthRelaxedClass = correctMaxRelaxed / noDatapoints\n",
        "\n",
        "    allMsesMulti.append(mses)\n",
        "    allClassificationsMulti.append(classifications)\n",
        "    bestGuessClassificationsMulti.append(bestMonthClass)\n",
        "    relaxedGuessClassificationsMulti.append(bestMonthRelaxedClass)\n",
        "\n",
        "\n",
        "def runModels(models):\n",
        "\n",
        "    modelMses = []\n",
        "    modelClassifications = []\n",
        "\n",
        "    for i in range(1, FOLDS):\n",
        "\n",
        "        valIndex = fold_locations[i]\n",
        "    \n",
        "        if (i==FOLDS-1):\n",
        "            endIndex = None\n",
        "        else:\n",
        "            endIndex = fold_locations[i+1]\n",
        "\n",
        "        xTestMulti, yTestMulti = splitData(dataSet, dataSet[:, 0], valIndex, endIndex, HISTORY_STEPS, FUTURE_STEPS)\n",
        "\n",
        "        multiStepModelTests(models[i-1], xTestMulti, yTestMulti)\n",
        "\n",
        "runModels(models)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GoqA1iO8TQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allMsesMulti = list(map(list, zip(*allMsesMulti)))\n",
        "allClassificationsMulti = list(map(list, zip(*allClassificationsMulti)))\n",
        "\n",
        "print(allMsesMulti)\n",
        "print(allClassificationsMulti)\n",
        "print(bestGuessClassificationsMulti)\n",
        "print(relaxedGuessClassificationsMulti)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNSYYPtFgP4i",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2SBad6gSMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printResults(monthAverageMses,monthAverageClass,bestClass):\n",
        "\n",
        "    for i in range(len(monthAverageMses)):\n",
        "\n",
        "        print(\"-----------\")\n",
        "        print(\"Month \" + str((i+1)))\n",
        "        print(\"MSE: \" + str(monthAverageMses[i]))\n",
        "        print(\"Dir: \" + str(monthAverageClass[i]))\n",
        "\n",
        "    print(\"---------\")\n",
        "    print(\"Bes: \" + str(bestClass))\n",
        "\n",
        "#printResults(monthAverageMses, monthAverageClass, bestClass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tii3SZcOw1qb",
        "colab_type": "text"
      },
      "source": [
        "### Prediction visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR0uE5bfw5uW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(TIME_LAGS,STEP)\n",
        "  num_out = len(true_future) * FUTURE_STEP\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 0]), label='History')\n",
        "  plt.plot(np.arange(num_out, step=FUTURE_STEP), np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out,step=FUTURE_STEP), np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "#model = models[-1]\n",
        "\n",
        "#for x, y in dataTrainMulti.take(1):\n",
        "#\n",
        "#    print(x)\n",
        "\n",
        "    #print((multiStepModel.predict(x)[0]).index(max(multiStepModel.predict(x)[0])))\n",
        "#    print(model.predict(x)[0])\n",
        "#    multi_step_plot(x[0], y[0], model.predict(x)[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_dvGN0dnK_y",
        "colab_type": "text"
      },
      "source": [
        "# Run all tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sub9ApHanOdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeJ7pc31UP8k",
        "colab_type": "text"
      },
      "source": [
        "# Exporting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKanocQUSfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade -q pygsheets\n",
        "\n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)\n",
        "\n",
        "gc.create(title=\"*testffh\",folder=\"1zb8cLLf2RtYz9RuofDhGDgmTAoXD2VnE\")\n",
        "\n",
        "sh = gc.open('*testffh')\n",
        "\n",
        "#sh.add_worksheet('test2',rows=5, cols=20) \n",
        "\n",
        "wk1 = sh[0]\n",
        "\n",
        "titles = ['SINGLE_STEP','MSE(Fold1)','MSE(Fold2)','MSE(Fold3)','MSE(Fold4)','MSE(avg)',\n",
        "          'Dir(Fold1)','Dir(Fold2)','Dir(Fold3)','Dir(Fold4)','Dir(avg)']\n",
        "\n",
        "shiftSize = FUTURE_STEPS+5\n",
        "\n",
        "wk1.insert_rows(row = 0, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "mseAvgsSingle = []\n",
        "dirAvgsSingle = []\n",
        "bestSingle = []\n",
        "relaxedSingle = []\n",
        "\n",
        "mseAvgsMulti = []\n",
        "dirAvgsMulti = []\n",
        "bestMulti = []\n",
        "relaxedMultti = []\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMses[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allMses[step][1:])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsSingle.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassifications[step][fold][0]))\n",
        "\n",
        "    arr = np.asarray(allClassifications[step][1:])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsSingle.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = step+1, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassifications[0][1:])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestSingle = mean\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassifications[0][fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassifications[0][1:])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedSingle = mean\n",
        "\n",
        "wk1.insert_rows(row = FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "\n",
        "titles[0] = 'MULTI-STEP'\n",
        "\n",
        "wk1.insert_rows(row = shiftSize, number = 0, values = titles) # insert 1 new row and insert values in same row\n",
        "\n",
        "for step in range(FUTURE_STEPS):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    month = 'Month ' + str(step+1)\n",
        "\n",
        "    row.append(month)\n",
        "    \n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allMsesMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allMsesMulti[step][1:])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(mean)\n",
        "    mseAvgsMulti.append(mean)\n",
        "\n",
        "    for fold in range(FOLDS-1):\n",
        "        row.append(str(allClassificationsMulti[step][fold]))\n",
        "\n",
        "    arr = np.asarray(allClassificationsMulti[step][1:])\n",
        "    mean = np.mean(arr)\n",
        "    row.append(str(mean))\n",
        "    dirAvgsMulti.append(mean)\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+step+1, number = 1, values = row)\n",
        "\n",
        "guessTitles = ['','Best(Fold1)','Best(Fold2)','Best(Fold3)','Best(Fold4)','Best(avg)',\n",
        "               'Relaxed(Fold1)','Relaxed(Fold2)','Relaxed(Fold3)','Relaxed(Fold4)','Relaxed(avg)']\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+2, number = 1, values = guessTitles)\n",
        "\n",
        "guessResults = ['']\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = bestGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(bestGuessClassificationsMulti[1:])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "bestMulti = mean\n",
        "\n",
        "for fold in range(len(bestGuessClassificationsMulti)):\n",
        "    classification = relaxedGuessClassificationsMulti[fold]\n",
        "    guessResults.append(classification)\n",
        "\n",
        "arr = np.asarray(relaxedGuessClassificationsMulti[1:])\n",
        "mean = np.mean(arr)\n",
        "guessResults.append(str(mean))\n",
        "relaxedMulti = mean\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+3, number = 1, values = guessResults)\n",
        "\n",
        "for i in range(FUTURE_STEPS):\n",
        "\n",
        "    month = 'Month ' + str(i+1)\n",
        "    row = [month]\n",
        "    row.append(str(mseAvgsSingle[i]))\n",
        "    row.append(str(dirAvgsSingle[i]))\n",
        "    row.append(str(mseAvgsMulti[i]))\n",
        "    row.append(str(dirAvgsMulti[i]))\n",
        "\n",
        "    wk1.insert_rows(row = shiftSize+FUTURE_STEPS+i+7, number = 1, values = row)\n",
        "\n",
        "row = ['Guesses']\n",
        "row.append(str(bestSingle))\n",
        "row.append(str(relaxedSingle))\n",
        "row.append(str(bestMulti))\n",
        "row.append(str(relaxedMulti))\n",
        "\n",
        "wk1.insert_rows(row = shiftSize+FUTURE_STEPS+FUTURE_STEPS+7, number = 1, values = row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_1JpTDehzM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(allMsesMulti[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}